{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5513df96c844586a813166c5f771b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_126d048f244f4b8a98e2880c2ea07fae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c32481a68daa4af3b556018d1effb518",
              "IPY_MODEL_d8171ff6475046619d539c6abd1bce98",
              "IPY_MODEL_638d8710dbcc4e858ac6488c4523a6f6"
            ]
          }
        },
        "126d048f244f4b8a98e2880c2ea07fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c32481a68daa4af3b556018d1effb518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f250e3ddbd64112bc98cd1ef14848e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc93b18934a4412c97c8bed5a78748f1"
          }
        },
        "d8171ff6475046619d539c6abd1bce98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2bf6b3b2270547168ebf6f2f665c4125",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e5802f756bb464193cdac5a2cfa506f"
          }
        },
        "638d8710dbcc4e858ac6488c4523a6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d43403983edc4eeea15eacec72cb5047",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 55058675.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8223ed79a6b425197a3591b31061785"
          }
        },
        "6f250e3ddbd64112bc98cd1ef14848e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc93b18934a4412c97c8bed5a78748f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bf6b3b2270547168ebf6f2f665c4125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e5802f756bb464193cdac5a2cfa506f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d43403983edc4eeea15eacec72cb5047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8223ed79a6b425197a3591b31061785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nageswar-Sahoo/Computer-Vision-Learning/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKQhaGxKQfUH",
        "outputId": "251d0383-276b-453e-c186-ac9e2134a18c"
      },
      "source": [
        "!git clone -b  backup-1  https://github.com/Nageswar-Sahoo/Computer-Vision-Project.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Computer-Vision-Project'...\n",
            "remote: Enumerating objects: 556, done.\u001b[K\n",
            "remote: Counting objects: 100% (556/556), done.\u001b[K\n",
            "remote: Compressing objects: 100% (481/481), done.\u001b[K\n",
            "remote: Total 556 (delta 345), reused 195 (delta 63), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (556/556), 1.84 MiB | 25.88 MiB/s, done.\n",
            "Resolving deltas: 100% (345/345), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op1IgEBkQiV4",
        "outputId": "077194e2-c1e0-460f-88ce-14d4acf2da3f"
      },
      "source": [
        "!pip install albumentations==0.4.6\n",
        "import albumentations \n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65172 sha256=0f9819e0f87e121a5ab855fcf6885996ac8dc30b7a73739764fdf7b5a1d07da4\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixPgAYQOQjEF",
        "outputId": "84210ef7-fd49-4e98-a8dc-76243a7706d6"
      },
      "source": [
        "cd Computer-Vision-Project/S7"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Computer-Vision-Project/S7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jovdq3wiQmZ_"
      },
      "source": [
        "import data_loader.data_loaders as module_data\n",
        "from parse_config import ConfigParser\n",
        "from trainer import Trainer\n",
        "from utils import prepare_device\n",
        "import torch\n",
        "import numpy as np\n",
        "import model.loss as module_loss\n",
        "import model.metric as module_metric\n",
        "import model.model as module_arch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import logging\n",
        "\n",
        "# fix random seeds for reproducibility\n",
        "SEED = 123\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcAdc1FNa3T2",
        "outputId": "4a887de4-6734-4448-83d3-92bf161da963"
      },
      "source": [
        "cat config.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"CIFR10\",\n",
            "    \"trainer\": {\n",
            "        \"epochs\": 300,\n",
            "        \"save_dir\": \"saved/\",\n",
            "        \"save_period\": 1,\n",
            "        \"verbosity\": 1,\n",
            "        \"monitor\": \"min val_loss\",\n",
            "        \"early_stop\": 300,\n",
            "        \"tensorboard\": true\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-JVA2n3Qqau"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from base import BaseModel\n",
        "from normalization import norm\n",
        "\n",
        "\n",
        "class CIFRModel(BaseModel):\n",
        "    # epoch: 8\n",
        "    # loss: 0.73457906589928\n",
        "    # accuracy: 75.11097301136364\n",
        "    # val_loss: 0.7309541015685359\n",
        "    # val_accuracy: 74.72310126582279\n",
        "\n",
        "    def __init__(self, num_classes=10, normalizationtype='Layer', dropout=.01):\n",
        "        super().__init__()\n",
        "        # Input Block\n",
        "\n",
        "        self.depthwise_separable_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, groups=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(3),\n",
        "            #nn.Dropout(.05),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=3, out_channels=256, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            #nn.Dropout(.05),\n",
        "            nn.ReLU(),\n",
        "        )  # output_size = 28 receptive field  : 5\n",
        "\n",
        "        # Input Block\n",
        "        self.depthwise_separable_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, groups=256, padding=1,dilation=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "           #nn.Dropout(.05),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=256, out_channels=40, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(40),\n",
        "            #nn.Dropout(.05),\n",
        "            nn.ReLU(),\n",
        "        )  # output_size = 28 receptive field  : 5\n",
        "        # Input Block\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=40, out_channels=185, kernel_size=(3, 3), padding=0, bias=False, dilation=8),\n",
        "            nn.BatchNorm2d(185),\n",
        "            #nn.Dropout(.05),\n",
        "            nn.ReLU(),\n",
        "\n",
        "        )  # output_size = 26 receptive field  : 7\n",
        "\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=185, out_channels=10, kernel_size=(3, 3), padding=0, bias=False, dilation=16),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.ReLU()\n",
        "        )  # output_size = 20 receptive field  : 12\n",
        "\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=16)\n",
        "        )  # output_size = 20 receptive field  : 28\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise_separable_conv1(x)\n",
        "        x = self.depthwise_separable_conv2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.reshape(-1, 10 * 1 * 1)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOy_vsQiQsin",
        "outputId": "bea082c3-6e62-4d62-c28f-6984348f7721"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = CIFRModel().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 3, 32, 32]              27\n",
            "       BatchNorm2d-2            [-1, 3, 32, 32]               6\n",
            "              ReLU-3            [-1, 3, 32, 32]               0\n",
            "            Conv2d-4          [-1, 256, 32, 32]             768\n",
            "       BatchNorm2d-5          [-1, 256, 32, 32]             512\n",
            "              ReLU-6          [-1, 256, 32, 32]               0\n",
            "            Conv2d-7          [-1, 256, 32, 32]           2,304\n",
            "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
            "              ReLU-9          [-1, 256, 32, 32]               0\n",
            "           Conv2d-10           [-1, 40, 32, 32]          10,240\n",
            "      BatchNorm2d-11           [-1, 40, 32, 32]              80\n",
            "             ReLU-12           [-1, 40, 32, 32]               0\n",
            "  ConvTranspose2d-13          [-1, 185, 48, 48]          66,600\n",
            "      BatchNorm2d-14          [-1, 185, 48, 48]             370\n",
            "             ReLU-15          [-1, 185, 48, 48]               0\n",
            "           Conv2d-16           [-1, 10, 16, 16]          16,650\n",
            "      BatchNorm2d-17           [-1, 10, 16, 16]              20\n",
            "             ReLU-18           [-1, 10, 16, 16]               0\n",
            "        AvgPool2d-19             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 98,089\n",
            "Trainable params: 98,089\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 22.82\n",
            "Params size (MB): 0.37\n",
            "Estimated Total Size (MB): 23.21\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e5513df96c844586a813166c5f771b56",
            "126d048f244f4b8a98e2880c2ea07fae",
            "c32481a68daa4af3b556018d1effb518",
            "d8171ff6475046619d539c6abd1bce98",
            "638d8710dbcc4e858ac6488c4523a6f6",
            "6f250e3ddbd64112bc98cd1ef14848e7",
            "cc93b18934a4412c97c8bed5a78748f1",
            "2bf6b3b2270547168ebf6f2f665c4125",
            "5e5802f756bb464193cdac5a2cfa506f",
            "d43403983edc4eeea15eacec72cb5047",
            "c8223ed79a6b425197a3591b31061785"
          ]
        },
        "id": "dOhJSZDyQ0RX",
        "outputId": "40a945ff-76ff-4fe1-c9ac-c7afb71cc16a"
      },
      "source": [
        "    # added logger to track change\n",
        "    logger = logging.getLogger(\"trian\")\n",
        "    # Read the config.json\n",
        "    config = ConfigParser.from_args()\n",
        "\n",
        "    # setup data_loader instances\n",
        "    data_loader = module_data.CIFRDataLoader(data_dir='data/', batch_size=64, shuffle=True, validation_split=0.1,\n",
        "                                             num_workers=2, training=True)\n",
        "    valid_data_loader = data_loader.split_validation()\n",
        "\n",
        "    # build model architecture, then print to console\n",
        "    model = CIFRModel()\n",
        "    logger.info(model)\n",
        "\n",
        "    # prepare for (multi-device) GPU training\n",
        "\n",
        "    n_gpu = 8\n",
        "    device, device_ids = prepare_device(n_gpu)\n",
        "    model = model.to(device)\n",
        "    if len(device_ids) > 1:\n",
        "        model = torch.nn.DataParallel(model, device_ids=device_ids)\n",
        "\n",
        "    # get function handles of loss and metrics\n",
        "    criterion = module_loss.crossentropyloss\n",
        "    metrics = [module_metric.accuracy]\n",
        "\n",
        "    # build optimizer, learning rate scheduler. delete every lines containing lr_scheduler for disabling scheduler\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "    #optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "    lr_scheduler = StepLR(optimizer, step_size=70, gamma=0.1)\n",
        "    trainer = Trainer(model, criterion, metrics, optimizer,\n",
        "                      config=config,\n",
        "                      device=device,\n",
        "                      data_loader=data_loader,\n",
        "                      valid_data_loader=valid_data_loader,\n",
        "                      lr_scheduler=lr_scheduler)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******************************\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5513df96c844586a813166c5f771b56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 608, in format\n",
            "    record.message = record.getMessage()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 367, in getMessage\n",
            "    msg = str(self.msg)\n",
            "  File \"/content/Computer-Vision-Project/S7/base/base_model.py\", line 23, in __str__\n",
            "    summary(self, input_size=(1, 28, 28))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
            "    model(*x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"<ipython-input-6-2457e007ef5d>\", line 61, in forward\n",
            "    x = self.depthwise_separable_conv1(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 446, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 443, in _conv_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "RuntimeError: Given groups=3, weight of size [3, 1, 3, 3], expected input[2, 1, 28, 28] to have 3 channels, but got 1 channels instead\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
            "    handler_func(fileobj, events)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-45f30880c54f>\", line 13, in <module>\n",
            "    logger.info(model)\n",
            "Message: CIFRModel(\n",
            "  (depthwise_separable_conv1): Sequential(\n",
            "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
            "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (depthwise_separable_conv2): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (convblock3): Sequential(\n",
            "    (0): ConvTranspose2d(40, 185, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8), bias=False)\n",
            "    (1): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (convblock4): Sequential(\n",
            "    (0): Conv2d(185, 10, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16), bias=False)\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (gap): Sequential(\n",
            "    (0): AvgPool2d(kernel_size=16, stride=16, padding=0)\n",
            "  )\n",
            ")\n",
            "Arguments: ()\n",
            "--- Logging error ---\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/handlers.py\", line 69, in emit\n",
            "    if self.shouldRollover(record):\n",
            "  File \"/usr/lib/python3.7/logging/handlers.py\", line 185, in shouldRollover\n",
            "    msg = \"%s\\n\" % self.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 608, in format\n",
            "    record.message = record.getMessage()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 367, in getMessage\n",
            "    msg = str(self.msg)\n",
            "  File \"/content/Computer-Vision-Project/S7/base/base_model.py\", line 23, in __str__\n",
            "    summary(self, input_size=(1, 28, 28))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\", line 72, in summary\n",
            "    model(*x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"<ipython-input-6-2457e007ef5d>\", line 61, in forward\n",
            "    x = self.depthwise_separable_conv1(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1120, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 446, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 443, in _conv_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "RuntimeError: Given groups=3, weight of size [3, 1, 3, 3], expected input[2, 1, 28, 28] to have 3 channels, but got 1 channels instead\n",
            "Call stack:\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
            "    app.launch_new_instance()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
            "    handler_func(fileobj, events)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n",
            "    self._handle_recv()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n",
            "    self._run_callback(callback, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n",
            "    callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
            "    return self.dispatch_shell(stream, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
            "    handler(stream, idents, msg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
            "    user_expressions, allow_stdin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n",
            "    interactivity=interactivity, compiler=compiler, result=result)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n",
            "    if self.run_code(code, result):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-45f30880c54f>\", line 13, in <module>\n",
            "    logger.info(model)\n",
            "Message: CIFRModel(\n",
            "  (depthwise_separable_conv1): Sequential(\n",
            "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
            "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (depthwise_separable_conv2): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(256, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (convblock3): Sequential(\n",
            "    (0): ConvTranspose2d(40, 185, kernel_size=(3, 3), stride=(1, 1), dilation=(8, 8), bias=False)\n",
            "    (1): BatchNorm2d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (convblock4): Sequential(\n",
            "    (0): Conv2d(185, 10, kernel_size=(3, 3), stride=(1, 1), dilation=(16, 16), bias=False)\n",
            "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (gap): Sequential(\n",
            "    (0): AvgPool2d(kernel_size=16, stride=16, padding=0)\n",
            "  )\n",
            ")\n",
            "Arguments: ()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: The number of GPU's configured to use is 8, but only 1 are available on this machine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VcqfrY6NQ5ye",
        "outputId": "0712aec3-f9c8-4c3a-fd27-c1b726970e65"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train Epoch: 7 [4096/45000 (9%)] Loss: 1.007444\n",
            "Train Epoch: 7 [4608/45000 (10%)] Loss: 0.815562\n",
            "Train Epoch: 7 [5120/45000 (11%)] Loss: 0.790120\n",
            "Train Epoch: 7 [5632/45000 (13%)] Loss: 0.710074\n",
            "Train Epoch: 7 [6144/45000 (14%)] Loss: 0.828200\n",
            "Train Epoch: 7 [6656/45000 (15%)] Loss: 0.828370\n",
            "Train Epoch: 7 [7168/45000 (16%)] Loss: 1.059130\n",
            "Train Epoch: 7 [7680/45000 (17%)] Loss: 0.913817\n",
            "Train Epoch: 7 [8192/45000 (18%)] Loss: 0.713760\n",
            "Train Epoch: 7 [8704/45000 (19%)] Loss: 0.952678\n",
            "Train Epoch: 7 [9216/45000 (20%)] Loss: 0.780831\n",
            "Train Epoch: 7 [9728/45000 (22%)] Loss: 0.837033\n",
            "Train Epoch: 7 [10240/45000 (23%)] Loss: 0.726385\n",
            "Train Epoch: 7 [10752/45000 (24%)] Loss: 1.120898\n",
            "Train Epoch: 7 [11264/45000 (25%)] Loss: 1.081913\n",
            "Train Epoch: 7 [11776/45000 (26%)] Loss: 0.909024\n",
            "Train Epoch: 7 [12288/45000 (27%)] Loss: 0.658550\n",
            "Train Epoch: 7 [12800/45000 (28%)] Loss: 0.675828\n",
            "Train Epoch: 7 [13312/45000 (30%)] Loss: 0.741708\n",
            "Train Epoch: 7 [13824/45000 (31%)] Loss: 0.679857\n",
            "Train Epoch: 7 [14336/45000 (32%)] Loss: 0.819544\n",
            "Train Epoch: 7 [14848/45000 (33%)] Loss: 0.670989\n",
            "Train Epoch: 7 [15360/45000 (34%)] Loss: 1.242391\n",
            "Train Epoch: 7 [15872/45000 (35%)] Loss: 0.841046\n",
            "Train Epoch: 7 [16384/45000 (36%)] Loss: 0.797985\n",
            "Train Epoch: 7 [16896/45000 (38%)] Loss: 0.836214\n",
            "Train Epoch: 7 [17408/45000 (39%)] Loss: 1.008379\n",
            "Train Epoch: 7 [17920/45000 (40%)] Loss: 0.800647\n",
            "Train Epoch: 7 [18432/45000 (41%)] Loss: 0.798594\n",
            "Train Epoch: 7 [18944/45000 (42%)] Loss: 0.644831\n",
            "Train Epoch: 7 [19456/45000 (43%)] Loss: 0.846900\n",
            "Train Epoch: 7 [19968/45000 (44%)] Loss: 0.839711\n",
            "Train Epoch: 7 [20480/45000 (46%)] Loss: 0.604736\n",
            "Train Epoch: 7 [20992/45000 (47%)] Loss: 1.036458\n",
            "Train Epoch: 7 [21504/45000 (48%)] Loss: 0.773811\n",
            "Train Epoch: 7 [22016/45000 (49%)] Loss: 0.707488\n",
            "Train Epoch: 7 [22528/45000 (50%)] Loss: 0.801814\n",
            "Train Epoch: 7 [23040/45000 (51%)] Loss: 0.866967\n",
            "Train Epoch: 7 [23552/45000 (52%)] Loss: 0.744496\n",
            "Train Epoch: 7 [24064/45000 (53%)] Loss: 0.860150\n",
            "Train Epoch: 7 [24576/45000 (55%)] Loss: 0.731194\n",
            "Train Epoch: 7 [25088/45000 (56%)] Loss: 0.902333\n",
            "Train Epoch: 7 [25600/45000 (57%)] Loss: 0.767798\n",
            "Train Epoch: 7 [26112/45000 (58%)] Loss: 0.992994\n",
            "Train Epoch: 7 [26624/45000 (59%)] Loss: 0.767032\n",
            "Train Epoch: 7 [27136/45000 (60%)] Loss: 1.032493\n",
            "Train Epoch: 7 [27648/45000 (61%)] Loss: 0.638481\n",
            "Train Epoch: 7 [28160/45000 (63%)] Loss: 1.286955\n",
            "Train Epoch: 7 [28672/45000 (64%)] Loss: 0.672574\n",
            "Train Epoch: 7 [29184/45000 (65%)] Loss: 0.813934\n",
            "Train Epoch: 7 [29696/45000 (66%)] Loss: 1.082078\n",
            "Train Epoch: 7 [30208/45000 (67%)] Loss: 0.560527\n",
            "Train Epoch: 7 [30720/45000 (68%)] Loss: 0.501952\n",
            "Train Epoch: 7 [31232/45000 (69%)] Loss: 0.773684\n",
            "Train Epoch: 7 [31744/45000 (71%)] Loss: 0.899860\n",
            "Train Epoch: 7 [32256/45000 (72%)] Loss: 0.887141\n",
            "Train Epoch: 7 [32768/45000 (73%)] Loss: 0.959473\n",
            "Train Epoch: 7 [33280/45000 (74%)] Loss: 1.002825\n",
            "Train Epoch: 7 [33792/45000 (75%)] Loss: 0.827553\n",
            "Train Epoch: 7 [34304/45000 (76%)] Loss: 1.131613\n",
            "Train Epoch: 7 [34816/45000 (77%)] Loss: 0.770797\n",
            "Train Epoch: 7 [35328/45000 (79%)] Loss: 1.051105\n",
            "Train Epoch: 7 [35840/45000 (80%)] Loss: 0.701029\n",
            "Train Epoch: 7 [36352/45000 (81%)] Loss: 0.606607\n",
            "Train Epoch: 7 [36864/45000 (82%)] Loss: 0.873370\n",
            "Train Epoch: 7 [37376/45000 (83%)] Loss: 1.029858\n",
            "Train Epoch: 7 [37888/45000 (84%)] Loss: 0.873336\n",
            "Train Epoch: 7 [38400/45000 (85%)] Loss: 0.822897\n",
            "Train Epoch: 7 [38912/45000 (86%)] Loss: 0.639784\n",
            "Train Epoch: 7 [39424/45000 (88%)] Loss: 0.939059\n",
            "Train Epoch: 7 [39936/45000 (89%)] Loss: 0.992813\n",
            "Train Epoch: 7 [40448/45000 (90%)] Loss: 0.870435\n",
            "Train Epoch: 7 [40960/45000 (91%)] Loss: 0.771744\n",
            "Train Epoch: 7 [41472/45000 (92%)] Loss: 0.988691\n",
            "Train Epoch: 7 [41984/45000 (93%)] Loss: 0.812079\n",
            "Train Epoch: 7 [42496/45000 (94%)] Loss: 0.696997\n",
            "Train Epoch: 7 [43008/45000 (96%)] Loss: 0.851816\n",
            "Train Epoch: 7 [43520/45000 (97%)] Loss: 0.677553\n",
            "Train Epoch: 7 [44032/45000 (98%)] Loss: 0.890320\n",
            "Train Epoch: 7 [44544/45000 (99%)] Loss: 0.846339\n",
            "    epoch          : 7\n",
            "    loss           : 0.8303259582343426\n",
            "    accuracy       : 71.337890625\n",
            "    val_loss       : 1.0180654405038567\n",
            "    val_accuracy   : 65.76344936708861\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch7.pth ...\n",
            "Train Epoch: 8 [0/45000 (0%)] Loss: 0.736943\n",
            "Train Epoch: 8 [512/45000 (1%)] Loss: 0.935584\n",
            "Train Epoch: 8 [1024/45000 (2%)] Loss: 0.826200\n",
            "Train Epoch: 8 [1536/45000 (3%)] Loss: 1.064431\n",
            "Train Epoch: 8 [2048/45000 (5%)] Loss: 0.895033\n",
            "Train Epoch: 8 [2560/45000 (6%)] Loss: 0.949097\n",
            "Train Epoch: 8 [3072/45000 (7%)] Loss: 0.990387\n",
            "Train Epoch: 8 [3584/45000 (8%)] Loss: 0.694289\n",
            "Train Epoch: 8 [4096/45000 (9%)] Loss: 0.687194\n",
            "Train Epoch: 8 [4608/45000 (10%)] Loss: 0.840785\n",
            "Train Epoch: 8 [5120/45000 (11%)] Loss: 0.974343\n",
            "Train Epoch: 8 [5632/45000 (13%)] Loss: 1.010061\n",
            "Train Epoch: 8 [6144/45000 (14%)] Loss: 0.848863\n",
            "Train Epoch: 8 [6656/45000 (15%)] Loss: 0.789430\n",
            "Train Epoch: 8 [7168/45000 (16%)] Loss: 0.778774\n",
            "Train Epoch: 8 [7680/45000 (17%)] Loss: 0.596803\n",
            "Train Epoch: 8 [8192/45000 (18%)] Loss: 0.839823\n",
            "Train Epoch: 8 [8704/45000 (19%)] Loss: 1.077595\n",
            "Train Epoch: 8 [9216/45000 (20%)] Loss: 0.799530\n",
            "Train Epoch: 8 [9728/45000 (22%)] Loss: 0.731779\n",
            "Train Epoch: 8 [10240/45000 (23%)] Loss: 0.706238\n",
            "Train Epoch: 8 [10752/45000 (24%)] Loss: 0.794268\n",
            "Train Epoch: 8 [11264/45000 (25%)] Loss: 1.020170\n",
            "Train Epoch: 8 [11776/45000 (26%)] Loss: 0.974513\n",
            "Train Epoch: 8 [12288/45000 (27%)] Loss: 0.934223\n",
            "Train Epoch: 8 [12800/45000 (28%)] Loss: 0.900023\n",
            "Train Epoch: 8 [13312/45000 (30%)] Loss: 0.865848\n",
            "Train Epoch: 8 [13824/45000 (31%)] Loss: 0.830405\n",
            "Train Epoch: 8 [14336/45000 (32%)] Loss: 1.095288\n",
            "Train Epoch: 8 [14848/45000 (33%)] Loss: 0.757101\n",
            "Train Epoch: 8 [15360/45000 (34%)] Loss: 0.784775\n",
            "Train Epoch: 8 [15872/45000 (35%)] Loss: 0.734267\n",
            "Train Epoch: 8 [16384/45000 (36%)] Loss: 0.868089\n",
            "Train Epoch: 8 [16896/45000 (38%)] Loss: 0.707979\n",
            "Train Epoch: 8 [17408/45000 (39%)] Loss: 0.814157\n",
            "Train Epoch: 8 [17920/45000 (40%)] Loss: 0.929476\n",
            "Train Epoch: 8 [18432/45000 (41%)] Loss: 0.969794\n",
            "Train Epoch: 8 [18944/45000 (42%)] Loss: 0.932558\n",
            "Train Epoch: 8 [19456/45000 (43%)] Loss: 0.819368\n",
            "Train Epoch: 8 [19968/45000 (44%)] Loss: 0.727036\n",
            "Train Epoch: 8 [20480/45000 (46%)] Loss: 0.742578\n",
            "Train Epoch: 8 [20992/45000 (47%)] Loss: 1.140825\n",
            "Train Epoch: 8 [21504/45000 (48%)] Loss: 0.693242\n",
            "Train Epoch: 8 [22016/45000 (49%)] Loss: 0.723527\n",
            "Train Epoch: 8 [22528/45000 (50%)] Loss: 0.778479\n",
            "Train Epoch: 8 [23040/45000 (51%)] Loss: 0.837598\n",
            "Train Epoch: 8 [23552/45000 (52%)] Loss: 0.757847\n",
            "Train Epoch: 8 [24064/45000 (53%)] Loss: 0.810703\n",
            "Train Epoch: 8 [24576/45000 (55%)] Loss: 0.762927\n",
            "Train Epoch: 8 [25088/45000 (56%)] Loss: 0.804187\n",
            "Train Epoch: 8 [25600/45000 (57%)] Loss: 0.601161\n",
            "Train Epoch: 8 [26112/45000 (58%)] Loss: 0.608370\n",
            "Train Epoch: 8 [26624/45000 (59%)] Loss: 0.857697\n",
            "Train Epoch: 8 [27136/45000 (60%)] Loss: 0.780815\n",
            "Train Epoch: 8 [27648/45000 (61%)] Loss: 0.884863\n",
            "Train Epoch: 8 [28160/45000 (63%)] Loss: 0.788114\n",
            "Train Epoch: 8 [28672/45000 (64%)] Loss: 1.056741\n",
            "Train Epoch: 8 [29184/45000 (65%)] Loss: 0.953073\n",
            "Train Epoch: 8 [29696/45000 (66%)] Loss: 0.691006\n",
            "Train Epoch: 8 [30208/45000 (67%)] Loss: 0.953157\n",
            "Train Epoch: 8 [30720/45000 (68%)] Loss: 0.867263\n",
            "Train Epoch: 8 [31232/45000 (69%)] Loss: 0.944274\n",
            "Train Epoch: 8 [31744/45000 (71%)] Loss: 0.789230\n",
            "Train Epoch: 8 [32256/45000 (72%)] Loss: 0.836001\n",
            "Train Epoch: 8 [32768/45000 (73%)] Loss: 0.665773\n",
            "Train Epoch: 8 [33280/45000 (74%)] Loss: 0.783057\n",
            "Train Epoch: 8 [33792/45000 (75%)] Loss: 0.695646\n",
            "Train Epoch: 8 [34304/45000 (76%)] Loss: 0.740465\n",
            "Train Epoch: 8 [34816/45000 (77%)] Loss: 0.780864\n",
            "Train Epoch: 8 [35328/45000 (79%)] Loss: 0.837972\n",
            "Train Epoch: 8 [35840/45000 (80%)] Loss: 0.980744\n",
            "Train Epoch: 8 [36352/45000 (81%)] Loss: 0.718290\n",
            "Train Epoch: 8 [36864/45000 (82%)] Loss: 0.843700\n",
            "Train Epoch: 8 [37376/45000 (83%)] Loss: 0.710593\n",
            "Train Epoch: 8 [37888/45000 (84%)] Loss: 0.612554\n",
            "Train Epoch: 8 [38400/45000 (85%)] Loss: 0.838603\n",
            "Train Epoch: 8 [38912/45000 (86%)] Loss: 0.663323\n",
            "Train Epoch: 8 [39424/45000 (88%)] Loss: 0.653887\n",
            "Train Epoch: 8 [39936/45000 (89%)] Loss: 0.759180\n",
            "Train Epoch: 8 [40448/45000 (90%)] Loss: 0.682864\n",
            "Train Epoch: 8 [40960/45000 (91%)] Loss: 1.029423\n",
            "Train Epoch: 8 [41472/45000 (92%)] Loss: 0.764603\n",
            "Train Epoch: 8 [41984/45000 (93%)] Loss: 0.886698\n",
            "Train Epoch: 8 [42496/45000 (94%)] Loss: 0.659149\n",
            "Train Epoch: 8 [43008/45000 (96%)] Loss: 0.699493\n",
            "Train Epoch: 8 [43520/45000 (97%)] Loss: 0.846466\n",
            "Train Epoch: 8 [44032/45000 (98%)] Loss: 0.804865\n",
            "Train Epoch: 8 [44544/45000 (99%)] Loss: 0.657759\n",
            "    epoch          : 8\n",
            "    loss           : 0.8078704031014984\n",
            "    accuracy       : 72.05255681818181\n",
            "    val_loss       : 0.8488341064392766\n",
            "    val_accuracy   : 69.77848101265823\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch8.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 9 [0/45000 (0%)] Loss: 0.605723\n",
            "Train Epoch: 9 [512/45000 (1%)] Loss: 0.947689\n",
            "Train Epoch: 9 [1024/45000 (2%)] Loss: 0.936548\n",
            "Train Epoch: 9 [1536/45000 (3%)] Loss: 0.953619\n",
            "Train Epoch: 9 [2048/45000 (5%)] Loss: 0.785693\n",
            "Train Epoch: 9 [2560/45000 (6%)] Loss: 0.904743\n",
            "Train Epoch: 9 [3072/45000 (7%)] Loss: 0.653451\n",
            "Train Epoch: 9 [3584/45000 (8%)] Loss: 0.783153\n",
            "Train Epoch: 9 [4096/45000 (9%)] Loss: 1.038745\n",
            "Train Epoch: 9 [4608/45000 (10%)] Loss: 0.861175\n",
            "Train Epoch: 9 [5120/45000 (11%)] Loss: 0.727637\n",
            "Train Epoch: 9 [5632/45000 (13%)] Loss: 0.981995\n",
            "Train Epoch: 9 [6144/45000 (14%)] Loss: 0.684387\n",
            "Train Epoch: 9 [6656/45000 (15%)] Loss: 0.888884\n",
            "Train Epoch: 9 [7168/45000 (16%)] Loss: 0.756361\n",
            "Train Epoch: 9 [7680/45000 (17%)] Loss: 0.655894\n",
            "Train Epoch: 9 [8192/45000 (18%)] Loss: 0.896822\n",
            "Train Epoch: 9 [8704/45000 (19%)] Loss: 0.860250\n",
            "Train Epoch: 9 [9216/45000 (20%)] Loss: 0.707242\n",
            "Train Epoch: 9 [9728/45000 (22%)] Loss: 0.807952\n",
            "Train Epoch: 9 [10240/45000 (23%)] Loss: 0.936126\n",
            "Train Epoch: 9 [10752/45000 (24%)] Loss: 0.675386\n",
            "Train Epoch: 9 [11264/45000 (25%)] Loss: 0.719662\n",
            "Train Epoch: 9 [11776/45000 (26%)] Loss: 0.822329\n",
            "Train Epoch: 9 [12288/45000 (27%)] Loss: 0.976431\n",
            "Train Epoch: 9 [12800/45000 (28%)] Loss: 0.854729\n",
            "Train Epoch: 9 [13312/45000 (30%)] Loss: 0.650811\n",
            "Train Epoch: 9 [13824/45000 (31%)] Loss: 1.013609\n",
            "Train Epoch: 9 [14336/45000 (32%)] Loss: 0.988017\n",
            "Train Epoch: 9 [14848/45000 (33%)] Loss: 1.098055\n",
            "Train Epoch: 9 [15360/45000 (34%)] Loss: 0.712766\n",
            "Train Epoch: 9 [15872/45000 (35%)] Loss: 0.864081\n",
            "Train Epoch: 9 [16384/45000 (36%)] Loss: 0.700746\n",
            "Train Epoch: 9 [16896/45000 (38%)] Loss: 0.829403\n",
            "Train Epoch: 9 [17408/45000 (39%)] Loss: 0.767538\n",
            "Train Epoch: 9 [17920/45000 (40%)] Loss: 0.849695\n",
            "Train Epoch: 9 [18432/45000 (41%)] Loss: 0.976781\n",
            "Train Epoch: 9 [18944/45000 (42%)] Loss: 0.832895\n",
            "Train Epoch: 9 [19456/45000 (43%)] Loss: 0.649684\n",
            "Train Epoch: 9 [19968/45000 (44%)] Loss: 0.880524\n",
            "Train Epoch: 9 [20480/45000 (46%)] Loss: 1.051333\n",
            "Train Epoch: 9 [20992/45000 (47%)] Loss: 0.858568\n",
            "Train Epoch: 9 [21504/45000 (48%)] Loss: 0.798405\n",
            "Train Epoch: 9 [22016/45000 (49%)] Loss: 0.931380\n",
            "Train Epoch: 9 [22528/45000 (50%)] Loss: 0.604038\n",
            "Train Epoch: 9 [23040/45000 (51%)] Loss: 0.881203\n",
            "Train Epoch: 9 [23552/45000 (52%)] Loss: 0.674154\n",
            "Train Epoch: 9 [24064/45000 (53%)] Loss: 0.907522\n",
            "Train Epoch: 9 [24576/45000 (55%)] Loss: 0.783703\n",
            "Train Epoch: 9 [25088/45000 (56%)] Loss: 0.950300\n",
            "Train Epoch: 9 [25600/45000 (57%)] Loss: 0.876299\n",
            "Train Epoch: 9 [26112/45000 (58%)] Loss: 0.865466\n",
            "Train Epoch: 9 [26624/45000 (59%)] Loss: 0.799583\n",
            "Train Epoch: 9 [27136/45000 (60%)] Loss: 0.947650\n",
            "Train Epoch: 9 [27648/45000 (61%)] Loss: 0.893257\n",
            "Train Epoch: 9 [28160/45000 (63%)] Loss: 0.756562\n",
            "Train Epoch: 9 [28672/45000 (64%)] Loss: 0.882626\n",
            "Train Epoch: 9 [29184/45000 (65%)] Loss: 0.706433\n",
            "Train Epoch: 9 [29696/45000 (66%)] Loss: 0.771185\n",
            "Train Epoch: 9 [30208/45000 (67%)] Loss: 0.769360\n",
            "Train Epoch: 9 [30720/45000 (68%)] Loss: 0.792646\n",
            "Train Epoch: 9 [31232/45000 (69%)] Loss: 0.673562\n",
            "Train Epoch: 9 [31744/45000 (71%)] Loss: 0.815892\n",
            "Train Epoch: 9 [32256/45000 (72%)] Loss: 0.926825\n",
            "Train Epoch: 9 [32768/45000 (73%)] Loss: 0.685500\n",
            "Train Epoch: 9 [33280/45000 (74%)] Loss: 0.840029\n",
            "Train Epoch: 9 [33792/45000 (75%)] Loss: 0.776110\n",
            "Train Epoch: 9 [34304/45000 (76%)] Loss: 0.934313\n",
            "Train Epoch: 9 [34816/45000 (77%)] Loss: 1.063570\n",
            "Train Epoch: 9 [35328/45000 (79%)] Loss: 0.757244\n",
            "Train Epoch: 9 [35840/45000 (80%)] Loss: 0.578892\n",
            "Train Epoch: 9 [36352/45000 (81%)] Loss: 0.868607\n",
            "Train Epoch: 9 [36864/45000 (82%)] Loss: 0.781782\n",
            "Train Epoch: 9 [37376/45000 (83%)] Loss: 0.716172\n",
            "Train Epoch: 9 [37888/45000 (84%)] Loss: 0.642687\n",
            "Train Epoch: 9 [38400/45000 (85%)] Loss: 0.710266\n",
            "Train Epoch: 9 [38912/45000 (86%)] Loss: 0.915380\n",
            "Train Epoch: 9 [39424/45000 (88%)] Loss: 0.864469\n",
            "Train Epoch: 9 [39936/45000 (89%)] Loss: 0.792200\n",
            "Train Epoch: 9 [40448/45000 (90%)] Loss: 1.002126\n",
            "Train Epoch: 9 [40960/45000 (91%)] Loss: 0.804276\n",
            "Train Epoch: 9 [41472/45000 (92%)] Loss: 0.947266\n",
            "Train Epoch: 9 [41984/45000 (93%)] Loss: 0.948605\n",
            "Train Epoch: 9 [42496/45000 (94%)] Loss: 0.884052\n",
            "Train Epoch: 9 [43008/45000 (96%)] Loss: 0.888031\n",
            "Train Epoch: 9 [43520/45000 (97%)] Loss: 0.876159\n",
            "Train Epoch: 9 [44032/45000 (98%)] Loss: 1.080323\n",
            "Train Epoch: 9 [44544/45000 (99%)] Loss: 0.890926\n",
            "    epoch          : 9\n",
            "    loss           : 0.7873637750321492\n",
            "    accuracy       : 72.80717329545455\n",
            "    val_loss       : 0.8718776174738437\n",
            "    val_accuracy   : 70.15427215189874\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch9.pth ...\n",
            "Train Epoch: 10 [0/45000 (0%)] Loss: 0.869363\n",
            "Train Epoch: 10 [512/45000 (1%)] Loss: 0.848737\n",
            "Train Epoch: 10 [1024/45000 (2%)] Loss: 0.816153\n",
            "Train Epoch: 10 [1536/45000 (3%)] Loss: 0.993732\n",
            "Train Epoch: 10 [2048/45000 (5%)] Loss: 0.722200\n",
            "Train Epoch: 10 [2560/45000 (6%)] Loss: 0.646518\n",
            "Train Epoch: 10 [3072/45000 (7%)] Loss: 0.828948\n",
            "Train Epoch: 10 [3584/45000 (8%)] Loss: 0.733590\n",
            "Train Epoch: 10 [4096/45000 (9%)] Loss: 0.579854\n",
            "Train Epoch: 10 [4608/45000 (10%)] Loss: 0.717689\n",
            "Train Epoch: 10 [5120/45000 (11%)] Loss: 0.765814\n",
            "Train Epoch: 10 [5632/45000 (13%)] Loss: 0.598656\n",
            "Train Epoch: 10 [6144/45000 (14%)] Loss: 0.639442\n",
            "Train Epoch: 10 [6656/45000 (15%)] Loss: 0.818897\n",
            "Train Epoch: 10 [7168/45000 (16%)] Loss: 0.843293\n",
            "Train Epoch: 10 [7680/45000 (17%)] Loss: 0.734062\n",
            "Train Epoch: 10 [8192/45000 (18%)] Loss: 0.829415\n",
            "Train Epoch: 10 [8704/45000 (19%)] Loss: 0.806223\n",
            "Train Epoch: 10 [9216/45000 (20%)] Loss: 0.789586\n",
            "Train Epoch: 10 [9728/45000 (22%)] Loss: 0.725930\n",
            "Train Epoch: 10 [10240/45000 (23%)] Loss: 0.817961\n",
            "Train Epoch: 10 [10752/45000 (24%)] Loss: 0.599361\n",
            "Train Epoch: 10 [11264/45000 (25%)] Loss: 0.619845\n",
            "Train Epoch: 10 [11776/45000 (26%)] Loss: 0.811701\n",
            "Train Epoch: 10 [12288/45000 (27%)] Loss: 0.702598\n",
            "Train Epoch: 10 [12800/45000 (28%)] Loss: 0.678747\n",
            "Train Epoch: 10 [13312/45000 (30%)] Loss: 0.551424\n",
            "Train Epoch: 10 [13824/45000 (31%)] Loss: 0.754634\n",
            "Train Epoch: 10 [14336/45000 (32%)] Loss: 0.783604\n",
            "Train Epoch: 10 [14848/45000 (33%)] Loss: 0.591704\n",
            "Train Epoch: 10 [15360/45000 (34%)] Loss: 0.633308\n",
            "Train Epoch: 10 [15872/45000 (35%)] Loss: 0.916583\n",
            "Train Epoch: 10 [16384/45000 (36%)] Loss: 0.773821\n",
            "Train Epoch: 10 [16896/45000 (38%)] Loss: 0.889144\n",
            "Train Epoch: 10 [17408/45000 (39%)] Loss: 0.657016\n",
            "Train Epoch: 10 [17920/45000 (40%)] Loss: 0.722745\n",
            "Train Epoch: 10 [18432/45000 (41%)] Loss: 0.621668\n",
            "Train Epoch: 10 [18944/45000 (42%)] Loss: 0.642763\n",
            "Train Epoch: 10 [19456/45000 (43%)] Loss: 0.890420\n",
            "Train Epoch: 10 [19968/45000 (44%)] Loss: 0.772124\n",
            "Train Epoch: 10 [20480/45000 (46%)] Loss: 0.964187\n",
            "Train Epoch: 10 [20992/45000 (47%)] Loss: 0.538453\n",
            "Train Epoch: 10 [21504/45000 (48%)] Loss: 0.751757\n",
            "Train Epoch: 10 [22016/45000 (49%)] Loss: 0.752419\n",
            "Train Epoch: 10 [22528/45000 (50%)] Loss: 0.836181\n",
            "Train Epoch: 10 [23040/45000 (51%)] Loss: 0.821895\n",
            "Train Epoch: 10 [23552/45000 (52%)] Loss: 0.905418\n",
            "Train Epoch: 10 [24064/45000 (53%)] Loss: 0.907017\n",
            "Train Epoch: 10 [24576/45000 (55%)] Loss: 0.814331\n",
            "Train Epoch: 10 [25088/45000 (56%)] Loss: 0.779742\n",
            "Train Epoch: 10 [25600/45000 (57%)] Loss: 0.731929\n",
            "Train Epoch: 10 [26112/45000 (58%)] Loss: 0.879954\n",
            "Train Epoch: 10 [26624/45000 (59%)] Loss: 0.786659\n",
            "Train Epoch: 10 [27136/45000 (60%)] Loss: 0.645374\n",
            "Train Epoch: 10 [27648/45000 (61%)] Loss: 0.846139\n",
            "Train Epoch: 10 [28160/45000 (63%)] Loss: 0.683849\n",
            "Train Epoch: 10 [28672/45000 (64%)] Loss: 0.763175\n",
            "Train Epoch: 10 [29184/45000 (65%)] Loss: 0.677445\n",
            "Train Epoch: 10 [29696/45000 (66%)] Loss: 0.750149\n",
            "Train Epoch: 10 [30208/45000 (67%)] Loss: 0.731281\n",
            "Train Epoch: 10 [30720/45000 (68%)] Loss: 0.605768\n",
            "Train Epoch: 10 [31232/45000 (69%)] Loss: 0.722530\n",
            "Train Epoch: 10 [31744/45000 (71%)] Loss: 0.863577\n",
            "Train Epoch: 10 [32256/45000 (72%)] Loss: 0.879058\n",
            "Train Epoch: 10 [32768/45000 (73%)] Loss: 0.716383\n",
            "Train Epoch: 10 [33280/45000 (74%)] Loss: 0.585402\n",
            "Train Epoch: 10 [33792/45000 (75%)] Loss: 0.677451\n",
            "Train Epoch: 10 [34304/45000 (76%)] Loss: 0.841934\n",
            "Train Epoch: 10 [34816/45000 (77%)] Loss: 0.765515\n",
            "Train Epoch: 10 [35328/45000 (79%)] Loss: 0.819469\n",
            "Train Epoch: 10 [35840/45000 (80%)] Loss: 0.865683\n",
            "Train Epoch: 10 [36352/45000 (81%)] Loss: 0.684077\n",
            "Train Epoch: 10 [36864/45000 (82%)] Loss: 0.551596\n",
            "Train Epoch: 10 [37376/45000 (83%)] Loss: 0.801947\n",
            "Train Epoch: 10 [37888/45000 (84%)] Loss: 0.517090\n",
            "Train Epoch: 10 [38400/45000 (85%)] Loss: 0.573881\n",
            "Train Epoch: 10 [38912/45000 (86%)] Loss: 0.977119\n",
            "Train Epoch: 10 [39424/45000 (88%)] Loss: 0.845950\n",
            "Train Epoch: 10 [39936/45000 (89%)] Loss: 0.706098\n",
            "Train Epoch: 10 [40448/45000 (90%)] Loss: 0.862687\n",
            "Train Epoch: 10 [40960/45000 (91%)] Loss: 0.686640\n",
            "Train Epoch: 10 [41472/45000 (92%)] Loss: 0.752542\n",
            "Train Epoch: 10 [41984/45000 (93%)] Loss: 0.682618\n",
            "Train Epoch: 10 [42496/45000 (94%)] Loss: 0.504593\n",
            "Train Epoch: 10 [43008/45000 (96%)] Loss: 0.694412\n",
            "Train Epoch: 10 [43520/45000 (97%)] Loss: 0.574233\n",
            "Train Epoch: 10 [44032/45000 (98%)] Loss: 0.755647\n",
            "Train Epoch: 10 [44544/45000 (99%)] Loss: 0.687130\n",
            "    epoch          : 10\n",
            "    loss           : 0.766764284492555\n",
            "    accuracy       : 73.41530539772727\n",
            "    val_loss       : 0.8781672874583474\n",
            "    val_accuracy   : 69.67958860759494\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch10.pth ...\n",
            "Train Epoch: 11 [0/45000 (0%)] Loss: 0.692285\n",
            "Train Epoch: 11 [512/45000 (1%)] Loss: 1.019063\n",
            "Train Epoch: 11 [1024/45000 (2%)] Loss: 0.650108\n",
            "Train Epoch: 11 [1536/45000 (3%)] Loss: 0.788971\n",
            "Train Epoch: 11 [2048/45000 (5%)] Loss: 0.693047\n",
            "Train Epoch: 11 [2560/45000 (6%)] Loss: 0.724418\n",
            "Train Epoch: 11 [3072/45000 (7%)] Loss: 0.630047\n",
            "Train Epoch: 11 [3584/45000 (8%)] Loss: 0.730763\n",
            "Train Epoch: 11 [4096/45000 (9%)] Loss: 0.627384\n",
            "Train Epoch: 11 [4608/45000 (10%)] Loss: 0.582881\n",
            "Train Epoch: 11 [5120/45000 (11%)] Loss: 0.807089\n",
            "Train Epoch: 11 [5632/45000 (13%)] Loss: 0.641419\n",
            "Train Epoch: 11 [6144/45000 (14%)] Loss: 1.084832\n",
            "Train Epoch: 11 [6656/45000 (15%)] Loss: 0.498150\n",
            "Train Epoch: 11 [7168/45000 (16%)] Loss: 0.823541\n",
            "Train Epoch: 11 [7680/45000 (17%)] Loss: 0.758633\n",
            "Train Epoch: 11 [8192/45000 (18%)] Loss: 0.747254\n",
            "Train Epoch: 11 [8704/45000 (19%)] Loss: 0.615316\n",
            "Train Epoch: 11 [9216/45000 (20%)] Loss: 0.762756\n",
            "Train Epoch: 11 [9728/45000 (22%)] Loss: 0.565557\n",
            "Train Epoch: 11 [10240/45000 (23%)] Loss: 0.765769\n",
            "Train Epoch: 11 [10752/45000 (24%)] Loss: 0.736185\n",
            "Train Epoch: 11 [11264/45000 (25%)] Loss: 0.670564\n",
            "Train Epoch: 11 [11776/45000 (26%)] Loss: 0.742047\n",
            "Train Epoch: 11 [12288/45000 (27%)] Loss: 0.633356\n",
            "Train Epoch: 11 [12800/45000 (28%)] Loss: 0.858950\n",
            "Train Epoch: 11 [13312/45000 (30%)] Loss: 1.127808\n",
            "Train Epoch: 11 [13824/45000 (31%)] Loss: 0.822535\n",
            "Train Epoch: 11 [14336/45000 (32%)] Loss: 0.722928\n",
            "Train Epoch: 11 [14848/45000 (33%)] Loss: 1.057888\n",
            "Train Epoch: 11 [15360/45000 (34%)] Loss: 0.763711\n",
            "Train Epoch: 11 [15872/45000 (35%)] Loss: 0.810504\n",
            "Train Epoch: 11 [16384/45000 (36%)] Loss: 0.922847\n",
            "Train Epoch: 11 [16896/45000 (38%)] Loss: 0.534226\n",
            "Train Epoch: 11 [17408/45000 (39%)] Loss: 1.056280\n",
            "Train Epoch: 11 [17920/45000 (40%)] Loss: 0.673513\n",
            "Train Epoch: 11 [18432/45000 (41%)] Loss: 0.810797\n",
            "Train Epoch: 11 [18944/45000 (42%)] Loss: 0.608269\n",
            "Train Epoch: 11 [19456/45000 (43%)] Loss: 0.909739\n",
            "Train Epoch: 11 [19968/45000 (44%)] Loss: 0.820788\n",
            "Train Epoch: 11 [20480/45000 (46%)] Loss: 0.694899\n",
            "Train Epoch: 11 [20992/45000 (47%)] Loss: 0.671759\n",
            "Train Epoch: 11 [21504/45000 (48%)] Loss: 0.822016\n",
            "Train Epoch: 11 [22016/45000 (49%)] Loss: 0.687281\n",
            "Train Epoch: 11 [22528/45000 (50%)] Loss: 0.649122\n",
            "Train Epoch: 11 [23040/45000 (51%)] Loss: 0.608128\n",
            "Train Epoch: 11 [23552/45000 (52%)] Loss: 0.825438\n",
            "Train Epoch: 11 [24064/45000 (53%)] Loss: 0.796928\n",
            "Train Epoch: 11 [24576/45000 (55%)] Loss: 0.754651\n",
            "Train Epoch: 11 [25088/45000 (56%)] Loss: 0.716265\n",
            "Train Epoch: 11 [25600/45000 (57%)] Loss: 0.510308\n",
            "Train Epoch: 11 [26112/45000 (58%)] Loss: 0.890554\n",
            "Train Epoch: 11 [26624/45000 (59%)] Loss: 0.777323\n",
            "Train Epoch: 11 [27136/45000 (60%)] Loss: 0.884767\n",
            "Train Epoch: 11 [27648/45000 (61%)] Loss: 0.390490\n",
            "Train Epoch: 11 [28160/45000 (63%)] Loss: 0.589895\n",
            "Train Epoch: 11 [28672/45000 (64%)] Loss: 0.559467\n",
            "Train Epoch: 11 [29184/45000 (65%)] Loss: 0.651397\n",
            "Train Epoch: 11 [29696/45000 (66%)] Loss: 0.669463\n",
            "Train Epoch: 11 [30208/45000 (67%)] Loss: 0.633369\n",
            "Train Epoch: 11 [30720/45000 (68%)] Loss: 0.859753\n",
            "Train Epoch: 11 [31232/45000 (69%)] Loss: 0.870030\n",
            "Train Epoch: 11 [31744/45000 (71%)] Loss: 0.663623\n",
            "Train Epoch: 11 [32256/45000 (72%)] Loss: 0.841237\n",
            "Train Epoch: 11 [32768/45000 (73%)] Loss: 0.680093\n",
            "Train Epoch: 11 [33280/45000 (74%)] Loss: 0.745855\n",
            "Train Epoch: 11 [33792/45000 (75%)] Loss: 0.756781\n",
            "Train Epoch: 11 [34304/45000 (76%)] Loss: 0.643566\n",
            "Train Epoch: 11 [34816/45000 (77%)] Loss: 0.796813\n",
            "Train Epoch: 11 [35328/45000 (79%)] Loss: 0.713590\n",
            "Train Epoch: 11 [35840/45000 (80%)] Loss: 0.883361\n",
            "Train Epoch: 11 [36352/45000 (81%)] Loss: 0.829898\n",
            "Train Epoch: 11 [36864/45000 (82%)] Loss: 0.842614\n",
            "Train Epoch: 11 [37376/45000 (83%)] Loss: 1.039573\n",
            "Train Epoch: 11 [37888/45000 (84%)] Loss: 0.741277\n",
            "Train Epoch: 11 [38400/45000 (85%)] Loss: 0.742368\n",
            "Train Epoch: 11 [38912/45000 (86%)] Loss: 0.593297\n",
            "Train Epoch: 11 [39424/45000 (88%)] Loss: 0.955206\n",
            "Train Epoch: 11 [39936/45000 (89%)] Loss: 0.848552\n",
            "Train Epoch: 11 [40448/45000 (90%)] Loss: 0.594216\n",
            "Train Epoch: 11 [40960/45000 (91%)] Loss: 0.700563\n",
            "Train Epoch: 11 [41472/45000 (92%)] Loss: 0.583247\n",
            "Train Epoch: 11 [41984/45000 (93%)] Loss: 0.599779\n",
            "Train Epoch: 11 [42496/45000 (94%)] Loss: 0.735716\n",
            "Train Epoch: 11 [43008/45000 (96%)] Loss: 0.606761\n",
            "Train Epoch: 11 [43520/45000 (97%)] Loss: 0.891984\n",
            "Train Epoch: 11 [44032/45000 (98%)] Loss: 0.760126\n",
            "Train Epoch: 11 [44544/45000 (99%)] Loss: 1.070015\n",
            "    epoch          : 11\n",
            "    loss           : 0.7482710390097715\n",
            "    accuracy       : 74.0478515625\n",
            "    val_loss       : 0.7774750688407994\n",
            "    val_accuracy   : 71.99367088607595\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch11.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 12 [0/45000 (0%)] Loss: 0.700597\n",
            "Train Epoch: 12 [512/45000 (1%)] Loss: 0.738993\n",
            "Train Epoch: 12 [1024/45000 (2%)] Loss: 0.726731\n",
            "Train Epoch: 12 [1536/45000 (3%)] Loss: 0.681832\n",
            "Train Epoch: 12 [2048/45000 (5%)] Loss: 0.733254\n",
            "Train Epoch: 12 [2560/45000 (6%)] Loss: 0.877796\n",
            "Train Epoch: 12 [3072/45000 (7%)] Loss: 0.639081\n",
            "Train Epoch: 12 [3584/45000 (8%)] Loss: 0.675199\n",
            "Train Epoch: 12 [4096/45000 (9%)] Loss: 0.706367\n",
            "Train Epoch: 12 [4608/45000 (10%)] Loss: 0.838013\n",
            "Train Epoch: 12 [5120/45000 (11%)] Loss: 0.608137\n",
            "Train Epoch: 12 [5632/45000 (13%)] Loss: 0.708424\n",
            "Train Epoch: 12 [6144/45000 (14%)] Loss: 0.472996\n",
            "Train Epoch: 12 [6656/45000 (15%)] Loss: 0.897968\n",
            "Train Epoch: 12 [7168/45000 (16%)] Loss: 0.665977\n",
            "Train Epoch: 12 [7680/45000 (17%)] Loss: 0.864088\n",
            "Train Epoch: 12 [8192/45000 (18%)] Loss: 0.829492\n",
            "Train Epoch: 12 [8704/45000 (19%)] Loss: 0.728686\n",
            "Train Epoch: 12 [9216/45000 (20%)] Loss: 0.717771\n",
            "Train Epoch: 12 [9728/45000 (22%)] Loss: 0.771988\n",
            "Train Epoch: 12 [10240/45000 (23%)] Loss: 0.571981\n",
            "Train Epoch: 12 [10752/45000 (24%)] Loss: 0.711648\n",
            "Train Epoch: 12 [11264/45000 (25%)] Loss: 0.651613\n",
            "Train Epoch: 12 [11776/45000 (26%)] Loss: 0.858364\n",
            "Train Epoch: 12 [12288/45000 (27%)] Loss: 0.504978\n",
            "Train Epoch: 12 [12800/45000 (28%)] Loss: 0.626715\n",
            "Train Epoch: 12 [13312/45000 (30%)] Loss: 0.862560\n",
            "Train Epoch: 12 [13824/45000 (31%)] Loss: 0.685332\n",
            "Train Epoch: 12 [14336/45000 (32%)] Loss: 0.587726\n",
            "Train Epoch: 12 [14848/45000 (33%)] Loss: 0.631667\n",
            "Train Epoch: 12 [15360/45000 (34%)] Loss: 0.573887\n",
            "Train Epoch: 12 [15872/45000 (35%)] Loss: 0.554532\n",
            "Train Epoch: 12 [16384/45000 (36%)] Loss: 0.806256\n",
            "Train Epoch: 12 [16896/45000 (38%)] Loss: 0.656554\n",
            "Train Epoch: 12 [17408/45000 (39%)] Loss: 0.473233\n",
            "Train Epoch: 12 [17920/45000 (40%)] Loss: 0.716460\n",
            "Train Epoch: 12 [18432/45000 (41%)] Loss: 0.929058\n",
            "Train Epoch: 12 [18944/45000 (42%)] Loss: 0.742035\n",
            "Train Epoch: 12 [19456/45000 (43%)] Loss: 0.755460\n",
            "Train Epoch: 12 [19968/45000 (44%)] Loss: 0.573651\n",
            "Train Epoch: 12 [20480/45000 (46%)] Loss: 0.966203\n",
            "Train Epoch: 12 [20992/45000 (47%)] Loss: 0.631412\n",
            "Train Epoch: 12 [21504/45000 (48%)] Loss: 0.967446\n",
            "Train Epoch: 12 [22016/45000 (49%)] Loss: 0.821061\n",
            "Train Epoch: 12 [22528/45000 (50%)] Loss: 0.488782\n",
            "Train Epoch: 12 [23040/45000 (51%)] Loss: 0.560180\n",
            "Train Epoch: 12 [23552/45000 (52%)] Loss: 0.692273\n",
            "Train Epoch: 12 [24064/45000 (53%)] Loss: 0.797503\n",
            "Train Epoch: 12 [24576/45000 (55%)] Loss: 0.637679\n",
            "Train Epoch: 12 [25088/45000 (56%)] Loss: 0.779002\n",
            "Train Epoch: 12 [25600/45000 (57%)] Loss: 0.588356\n",
            "Train Epoch: 12 [26112/45000 (58%)] Loss: 0.455427\n",
            "Train Epoch: 12 [26624/45000 (59%)] Loss: 0.792379\n",
            "Train Epoch: 12 [27136/45000 (60%)] Loss: 0.791377\n",
            "Train Epoch: 12 [27648/45000 (61%)] Loss: 0.822487\n",
            "Train Epoch: 12 [28160/45000 (63%)] Loss: 0.876145\n",
            "Train Epoch: 12 [28672/45000 (64%)] Loss: 0.741199\n",
            "Train Epoch: 12 [29184/45000 (65%)] Loss: 0.698394\n",
            "Train Epoch: 12 [29696/45000 (66%)] Loss: 0.824717\n",
            "Train Epoch: 12 [30208/45000 (67%)] Loss: 0.710444\n",
            "Train Epoch: 12 [30720/45000 (68%)] Loss: 0.882794\n",
            "Train Epoch: 12 [31232/45000 (69%)] Loss: 1.050476\n",
            "Train Epoch: 12 [31744/45000 (71%)] Loss: 0.982400\n",
            "Train Epoch: 12 [32256/45000 (72%)] Loss: 0.779131\n",
            "Train Epoch: 12 [32768/45000 (73%)] Loss: 0.637789\n",
            "Train Epoch: 12 [33280/45000 (74%)] Loss: 0.814917\n",
            "Train Epoch: 12 [33792/45000 (75%)] Loss: 0.722885\n",
            "Train Epoch: 12 [34304/45000 (76%)] Loss: 1.043825\n",
            "Train Epoch: 12 [34816/45000 (77%)] Loss: 0.926995\n",
            "Train Epoch: 12 [35328/45000 (79%)] Loss: 0.739783\n",
            "Train Epoch: 12 [35840/45000 (80%)] Loss: 0.852643\n",
            "Train Epoch: 12 [36352/45000 (81%)] Loss: 0.867387\n",
            "Train Epoch: 12 [36864/45000 (82%)] Loss: 0.845360\n",
            "Train Epoch: 12 [37376/45000 (83%)] Loss: 0.584378\n",
            "Train Epoch: 12 [37888/45000 (84%)] Loss: 0.850842\n",
            "Train Epoch: 12 [38400/45000 (85%)] Loss: 0.772597\n",
            "Train Epoch: 12 [38912/45000 (86%)] Loss: 0.715910\n",
            "Train Epoch: 12 [39424/45000 (88%)] Loss: 0.642835\n",
            "Train Epoch: 12 [39936/45000 (89%)] Loss: 0.727410\n",
            "Train Epoch: 12 [40448/45000 (90%)] Loss: 0.671234\n",
            "Train Epoch: 12 [40960/45000 (91%)] Loss: 0.772671\n",
            "Train Epoch: 12 [41472/45000 (92%)] Loss: 0.651324\n",
            "Train Epoch: 12 [41984/45000 (93%)] Loss: 0.674281\n",
            "Train Epoch: 12 [42496/45000 (94%)] Loss: 0.773304\n",
            "Train Epoch: 12 [43008/45000 (96%)] Loss: 0.773130\n",
            "Train Epoch: 12 [43520/45000 (97%)] Loss: 0.741179\n",
            "Train Epoch: 12 [44032/45000 (98%)] Loss: 0.458390\n",
            "Train Epoch: 12 [44544/45000 (99%)] Loss: 0.415862\n",
            "    epoch          : 12\n",
            "    loss           : 0.7324320590123534\n",
            "    accuracy       : 74.58274147727273\n",
            "    val_loss       : 0.7537890219990211\n",
            "    val_accuracy   : 74.46598101265823\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch12.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 13 [0/45000 (0%)] Loss: 0.811776\n",
            "Train Epoch: 13 [512/45000 (1%)] Loss: 0.703076\n",
            "Train Epoch: 13 [1024/45000 (2%)] Loss: 0.829450\n",
            "Train Epoch: 13 [1536/45000 (3%)] Loss: 0.700675\n",
            "Train Epoch: 13 [2048/45000 (5%)] Loss: 0.757280\n",
            "Train Epoch: 13 [2560/45000 (6%)] Loss: 0.735418\n",
            "Train Epoch: 13 [3072/45000 (7%)] Loss: 0.823212\n",
            "Train Epoch: 13 [3584/45000 (8%)] Loss: 0.725597\n",
            "Train Epoch: 13 [4096/45000 (9%)] Loss: 0.561860\n",
            "Train Epoch: 13 [4608/45000 (10%)] Loss: 0.771620\n",
            "Train Epoch: 13 [5120/45000 (11%)] Loss: 0.800113\n",
            "Train Epoch: 13 [5632/45000 (13%)] Loss: 0.504129\n",
            "Train Epoch: 13 [6144/45000 (14%)] Loss: 0.673855\n",
            "Train Epoch: 13 [6656/45000 (15%)] Loss: 0.604829\n",
            "Train Epoch: 13 [7168/45000 (16%)] Loss: 0.948068\n",
            "Train Epoch: 13 [7680/45000 (17%)] Loss: 0.675264\n",
            "Train Epoch: 13 [8192/45000 (18%)] Loss: 1.029482\n",
            "Train Epoch: 13 [8704/45000 (19%)] Loss: 0.955860\n",
            "Train Epoch: 13 [9216/45000 (20%)] Loss: 0.816460\n",
            "Train Epoch: 13 [9728/45000 (22%)] Loss: 0.661682\n",
            "Train Epoch: 13 [10240/45000 (23%)] Loss: 0.600979\n",
            "Train Epoch: 13 [10752/45000 (24%)] Loss: 0.552806\n",
            "Train Epoch: 13 [11264/45000 (25%)] Loss: 0.717228\n",
            "Train Epoch: 13 [11776/45000 (26%)] Loss: 0.837084\n",
            "Train Epoch: 13 [12288/45000 (27%)] Loss: 0.840387\n",
            "Train Epoch: 13 [12800/45000 (28%)] Loss: 0.691293\n",
            "Train Epoch: 13 [13312/45000 (30%)] Loss: 0.679708\n",
            "Train Epoch: 13 [13824/45000 (31%)] Loss: 0.719984\n",
            "Train Epoch: 13 [14336/45000 (32%)] Loss: 0.639385\n",
            "Train Epoch: 13 [14848/45000 (33%)] Loss: 0.674595\n",
            "Train Epoch: 13 [15360/45000 (34%)] Loss: 0.796578\n",
            "Train Epoch: 13 [15872/45000 (35%)] Loss: 0.882740\n",
            "Train Epoch: 13 [16384/45000 (36%)] Loss: 0.645840\n",
            "Train Epoch: 13 [16896/45000 (38%)] Loss: 0.583582\n",
            "Train Epoch: 13 [17408/45000 (39%)] Loss: 0.590088\n",
            "Train Epoch: 13 [17920/45000 (40%)] Loss: 0.850616\n",
            "Train Epoch: 13 [18432/45000 (41%)] Loss: 0.752116\n",
            "Train Epoch: 13 [18944/45000 (42%)] Loss: 0.781673\n",
            "Train Epoch: 13 [19456/45000 (43%)] Loss: 0.708746\n",
            "Train Epoch: 13 [19968/45000 (44%)] Loss: 0.624169\n",
            "Train Epoch: 13 [20480/45000 (46%)] Loss: 0.824527\n",
            "Train Epoch: 13 [20992/45000 (47%)] Loss: 0.769173\n",
            "Train Epoch: 13 [21504/45000 (48%)] Loss: 0.799026\n",
            "Train Epoch: 13 [22016/45000 (49%)] Loss: 0.561463\n",
            "Train Epoch: 13 [22528/45000 (50%)] Loss: 0.601542\n",
            "Train Epoch: 13 [23040/45000 (51%)] Loss: 0.567078\n",
            "Train Epoch: 13 [23552/45000 (52%)] Loss: 0.633127\n",
            "Train Epoch: 13 [24064/45000 (53%)] Loss: 0.591515\n",
            "Train Epoch: 13 [24576/45000 (55%)] Loss: 0.696205\n",
            "Train Epoch: 13 [25088/45000 (56%)] Loss: 0.887849\n",
            "Train Epoch: 13 [25600/45000 (57%)] Loss: 0.582466\n",
            "Train Epoch: 13 [26112/45000 (58%)] Loss: 0.666859\n",
            "Train Epoch: 13 [26624/45000 (59%)] Loss: 0.530509\n",
            "Train Epoch: 13 [27136/45000 (60%)] Loss: 0.739531\n",
            "Train Epoch: 13 [27648/45000 (61%)] Loss: 0.775655\n",
            "Train Epoch: 13 [28160/45000 (63%)] Loss: 0.726189\n",
            "Train Epoch: 13 [28672/45000 (64%)] Loss: 0.615863\n",
            "Train Epoch: 13 [29184/45000 (65%)] Loss: 0.654034\n",
            "Train Epoch: 13 [29696/45000 (66%)] Loss: 0.499402\n",
            "Train Epoch: 13 [30208/45000 (67%)] Loss: 1.009949\n",
            "Train Epoch: 13 [30720/45000 (68%)] Loss: 0.500219\n",
            "Train Epoch: 13 [31232/45000 (69%)] Loss: 0.545115\n",
            "Train Epoch: 13 [31744/45000 (71%)] Loss: 0.926556\n",
            "Train Epoch: 13 [32256/45000 (72%)] Loss: 0.651331\n",
            "Train Epoch: 13 [32768/45000 (73%)] Loss: 0.697914\n",
            "Train Epoch: 13 [33280/45000 (74%)] Loss: 0.727839\n",
            "Train Epoch: 13 [33792/45000 (75%)] Loss: 0.789415\n",
            "Train Epoch: 13 [34304/45000 (76%)] Loss: 0.668325\n",
            "Train Epoch: 13 [34816/45000 (77%)] Loss: 0.629973\n",
            "Train Epoch: 13 [35328/45000 (79%)] Loss: 0.774984\n",
            "Train Epoch: 13 [35840/45000 (80%)] Loss: 0.978621\n",
            "Train Epoch: 13 [36352/45000 (81%)] Loss: 0.836911\n",
            "Train Epoch: 13 [36864/45000 (82%)] Loss: 0.733382\n",
            "Train Epoch: 13 [37376/45000 (83%)] Loss: 0.594233\n",
            "Train Epoch: 13 [37888/45000 (84%)] Loss: 0.856824\n",
            "Train Epoch: 13 [38400/45000 (85%)] Loss: 0.894323\n",
            "Train Epoch: 13 [38912/45000 (86%)] Loss: 0.686504\n",
            "Train Epoch: 13 [39424/45000 (88%)] Loss: 0.589940\n",
            "Train Epoch: 13 [39936/45000 (89%)] Loss: 0.692101\n",
            "Train Epoch: 13 [40448/45000 (90%)] Loss: 0.730202\n",
            "Train Epoch: 13 [40960/45000 (91%)] Loss: 0.730710\n",
            "Train Epoch: 13 [41472/45000 (92%)] Loss: 0.906531\n",
            "Train Epoch: 13 [41984/45000 (93%)] Loss: 0.830943\n",
            "Train Epoch: 13 [42496/45000 (94%)] Loss: 0.735044\n",
            "Train Epoch: 13 [43008/45000 (96%)] Loss: 0.621391\n",
            "Train Epoch: 13 [43520/45000 (97%)] Loss: 0.726743\n",
            "Train Epoch: 13 [44032/45000 (98%)] Loss: 0.690494\n",
            "Train Epoch: 13 [44544/45000 (99%)] Loss: 0.809280\n",
            "    epoch          : 13\n",
            "    loss           : 0.7159557309933007\n",
            "    accuracy       : 75.24192116477273\n",
            "    val_loss       : 0.8134765470329719\n",
            "    val_accuracy   : 71.7761075949367\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch13.pth ...\n",
            "Train Epoch: 14 [0/45000 (0%)] Loss: 0.580992\n",
            "Train Epoch: 14 [512/45000 (1%)] Loss: 0.853764\n",
            "Train Epoch: 14 [1024/45000 (2%)] Loss: 0.585097\n",
            "Train Epoch: 14 [1536/45000 (3%)] Loss: 0.869964\n",
            "Train Epoch: 14 [2048/45000 (5%)] Loss: 0.888749\n",
            "Train Epoch: 14 [2560/45000 (6%)] Loss: 0.790250\n",
            "Train Epoch: 14 [3072/45000 (7%)] Loss: 0.544401\n",
            "Train Epoch: 14 [3584/45000 (8%)] Loss: 0.444423\n",
            "Train Epoch: 14 [4096/45000 (9%)] Loss: 0.596140\n",
            "Train Epoch: 14 [4608/45000 (10%)] Loss: 0.656474\n",
            "Train Epoch: 14 [5120/45000 (11%)] Loss: 0.523622\n",
            "Train Epoch: 14 [5632/45000 (13%)] Loss: 0.579344\n",
            "Train Epoch: 14 [6144/45000 (14%)] Loss: 0.597719\n",
            "Train Epoch: 14 [6656/45000 (15%)] Loss: 0.811184\n",
            "Train Epoch: 14 [7168/45000 (16%)] Loss: 0.752056\n",
            "Train Epoch: 14 [7680/45000 (17%)] Loss: 0.787878\n",
            "Train Epoch: 14 [8192/45000 (18%)] Loss: 0.546869\n",
            "Train Epoch: 14 [8704/45000 (19%)] Loss: 0.580246\n",
            "Train Epoch: 14 [9216/45000 (20%)] Loss: 0.523142\n",
            "Train Epoch: 14 [9728/45000 (22%)] Loss: 0.854475\n",
            "Train Epoch: 14 [10240/45000 (23%)] Loss: 0.648899\n",
            "Train Epoch: 14 [10752/45000 (24%)] Loss: 0.824315\n",
            "Train Epoch: 14 [11264/45000 (25%)] Loss: 0.704316\n",
            "Train Epoch: 14 [11776/45000 (26%)] Loss: 0.756491\n",
            "Train Epoch: 14 [12288/45000 (27%)] Loss: 0.855682\n",
            "Train Epoch: 14 [12800/45000 (28%)] Loss: 0.639598\n",
            "Train Epoch: 14 [13312/45000 (30%)] Loss: 0.672883\n",
            "Train Epoch: 14 [13824/45000 (31%)] Loss: 0.589460\n",
            "Train Epoch: 14 [14336/45000 (32%)] Loss: 0.525200\n",
            "Train Epoch: 14 [14848/45000 (33%)] Loss: 0.684336\n",
            "Train Epoch: 14 [15360/45000 (34%)] Loss: 0.640287\n",
            "Train Epoch: 14 [15872/45000 (35%)] Loss: 0.719689\n",
            "Train Epoch: 14 [16384/45000 (36%)] Loss: 0.654070\n",
            "Train Epoch: 14 [16896/45000 (38%)] Loss: 0.614559\n",
            "Train Epoch: 14 [17408/45000 (39%)] Loss: 0.670269\n",
            "Train Epoch: 14 [17920/45000 (40%)] Loss: 0.640322\n",
            "Train Epoch: 14 [18432/45000 (41%)] Loss: 0.577467\n",
            "Train Epoch: 14 [18944/45000 (42%)] Loss: 0.653710\n",
            "Train Epoch: 14 [19456/45000 (43%)] Loss: 0.818385\n",
            "Train Epoch: 14 [19968/45000 (44%)] Loss: 0.432701\n",
            "Train Epoch: 14 [20480/45000 (46%)] Loss: 0.668487\n",
            "Train Epoch: 14 [20992/45000 (47%)] Loss: 0.492920\n",
            "Train Epoch: 14 [21504/45000 (48%)] Loss: 0.679375\n",
            "Train Epoch: 14 [22016/45000 (49%)] Loss: 0.550683\n",
            "Train Epoch: 14 [22528/45000 (50%)] Loss: 0.663947\n",
            "Train Epoch: 14 [23040/45000 (51%)] Loss: 0.709038\n",
            "Train Epoch: 14 [23552/45000 (52%)] Loss: 0.883025\n",
            "Train Epoch: 14 [24064/45000 (53%)] Loss: 0.487076\n",
            "Train Epoch: 14 [24576/45000 (55%)] Loss: 0.582386\n",
            "Train Epoch: 14 [25088/45000 (56%)] Loss: 0.591659\n",
            "Train Epoch: 14 [25600/45000 (57%)] Loss: 0.797647\n",
            "Train Epoch: 14 [26112/45000 (58%)] Loss: 1.111934\n",
            "Train Epoch: 14 [26624/45000 (59%)] Loss: 0.713840\n",
            "Train Epoch: 14 [27136/45000 (60%)] Loss: 0.626954\n",
            "Train Epoch: 14 [27648/45000 (61%)] Loss: 0.741877\n",
            "Train Epoch: 14 [28160/45000 (63%)] Loss: 0.774936\n",
            "Train Epoch: 14 [28672/45000 (64%)] Loss: 0.630896\n",
            "Train Epoch: 14 [29184/45000 (65%)] Loss: 0.626111\n",
            "Train Epoch: 14 [29696/45000 (66%)] Loss: 0.727676\n",
            "Train Epoch: 14 [30208/45000 (67%)] Loss: 0.717721\n",
            "Train Epoch: 14 [30720/45000 (68%)] Loss: 0.707871\n",
            "Train Epoch: 14 [31232/45000 (69%)] Loss: 0.579531\n",
            "Train Epoch: 14 [31744/45000 (71%)] Loss: 0.767613\n",
            "Train Epoch: 14 [32256/45000 (72%)] Loss: 0.724164\n",
            "Train Epoch: 14 [32768/45000 (73%)] Loss: 0.434382\n",
            "Train Epoch: 14 [33280/45000 (74%)] Loss: 0.750236\n",
            "Train Epoch: 14 [33792/45000 (75%)] Loss: 0.836167\n",
            "Train Epoch: 14 [34304/45000 (76%)] Loss: 0.684056\n",
            "Train Epoch: 14 [34816/45000 (77%)] Loss: 0.936630\n",
            "Train Epoch: 14 [35328/45000 (79%)] Loss: 0.738816\n",
            "Train Epoch: 14 [35840/45000 (80%)] Loss: 0.788173\n",
            "Train Epoch: 14 [36352/45000 (81%)] Loss: 0.795019\n",
            "Train Epoch: 14 [36864/45000 (82%)] Loss: 0.741331\n",
            "Train Epoch: 14 [37376/45000 (83%)] Loss: 0.536619\n",
            "Train Epoch: 14 [37888/45000 (84%)] Loss: 0.778510\n",
            "Train Epoch: 14 [38400/45000 (85%)] Loss: 0.708471\n",
            "Train Epoch: 14 [38912/45000 (86%)] Loss: 0.618273\n",
            "Train Epoch: 14 [39424/45000 (88%)] Loss: 0.418942\n",
            "Train Epoch: 14 [39936/45000 (89%)] Loss: 0.651906\n",
            "Train Epoch: 14 [40448/45000 (90%)] Loss: 0.693415\n",
            "Train Epoch: 14 [40960/45000 (91%)] Loss: 0.727323\n",
            "Train Epoch: 14 [41472/45000 (92%)] Loss: 0.562020\n",
            "Train Epoch: 14 [41984/45000 (93%)] Loss: 0.840892\n",
            "Train Epoch: 14 [42496/45000 (94%)] Loss: 0.747304\n",
            "Train Epoch: 14 [43008/45000 (96%)] Loss: 0.660418\n",
            "Train Epoch: 14 [43520/45000 (97%)] Loss: 0.515610\n",
            "Train Epoch: 14 [44032/45000 (98%)] Loss: 0.768181\n",
            "Train Epoch: 14 [44544/45000 (99%)] Loss: 0.839147\n",
            "    epoch          : 14\n",
            "    loss           : 0.7016678292896937\n",
            "    accuracy       : 75.88112571022727\n",
            "    val_loss       : 0.7794925344141224\n",
            "    val_accuracy   : 73.2001582278481\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch14.pth ...\n",
            "Train Epoch: 15 [0/45000 (0%)] Loss: 0.754486\n",
            "Train Epoch: 15 [512/45000 (1%)] Loss: 0.711025\n",
            "Train Epoch: 15 [1024/45000 (2%)] Loss: 0.867077\n",
            "Train Epoch: 15 [1536/45000 (3%)] Loss: 0.672295\n",
            "Train Epoch: 15 [2048/45000 (5%)] Loss: 0.526810\n",
            "Train Epoch: 15 [2560/45000 (6%)] Loss: 0.817254\n",
            "Train Epoch: 15 [3072/45000 (7%)] Loss: 0.652396\n",
            "Train Epoch: 15 [3584/45000 (8%)] Loss: 0.856840\n",
            "Train Epoch: 15 [4096/45000 (9%)] Loss: 0.640625\n",
            "Train Epoch: 15 [4608/45000 (10%)] Loss: 0.772671\n",
            "Train Epoch: 15 [5120/45000 (11%)] Loss: 0.649480\n",
            "Train Epoch: 15 [5632/45000 (13%)] Loss: 0.756293\n",
            "Train Epoch: 15 [6144/45000 (14%)] Loss: 0.694104\n",
            "Train Epoch: 15 [6656/45000 (15%)] Loss: 0.608054\n",
            "Train Epoch: 15 [7168/45000 (16%)] Loss: 0.781889\n",
            "Train Epoch: 15 [7680/45000 (17%)] Loss: 0.561950\n",
            "Train Epoch: 15 [8192/45000 (18%)] Loss: 0.855404\n",
            "Train Epoch: 15 [8704/45000 (19%)] Loss: 0.743152\n",
            "Train Epoch: 15 [9216/45000 (20%)] Loss: 0.724885\n",
            "Train Epoch: 15 [9728/45000 (22%)] Loss: 0.777960\n",
            "Train Epoch: 15 [10240/45000 (23%)] Loss: 0.538026\n",
            "Train Epoch: 15 [10752/45000 (24%)] Loss: 0.634293\n",
            "Train Epoch: 15 [11264/45000 (25%)] Loss: 0.549191\n",
            "Train Epoch: 15 [11776/45000 (26%)] Loss: 0.812764\n",
            "Train Epoch: 15 [12288/45000 (27%)] Loss: 0.750710\n",
            "Train Epoch: 15 [12800/45000 (28%)] Loss: 0.727001\n",
            "Train Epoch: 15 [13312/45000 (30%)] Loss: 0.884055\n",
            "Train Epoch: 15 [13824/45000 (31%)] Loss: 0.488987\n",
            "Train Epoch: 15 [14336/45000 (32%)] Loss: 0.811194\n",
            "Train Epoch: 15 [14848/45000 (33%)] Loss: 0.646144\n",
            "Train Epoch: 15 [15360/45000 (34%)] Loss: 0.789267\n",
            "Train Epoch: 15 [15872/45000 (35%)] Loss: 0.664020\n",
            "Train Epoch: 15 [16384/45000 (36%)] Loss: 0.816318\n",
            "Train Epoch: 15 [16896/45000 (38%)] Loss: 0.676454\n",
            "Train Epoch: 15 [17408/45000 (39%)] Loss: 0.621621\n",
            "Train Epoch: 15 [17920/45000 (40%)] Loss: 0.737595\n",
            "Train Epoch: 15 [18432/45000 (41%)] Loss: 0.680142\n",
            "Train Epoch: 15 [18944/45000 (42%)] Loss: 0.691590\n",
            "Train Epoch: 15 [19456/45000 (43%)] Loss: 1.031939\n",
            "Train Epoch: 15 [19968/45000 (44%)] Loss: 0.738215\n",
            "Train Epoch: 15 [20480/45000 (46%)] Loss: 0.717778\n",
            "Train Epoch: 15 [20992/45000 (47%)] Loss: 0.631533\n",
            "Train Epoch: 15 [21504/45000 (48%)] Loss: 0.379922\n",
            "Train Epoch: 15 [22016/45000 (49%)] Loss: 0.852740\n",
            "Train Epoch: 15 [22528/45000 (50%)] Loss: 0.766036\n",
            "Train Epoch: 15 [23040/45000 (51%)] Loss: 0.674091\n",
            "Train Epoch: 15 [23552/45000 (52%)] Loss: 0.470886\n",
            "Train Epoch: 15 [24064/45000 (53%)] Loss: 0.720553\n",
            "Train Epoch: 15 [24576/45000 (55%)] Loss: 0.623569\n",
            "Train Epoch: 15 [25088/45000 (56%)] Loss: 0.548316\n",
            "Train Epoch: 15 [25600/45000 (57%)] Loss: 0.725331\n",
            "Train Epoch: 15 [26112/45000 (58%)] Loss: 0.688004\n",
            "Train Epoch: 15 [26624/45000 (59%)] Loss: 0.533049\n",
            "Train Epoch: 15 [27136/45000 (60%)] Loss: 0.765266\n",
            "Train Epoch: 15 [27648/45000 (61%)] Loss: 0.636640\n",
            "Train Epoch: 15 [28160/45000 (63%)] Loss: 0.506932\n",
            "Train Epoch: 15 [28672/45000 (64%)] Loss: 0.902435\n",
            "Train Epoch: 15 [29184/45000 (65%)] Loss: 0.834382\n",
            "Train Epoch: 15 [29696/45000 (66%)] Loss: 0.787496\n",
            "Train Epoch: 15 [30208/45000 (67%)] Loss: 0.743310\n",
            "Train Epoch: 15 [30720/45000 (68%)] Loss: 0.687011\n",
            "Train Epoch: 15 [31232/45000 (69%)] Loss: 0.818717\n",
            "Train Epoch: 15 [31744/45000 (71%)] Loss: 0.606154\n",
            "Train Epoch: 15 [32256/45000 (72%)] Loss: 1.065984\n",
            "Train Epoch: 15 [32768/45000 (73%)] Loss: 0.694804\n",
            "Train Epoch: 15 [33280/45000 (74%)] Loss: 0.736242\n",
            "Train Epoch: 15 [33792/45000 (75%)] Loss: 0.638858\n",
            "Train Epoch: 15 [34304/45000 (76%)] Loss: 0.524571\n",
            "Train Epoch: 15 [34816/45000 (77%)] Loss: 0.787298\n",
            "Train Epoch: 15 [35328/45000 (79%)] Loss: 0.558442\n",
            "Train Epoch: 15 [35840/45000 (80%)] Loss: 0.629567\n",
            "Train Epoch: 15 [36352/45000 (81%)] Loss: 0.909670\n",
            "Train Epoch: 15 [36864/45000 (82%)] Loss: 0.824332\n",
            "Train Epoch: 15 [37376/45000 (83%)] Loss: 0.553299\n",
            "Train Epoch: 15 [37888/45000 (84%)] Loss: 0.898763\n",
            "Train Epoch: 15 [38400/45000 (85%)] Loss: 0.665585\n",
            "Train Epoch: 15 [38912/45000 (86%)] Loss: 0.613532\n",
            "Train Epoch: 15 [39424/45000 (88%)] Loss: 0.666798\n",
            "Train Epoch: 15 [39936/45000 (89%)] Loss: 0.580849\n",
            "Train Epoch: 15 [40448/45000 (90%)] Loss: 0.677337\n",
            "Train Epoch: 15 [40960/45000 (91%)] Loss: 0.660060\n",
            "Train Epoch: 15 [41472/45000 (92%)] Loss: 0.688915\n",
            "Train Epoch: 15 [41984/45000 (93%)] Loss: 0.643362\n",
            "Train Epoch: 15 [42496/45000 (94%)] Loss: 0.819187\n",
            "Train Epoch: 15 [43008/45000 (96%)] Loss: 0.821965\n",
            "Train Epoch: 15 [43520/45000 (97%)] Loss: 0.542811\n",
            "Train Epoch: 15 [44032/45000 (98%)] Loss: 0.803557\n",
            "Train Epoch: 15 [44544/45000 (99%)] Loss: 0.738396\n",
            "    epoch          : 15\n",
            "    loss           : 0.6924121490341019\n",
            "    accuracy       : 76.123046875\n",
            "    val_loss       : 0.7427840640273276\n",
            "    val_accuracy   : 74.16930379746836\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch15.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 16 [0/45000 (0%)] Loss: 0.696537\n",
            "Train Epoch: 16 [512/45000 (1%)] Loss: 0.789695\n",
            "Train Epoch: 16 [1024/45000 (2%)] Loss: 0.819560\n",
            "Train Epoch: 16 [1536/45000 (3%)] Loss: 0.575154\n",
            "Train Epoch: 16 [2048/45000 (5%)] Loss: 0.758758\n",
            "Train Epoch: 16 [2560/45000 (6%)] Loss: 0.716200\n",
            "Train Epoch: 16 [3072/45000 (7%)] Loss: 0.518627\n",
            "Train Epoch: 16 [3584/45000 (8%)] Loss: 0.594373\n",
            "Train Epoch: 16 [4096/45000 (9%)] Loss: 0.668216\n",
            "Train Epoch: 16 [4608/45000 (10%)] Loss: 0.580251\n",
            "Train Epoch: 16 [5120/45000 (11%)] Loss: 0.866337\n",
            "Train Epoch: 16 [5632/45000 (13%)] Loss: 0.797886\n",
            "Train Epoch: 16 [6144/45000 (14%)] Loss: 0.707251\n",
            "Train Epoch: 16 [6656/45000 (15%)] Loss: 0.678593\n",
            "Train Epoch: 16 [7168/45000 (16%)] Loss: 0.546492\n",
            "Train Epoch: 16 [7680/45000 (17%)] Loss: 0.503898\n",
            "Train Epoch: 16 [8192/45000 (18%)] Loss: 0.623601\n",
            "Train Epoch: 16 [8704/45000 (19%)] Loss: 0.454522\n",
            "Train Epoch: 16 [9216/45000 (20%)] Loss: 0.523150\n",
            "Train Epoch: 16 [9728/45000 (22%)] Loss: 0.528580\n",
            "Train Epoch: 16 [10240/45000 (23%)] Loss: 0.645227\n",
            "Train Epoch: 16 [10752/45000 (24%)] Loss: 0.524664\n",
            "Train Epoch: 16 [11264/45000 (25%)] Loss: 0.876822\n",
            "Train Epoch: 16 [11776/45000 (26%)] Loss: 0.528464\n",
            "Train Epoch: 16 [12288/45000 (27%)] Loss: 0.527451\n",
            "Train Epoch: 16 [12800/45000 (28%)] Loss: 0.450297\n",
            "Train Epoch: 16 [13312/45000 (30%)] Loss: 0.808271\n",
            "Train Epoch: 16 [13824/45000 (31%)] Loss: 0.635340\n",
            "Train Epoch: 16 [14336/45000 (32%)] Loss: 0.729362\n",
            "Train Epoch: 16 [14848/45000 (33%)] Loss: 0.503528\n",
            "Train Epoch: 16 [15360/45000 (34%)] Loss: 0.704535\n",
            "Train Epoch: 16 [15872/45000 (35%)] Loss: 0.608654\n",
            "Train Epoch: 16 [16384/45000 (36%)] Loss: 0.553512\n",
            "Train Epoch: 16 [16896/45000 (38%)] Loss: 0.652583\n",
            "Train Epoch: 16 [17408/45000 (39%)] Loss: 0.493609\n",
            "Train Epoch: 16 [17920/45000 (40%)] Loss: 0.461276\n",
            "Train Epoch: 16 [18432/45000 (41%)] Loss: 0.483900\n",
            "Train Epoch: 16 [18944/45000 (42%)] Loss: 0.894227\n",
            "Train Epoch: 16 [19456/45000 (43%)] Loss: 0.611748\n",
            "Train Epoch: 16 [19968/45000 (44%)] Loss: 0.566178\n",
            "Train Epoch: 16 [20480/45000 (46%)] Loss: 0.618209\n",
            "Train Epoch: 16 [20992/45000 (47%)] Loss: 0.465758\n",
            "Train Epoch: 16 [21504/45000 (48%)] Loss: 0.431026\n",
            "Train Epoch: 16 [22016/45000 (49%)] Loss: 0.598579\n",
            "Train Epoch: 16 [22528/45000 (50%)] Loss: 0.677349\n",
            "Train Epoch: 16 [23040/45000 (51%)] Loss: 0.538325\n",
            "Train Epoch: 16 [23552/45000 (52%)] Loss: 0.511336\n",
            "Train Epoch: 16 [24064/45000 (53%)] Loss: 0.943778\n",
            "Train Epoch: 16 [24576/45000 (55%)] Loss: 0.556426\n",
            "Train Epoch: 16 [25088/45000 (56%)] Loss: 0.617425\n",
            "Train Epoch: 16 [25600/45000 (57%)] Loss: 0.460034\n",
            "Train Epoch: 16 [26112/45000 (58%)] Loss: 0.373901\n",
            "Train Epoch: 16 [26624/45000 (59%)] Loss: 0.707755\n",
            "Train Epoch: 16 [27136/45000 (60%)] Loss: 0.477374\n",
            "Train Epoch: 16 [27648/45000 (61%)] Loss: 0.687964\n",
            "Train Epoch: 16 [28160/45000 (63%)] Loss: 0.374192\n",
            "Train Epoch: 16 [28672/45000 (64%)] Loss: 0.491388\n",
            "Train Epoch: 16 [29184/45000 (65%)] Loss: 0.507095\n",
            "Train Epoch: 16 [29696/45000 (66%)] Loss: 0.423143\n",
            "Train Epoch: 16 [30208/45000 (67%)] Loss: 0.531419\n",
            "Train Epoch: 16 [30720/45000 (68%)] Loss: 0.706625\n",
            "Train Epoch: 16 [31232/45000 (69%)] Loss: 0.719560\n",
            "Train Epoch: 16 [31744/45000 (71%)] Loss: 0.528972\n",
            "Train Epoch: 16 [32256/45000 (72%)] Loss: 0.445488\n",
            "Train Epoch: 16 [32768/45000 (73%)] Loss: 0.386980\n",
            "Train Epoch: 16 [33280/45000 (74%)] Loss: 0.467296\n",
            "Train Epoch: 16 [33792/45000 (75%)] Loss: 0.614442\n",
            "Train Epoch: 16 [34304/45000 (76%)] Loss: 0.629023\n",
            "Train Epoch: 16 [34816/45000 (77%)] Loss: 0.578488\n",
            "Train Epoch: 16 [35328/45000 (79%)] Loss: 0.385727\n",
            "Train Epoch: 16 [35840/45000 (80%)] Loss: 0.676556\n",
            "Train Epoch: 16 [36352/45000 (81%)] Loss: 0.369851\n",
            "Train Epoch: 16 [36864/45000 (82%)] Loss: 0.572839\n",
            "Train Epoch: 16 [37376/45000 (83%)] Loss: 0.510563\n",
            "Train Epoch: 16 [37888/45000 (84%)] Loss: 0.722373\n",
            "Train Epoch: 16 [38400/45000 (85%)] Loss: 0.770897\n",
            "Train Epoch: 16 [38912/45000 (86%)] Loss: 0.469896\n",
            "Train Epoch: 16 [39424/45000 (88%)] Loss: 0.659098\n",
            "Train Epoch: 16 [39936/45000 (89%)] Loss: 0.610058\n",
            "Train Epoch: 16 [40448/45000 (90%)] Loss: 0.461290\n",
            "Train Epoch: 16 [40960/45000 (91%)] Loss: 0.517163\n",
            "Train Epoch: 16 [41472/45000 (92%)] Loss: 0.594802\n",
            "Train Epoch: 16 [41984/45000 (93%)] Loss: 0.645807\n",
            "Train Epoch: 16 [42496/45000 (94%)] Loss: 0.665446\n",
            "Train Epoch: 16 [43008/45000 (96%)] Loss: 0.522363\n",
            "Train Epoch: 16 [43520/45000 (97%)] Loss: 0.527021\n",
            "Train Epoch: 16 [44032/45000 (98%)] Loss: 0.833670\n",
            "Train Epoch: 16 [44544/45000 (99%)] Loss: 0.744307\n",
            "    epoch          : 16\n",
            "    loss           : 0.6195327840660784\n",
            "    accuracy       : 78.6532315340909\n",
            "    val_loss       : 0.6415337637255464\n",
            "    val_accuracy   : 78.18433544303798\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch16.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 17 [0/45000 (0%)] Loss: 0.422376\n",
            "Train Epoch: 17 [512/45000 (1%)] Loss: 0.642115\n",
            "Train Epoch: 17 [1024/45000 (2%)] Loss: 0.537229\n",
            "Train Epoch: 17 [1536/45000 (3%)] Loss: 0.621269\n",
            "Train Epoch: 17 [2048/45000 (5%)] Loss: 0.579125\n",
            "Train Epoch: 17 [2560/45000 (6%)] Loss: 0.545975\n",
            "Train Epoch: 17 [3072/45000 (7%)] Loss: 0.536019\n",
            "Train Epoch: 17 [3584/45000 (8%)] Loss: 0.638050\n",
            "Train Epoch: 17 [4096/45000 (9%)] Loss: 0.515941\n",
            "Train Epoch: 17 [4608/45000 (10%)] Loss: 0.828141\n",
            "Train Epoch: 17 [5120/45000 (11%)] Loss: 0.501082\n",
            "Train Epoch: 17 [5632/45000 (13%)] Loss: 0.568909\n",
            "Train Epoch: 17 [6144/45000 (14%)] Loss: 0.584931\n",
            "Train Epoch: 17 [6656/45000 (15%)] Loss: 0.659770\n",
            "Train Epoch: 17 [7168/45000 (16%)] Loss: 0.814642\n",
            "Train Epoch: 17 [7680/45000 (17%)] Loss: 0.525895\n",
            "Train Epoch: 17 [8192/45000 (18%)] Loss: 0.425934\n",
            "Train Epoch: 17 [8704/45000 (19%)] Loss: 0.536152\n",
            "Train Epoch: 17 [9216/45000 (20%)] Loss: 0.615540\n",
            "Train Epoch: 17 [9728/45000 (22%)] Loss: 0.508874\n",
            "Train Epoch: 17 [10240/45000 (23%)] Loss: 0.629280\n",
            "Train Epoch: 17 [10752/45000 (24%)] Loss: 0.666860\n",
            "Train Epoch: 17 [11264/45000 (25%)] Loss: 0.468696\n",
            "Train Epoch: 17 [11776/45000 (26%)] Loss: 0.713830\n",
            "Train Epoch: 17 [12288/45000 (27%)] Loss: 0.561600\n",
            "Train Epoch: 17 [12800/45000 (28%)] Loss: 0.509172\n",
            "Train Epoch: 17 [13312/45000 (30%)] Loss: 0.443659\n",
            "Train Epoch: 17 [13824/45000 (31%)] Loss: 0.655448\n",
            "Train Epoch: 17 [14336/45000 (32%)] Loss: 0.481304\n",
            "Train Epoch: 17 [14848/45000 (33%)] Loss: 0.517337\n",
            "Train Epoch: 17 [15360/45000 (34%)] Loss: 0.499441\n",
            "Train Epoch: 17 [15872/45000 (35%)] Loss: 0.634151\n",
            "Train Epoch: 17 [16384/45000 (36%)] Loss: 0.623346\n",
            "Train Epoch: 17 [16896/45000 (38%)] Loss: 0.437809\n",
            "Train Epoch: 17 [17408/45000 (39%)] Loss: 0.630432\n",
            "Train Epoch: 17 [17920/45000 (40%)] Loss: 0.366468\n",
            "Train Epoch: 17 [18432/45000 (41%)] Loss: 0.531966\n",
            "Train Epoch: 17 [18944/45000 (42%)] Loss: 0.585741\n",
            "Train Epoch: 17 [19456/45000 (43%)] Loss: 0.594501\n",
            "Train Epoch: 17 [19968/45000 (44%)] Loss: 0.523630\n",
            "Train Epoch: 17 [20480/45000 (46%)] Loss: 0.649002\n",
            "Train Epoch: 17 [20992/45000 (47%)] Loss: 0.498153\n",
            "Train Epoch: 17 [21504/45000 (48%)] Loss: 0.652492\n",
            "Train Epoch: 17 [22016/45000 (49%)] Loss: 0.471006\n",
            "Train Epoch: 17 [22528/45000 (50%)] Loss: 0.571997\n",
            "Train Epoch: 17 [23040/45000 (51%)] Loss: 0.429228\n",
            "Train Epoch: 17 [23552/45000 (52%)] Loss: 0.607856\n",
            "Train Epoch: 17 [24064/45000 (53%)] Loss: 0.793051\n",
            "Train Epoch: 17 [24576/45000 (55%)] Loss: 0.572470\n",
            "Train Epoch: 17 [25088/45000 (56%)] Loss: 0.671097\n",
            "Train Epoch: 17 [25600/45000 (57%)] Loss: 0.475338\n",
            "Train Epoch: 17 [26112/45000 (58%)] Loss: 0.576406\n",
            "Train Epoch: 17 [26624/45000 (59%)] Loss: 0.592749\n",
            "Train Epoch: 17 [27136/45000 (60%)] Loss: 0.509175\n",
            "Train Epoch: 17 [27648/45000 (61%)] Loss: 0.614448\n",
            "Train Epoch: 17 [28160/45000 (63%)] Loss: 0.620094\n",
            "Train Epoch: 17 [28672/45000 (64%)] Loss: 0.561979\n",
            "Train Epoch: 17 [29184/45000 (65%)] Loss: 0.568012\n",
            "Train Epoch: 17 [29696/45000 (66%)] Loss: 0.582678\n",
            "Train Epoch: 17 [30208/45000 (67%)] Loss: 0.474193\n",
            "Train Epoch: 17 [30720/45000 (68%)] Loss: 0.547327\n",
            "Train Epoch: 17 [31232/45000 (69%)] Loss: 0.533095\n",
            "Train Epoch: 17 [31744/45000 (71%)] Loss: 0.612842\n",
            "Train Epoch: 17 [32256/45000 (72%)] Loss: 0.684411\n",
            "Train Epoch: 17 [32768/45000 (73%)] Loss: 0.575482\n",
            "Train Epoch: 17 [33280/45000 (74%)] Loss: 0.490496\n",
            "Train Epoch: 17 [33792/45000 (75%)] Loss: 0.581527\n",
            "Train Epoch: 17 [34304/45000 (76%)] Loss: 0.595188\n",
            "Train Epoch: 17 [34816/45000 (77%)] Loss: 0.490486\n",
            "Train Epoch: 17 [35328/45000 (79%)] Loss: 0.511411\n",
            "Train Epoch: 17 [35840/45000 (80%)] Loss: 0.865547\n",
            "Train Epoch: 17 [36352/45000 (81%)] Loss: 0.564278\n",
            "Train Epoch: 17 [36864/45000 (82%)] Loss: 0.783700\n",
            "Train Epoch: 17 [37376/45000 (83%)] Loss: 0.482167\n",
            "Train Epoch: 17 [37888/45000 (84%)] Loss: 0.721691\n",
            "Train Epoch: 17 [38400/45000 (85%)] Loss: 0.534030\n",
            "Train Epoch: 17 [38912/45000 (86%)] Loss: 0.537314\n",
            "Train Epoch: 17 [39424/45000 (88%)] Loss: 0.636815\n",
            "Train Epoch: 17 [39936/45000 (89%)] Loss: 0.569769\n",
            "Train Epoch: 17 [40448/45000 (90%)] Loss: 0.639127\n",
            "Train Epoch: 17 [40960/45000 (91%)] Loss: 0.760127\n",
            "Train Epoch: 17 [41472/45000 (92%)] Loss: 0.486581\n",
            "Train Epoch: 17 [41984/45000 (93%)] Loss: 0.658126\n",
            "Train Epoch: 17 [42496/45000 (94%)] Loss: 0.477106\n",
            "Train Epoch: 17 [43008/45000 (96%)] Loss: 0.513756\n",
            "Train Epoch: 17 [43520/45000 (97%)] Loss: 0.587778\n",
            "Train Epoch: 17 [44032/45000 (98%)] Loss: 0.450137\n",
            "Train Epoch: 17 [44544/45000 (99%)] Loss: 0.455496\n",
            "    epoch          : 17\n",
            "    loss           : 0.5931470567699183\n",
            "    accuracy       : 79.70081676136364\n",
            "    val_loss       : 0.6384695824943011\n",
            "    val_accuracy   : 78.2238924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch17.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 18 [0/45000 (0%)] Loss: 0.500161\n",
            "Train Epoch: 18 [512/45000 (1%)] Loss: 0.461338\n",
            "Train Epoch: 18 [1024/45000 (2%)] Loss: 0.585487\n",
            "Train Epoch: 18 [1536/45000 (3%)] Loss: 0.764417\n",
            "Train Epoch: 18 [2048/45000 (5%)] Loss: 0.623672\n",
            "Train Epoch: 18 [2560/45000 (6%)] Loss: 0.608517\n",
            "Train Epoch: 18 [3072/45000 (7%)] Loss: 0.663957\n",
            "Train Epoch: 18 [3584/45000 (8%)] Loss: 0.516300\n",
            "Train Epoch: 18 [4096/45000 (9%)] Loss: 0.687064\n",
            "Train Epoch: 18 [4608/45000 (10%)] Loss: 0.626241\n",
            "Train Epoch: 18 [5120/45000 (11%)] Loss: 0.785814\n",
            "Train Epoch: 18 [5632/45000 (13%)] Loss: 0.525767\n",
            "Train Epoch: 18 [6144/45000 (14%)] Loss: 0.472436\n",
            "Train Epoch: 18 [6656/45000 (15%)] Loss: 0.483588\n",
            "Train Epoch: 18 [7168/45000 (16%)] Loss: 0.621093\n",
            "Train Epoch: 18 [7680/45000 (17%)] Loss: 0.490205\n",
            "Train Epoch: 18 [8192/45000 (18%)] Loss: 0.786793\n",
            "Train Epoch: 18 [8704/45000 (19%)] Loss: 0.603005\n",
            "Train Epoch: 18 [9216/45000 (20%)] Loss: 0.710922\n",
            "Train Epoch: 18 [9728/45000 (22%)] Loss: 0.738652\n",
            "Train Epoch: 18 [10240/45000 (23%)] Loss: 0.417209\n",
            "Train Epoch: 18 [10752/45000 (24%)] Loss: 0.536272\n",
            "Train Epoch: 18 [11264/45000 (25%)] Loss: 0.535175\n",
            "Train Epoch: 18 [11776/45000 (26%)] Loss: 0.648909\n",
            "Train Epoch: 18 [12288/45000 (27%)] Loss: 0.599131\n",
            "Train Epoch: 18 [12800/45000 (28%)] Loss: 0.566733\n",
            "Train Epoch: 18 [13312/45000 (30%)] Loss: 0.563595\n",
            "Train Epoch: 18 [13824/45000 (31%)] Loss: 0.393478\n",
            "Train Epoch: 18 [14336/45000 (32%)] Loss: 0.362989\n",
            "Train Epoch: 18 [14848/45000 (33%)] Loss: 0.751690\n",
            "Train Epoch: 18 [15360/45000 (34%)] Loss: 0.625768\n",
            "Train Epoch: 18 [15872/45000 (35%)] Loss: 0.611744\n",
            "Train Epoch: 18 [16384/45000 (36%)] Loss: 0.543971\n",
            "Train Epoch: 18 [16896/45000 (38%)] Loss: 0.404299\n",
            "Train Epoch: 18 [17408/45000 (39%)] Loss: 0.594395\n",
            "Train Epoch: 18 [17920/45000 (40%)] Loss: 0.714874\n",
            "Train Epoch: 18 [18432/45000 (41%)] Loss: 0.563128\n",
            "Train Epoch: 18 [18944/45000 (42%)] Loss: 0.638227\n",
            "Train Epoch: 18 [19456/45000 (43%)] Loss: 0.725211\n",
            "Train Epoch: 18 [19968/45000 (44%)] Loss: 0.687707\n",
            "Train Epoch: 18 [20480/45000 (46%)] Loss: 0.536954\n",
            "Train Epoch: 18 [20992/45000 (47%)] Loss: 0.447537\n",
            "Train Epoch: 18 [21504/45000 (48%)] Loss: 0.499289\n",
            "Train Epoch: 18 [22016/45000 (49%)] Loss: 0.494640\n",
            "Train Epoch: 18 [22528/45000 (50%)] Loss: 0.537817\n",
            "Train Epoch: 18 [23040/45000 (51%)] Loss: 0.487421\n",
            "Train Epoch: 18 [23552/45000 (52%)] Loss: 0.470139\n",
            "Train Epoch: 18 [24064/45000 (53%)] Loss: 0.687619\n",
            "Train Epoch: 18 [24576/45000 (55%)] Loss: 0.521774\n",
            "Train Epoch: 18 [25088/45000 (56%)] Loss: 0.726386\n",
            "Train Epoch: 18 [25600/45000 (57%)] Loss: 0.603694\n",
            "Train Epoch: 18 [26112/45000 (58%)] Loss: 0.556085\n",
            "Train Epoch: 18 [26624/45000 (59%)] Loss: 0.543650\n",
            "Train Epoch: 18 [27136/45000 (60%)] Loss: 0.586642\n",
            "Train Epoch: 18 [27648/45000 (61%)] Loss: 0.699376\n",
            "Train Epoch: 18 [28160/45000 (63%)] Loss: 0.678007\n",
            "Train Epoch: 18 [28672/45000 (64%)] Loss: 0.504038\n",
            "Train Epoch: 18 [29184/45000 (65%)] Loss: 0.558577\n",
            "Train Epoch: 18 [29696/45000 (66%)] Loss: 0.442396\n",
            "Train Epoch: 18 [30208/45000 (67%)] Loss: 0.564347\n",
            "Train Epoch: 18 [30720/45000 (68%)] Loss: 0.788103\n",
            "Train Epoch: 18 [31232/45000 (69%)] Loss: 0.453726\n",
            "Train Epoch: 18 [31744/45000 (71%)] Loss: 0.738845\n",
            "Train Epoch: 18 [32256/45000 (72%)] Loss: 0.600348\n",
            "Train Epoch: 18 [32768/45000 (73%)] Loss: 0.575351\n",
            "Train Epoch: 18 [33280/45000 (74%)] Loss: 0.722281\n",
            "Train Epoch: 18 [33792/45000 (75%)] Loss: 0.595818\n",
            "Train Epoch: 18 [34304/45000 (76%)] Loss: 0.494212\n",
            "Train Epoch: 18 [34816/45000 (77%)] Loss: 0.631683\n",
            "Train Epoch: 18 [35328/45000 (79%)] Loss: 0.601624\n",
            "Train Epoch: 18 [35840/45000 (80%)] Loss: 0.699067\n",
            "Train Epoch: 18 [36352/45000 (81%)] Loss: 0.646994\n",
            "Train Epoch: 18 [36864/45000 (82%)] Loss: 0.769693\n",
            "Train Epoch: 18 [37376/45000 (83%)] Loss: 0.736142\n",
            "Train Epoch: 18 [37888/45000 (84%)] Loss: 0.377190\n",
            "Train Epoch: 18 [38400/45000 (85%)] Loss: 0.766506\n",
            "Train Epoch: 18 [38912/45000 (86%)] Loss: 0.623438\n",
            "Train Epoch: 18 [39424/45000 (88%)] Loss: 0.361928\n",
            "Train Epoch: 18 [39936/45000 (89%)] Loss: 0.494125\n",
            "Train Epoch: 18 [40448/45000 (90%)] Loss: 0.672981\n",
            "Train Epoch: 18 [40960/45000 (91%)] Loss: 0.509310\n",
            "Train Epoch: 18 [41472/45000 (92%)] Loss: 0.458117\n",
            "Train Epoch: 18 [41984/45000 (93%)] Loss: 0.480846\n",
            "Train Epoch: 18 [42496/45000 (94%)] Loss: 0.723544\n",
            "Train Epoch: 18 [43008/45000 (96%)] Loss: 0.517590\n",
            "Train Epoch: 18 [43520/45000 (97%)] Loss: 0.591266\n",
            "Train Epoch: 18 [44032/45000 (98%)] Loss: 0.279973\n",
            "Train Epoch: 18 [44544/45000 (99%)] Loss: 0.936294\n",
            "    epoch          : 18\n",
            "    loss           : 0.5842901769263501\n",
            "    accuracy       : 80.029296875\n",
            "    val_loss       : 0.6322386502465115\n",
            "    val_accuracy   : 78.34256329113924\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch18.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 19 [0/45000 (0%)] Loss: 0.666776\n",
            "Train Epoch: 19 [512/45000 (1%)] Loss: 0.491673\n",
            "Train Epoch: 19 [1024/45000 (2%)] Loss: 0.436543\n",
            "Train Epoch: 19 [1536/45000 (3%)] Loss: 0.603894\n",
            "Train Epoch: 19 [2048/45000 (5%)] Loss: 0.546296\n",
            "Train Epoch: 19 [2560/45000 (6%)] Loss: 0.547831\n",
            "Train Epoch: 19 [3072/45000 (7%)] Loss: 0.475091\n",
            "Train Epoch: 19 [3584/45000 (8%)] Loss: 0.620278\n",
            "Train Epoch: 19 [4096/45000 (9%)] Loss: 0.511269\n",
            "Train Epoch: 19 [4608/45000 (10%)] Loss: 0.358413\n",
            "Train Epoch: 19 [5120/45000 (11%)] Loss: 0.507207\n",
            "Train Epoch: 19 [5632/45000 (13%)] Loss: 0.499645\n",
            "Train Epoch: 19 [6144/45000 (14%)] Loss: 0.651790\n",
            "Train Epoch: 19 [6656/45000 (15%)] Loss: 0.353822\n",
            "Train Epoch: 19 [7168/45000 (16%)] Loss: 0.350680\n",
            "Train Epoch: 19 [7680/45000 (17%)] Loss: 0.644313\n",
            "Train Epoch: 19 [8192/45000 (18%)] Loss: 0.647818\n",
            "Train Epoch: 19 [8704/45000 (19%)] Loss: 0.470737\n",
            "Train Epoch: 19 [9216/45000 (20%)] Loss: 0.493868\n",
            "Train Epoch: 19 [9728/45000 (22%)] Loss: 1.012337\n",
            "Train Epoch: 19 [10240/45000 (23%)] Loss: 0.413627\n",
            "Train Epoch: 19 [10752/45000 (24%)] Loss: 0.509298\n",
            "Train Epoch: 19 [11264/45000 (25%)] Loss: 0.470134\n",
            "Train Epoch: 19 [11776/45000 (26%)] Loss: 0.582319\n",
            "Train Epoch: 19 [12288/45000 (27%)] Loss: 0.625710\n",
            "Train Epoch: 19 [12800/45000 (28%)] Loss: 0.680428\n",
            "Train Epoch: 19 [13312/45000 (30%)] Loss: 0.595805\n",
            "Train Epoch: 19 [13824/45000 (31%)] Loss: 0.665973\n",
            "Train Epoch: 19 [14336/45000 (32%)] Loss: 0.562320\n",
            "Train Epoch: 19 [14848/45000 (33%)] Loss: 0.534730\n",
            "Train Epoch: 19 [15360/45000 (34%)] Loss: 0.570154\n",
            "Train Epoch: 19 [15872/45000 (35%)] Loss: 0.561475\n",
            "Train Epoch: 19 [16384/45000 (36%)] Loss: 0.446414\n",
            "Train Epoch: 19 [16896/45000 (38%)] Loss: 0.613649\n",
            "Train Epoch: 19 [17408/45000 (39%)] Loss: 0.755874\n",
            "Train Epoch: 19 [17920/45000 (40%)] Loss: 0.620656\n",
            "Train Epoch: 19 [18432/45000 (41%)] Loss: 0.522458\n",
            "Train Epoch: 19 [18944/45000 (42%)] Loss: 0.504983\n",
            "Train Epoch: 19 [19456/45000 (43%)] Loss: 0.570811\n",
            "Train Epoch: 19 [19968/45000 (44%)] Loss: 0.533970\n",
            "Train Epoch: 19 [20480/45000 (46%)] Loss: 0.759005\n",
            "Train Epoch: 19 [20992/45000 (47%)] Loss: 0.410525\n",
            "Train Epoch: 19 [21504/45000 (48%)] Loss: 0.429628\n",
            "Train Epoch: 19 [22016/45000 (49%)] Loss: 0.549988\n",
            "Train Epoch: 19 [22528/45000 (50%)] Loss: 0.616554\n",
            "Train Epoch: 19 [23040/45000 (51%)] Loss: 0.473173\n",
            "Train Epoch: 19 [23552/45000 (52%)] Loss: 0.595861\n",
            "Train Epoch: 19 [24064/45000 (53%)] Loss: 0.480988\n",
            "Train Epoch: 19 [24576/45000 (55%)] Loss: 0.675672\n",
            "Train Epoch: 19 [25088/45000 (56%)] Loss: 0.415133\n",
            "Train Epoch: 19 [25600/45000 (57%)] Loss: 0.480282\n",
            "Train Epoch: 19 [26112/45000 (58%)] Loss: 0.467840\n",
            "Train Epoch: 19 [26624/45000 (59%)] Loss: 0.393888\n",
            "Train Epoch: 19 [27136/45000 (60%)] Loss: 0.496194\n",
            "Train Epoch: 19 [27648/45000 (61%)] Loss: 0.436643\n",
            "Train Epoch: 19 [28160/45000 (63%)] Loss: 0.680404\n",
            "Train Epoch: 19 [28672/45000 (64%)] Loss: 0.698705\n",
            "Train Epoch: 19 [29184/45000 (65%)] Loss: 0.582367\n",
            "Train Epoch: 19 [29696/45000 (66%)] Loss: 0.395229\n",
            "Train Epoch: 19 [30208/45000 (67%)] Loss: 0.448590\n",
            "Train Epoch: 19 [30720/45000 (68%)] Loss: 0.373841\n",
            "Train Epoch: 19 [31232/45000 (69%)] Loss: 0.564871\n",
            "Train Epoch: 19 [31744/45000 (71%)] Loss: 0.709690\n",
            "Train Epoch: 19 [32256/45000 (72%)] Loss: 0.331365\n",
            "Train Epoch: 19 [32768/45000 (73%)] Loss: 0.563028\n",
            "Train Epoch: 19 [33280/45000 (74%)] Loss: 0.527407\n",
            "Train Epoch: 19 [33792/45000 (75%)] Loss: 0.581949\n",
            "Train Epoch: 19 [34304/45000 (76%)] Loss: 0.556480\n",
            "Train Epoch: 19 [34816/45000 (77%)] Loss: 0.485568\n",
            "Train Epoch: 19 [35328/45000 (79%)] Loss: 0.560511\n",
            "Train Epoch: 19 [35840/45000 (80%)] Loss: 0.520080\n",
            "Train Epoch: 19 [36352/45000 (81%)] Loss: 0.511098\n",
            "Train Epoch: 19 [36864/45000 (82%)] Loss: 0.450132\n",
            "Train Epoch: 19 [37376/45000 (83%)] Loss: 0.423929\n",
            "Train Epoch: 19 [37888/45000 (84%)] Loss: 0.366752\n",
            "Train Epoch: 19 [38400/45000 (85%)] Loss: 0.631112\n",
            "Train Epoch: 19 [38912/45000 (86%)] Loss: 0.604213\n",
            "Train Epoch: 19 [39424/45000 (88%)] Loss: 0.577314\n",
            "Train Epoch: 19 [39936/45000 (89%)] Loss: 0.534287\n",
            "Train Epoch: 19 [40448/45000 (90%)] Loss: 0.694179\n",
            "Train Epoch: 19 [40960/45000 (91%)] Loss: 0.679582\n",
            "Train Epoch: 19 [41472/45000 (92%)] Loss: 0.499686\n",
            "Train Epoch: 19 [41984/45000 (93%)] Loss: 0.763002\n",
            "Train Epoch: 19 [42496/45000 (94%)] Loss: 0.503200\n",
            "Train Epoch: 19 [43008/45000 (96%)] Loss: 0.420248\n",
            "Train Epoch: 19 [43520/45000 (97%)] Loss: 0.448305\n",
            "Train Epoch: 19 [44032/45000 (98%)] Loss: 0.453992\n",
            "Train Epoch: 19 [44544/45000 (99%)] Loss: 0.695749\n",
            "    epoch          : 19\n",
            "    loss           : 0.5790717117488384\n",
            "    accuracy       : 80.22904829545455\n",
            "    val_loss       : 0.6550414388692831\n",
            "    val_accuracy   : 77.2745253164557\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch19.pth ...\n",
            "Train Epoch: 20 [0/45000 (0%)] Loss: 0.610960\n",
            "Train Epoch: 20 [512/45000 (1%)] Loss: 0.572498\n",
            "Train Epoch: 20 [1024/45000 (2%)] Loss: 0.726246\n",
            "Train Epoch: 20 [1536/45000 (3%)] Loss: 0.722908\n",
            "Train Epoch: 20 [2048/45000 (5%)] Loss: 0.409894\n",
            "Train Epoch: 20 [2560/45000 (6%)] Loss: 0.453311\n",
            "Train Epoch: 20 [3072/45000 (7%)] Loss: 0.414624\n",
            "Train Epoch: 20 [3584/45000 (8%)] Loss: 0.636660\n",
            "Train Epoch: 20 [4096/45000 (9%)] Loss: 0.535309\n",
            "Train Epoch: 20 [4608/45000 (10%)] Loss: 0.650566\n",
            "Train Epoch: 20 [5120/45000 (11%)] Loss: 0.568639\n",
            "Train Epoch: 20 [5632/45000 (13%)] Loss: 0.538226\n",
            "Train Epoch: 20 [6144/45000 (14%)] Loss: 0.500453\n",
            "Train Epoch: 20 [6656/45000 (15%)] Loss: 0.596989\n",
            "Train Epoch: 20 [7168/45000 (16%)] Loss: 0.534982\n",
            "Train Epoch: 20 [7680/45000 (17%)] Loss: 0.523357\n",
            "Train Epoch: 20 [8192/45000 (18%)] Loss: 0.655519\n",
            "Train Epoch: 20 [8704/45000 (19%)] Loss: 0.633669\n",
            "Train Epoch: 20 [9216/45000 (20%)] Loss: 0.647350\n",
            "Train Epoch: 20 [9728/45000 (22%)] Loss: 0.439102\n",
            "Train Epoch: 20 [10240/45000 (23%)] Loss: 0.869407\n",
            "Train Epoch: 20 [10752/45000 (24%)] Loss: 0.524102\n",
            "Train Epoch: 20 [11264/45000 (25%)] Loss: 0.393728\n",
            "Train Epoch: 20 [11776/45000 (26%)] Loss: 0.701985\n",
            "Train Epoch: 20 [12288/45000 (27%)] Loss: 0.627454\n",
            "Train Epoch: 20 [12800/45000 (28%)] Loss: 0.510183\n",
            "Train Epoch: 20 [13312/45000 (30%)] Loss: 0.552884\n",
            "Train Epoch: 20 [13824/45000 (31%)] Loss: 0.480273\n",
            "Train Epoch: 20 [14336/45000 (32%)] Loss: 0.630856\n",
            "Train Epoch: 20 [14848/45000 (33%)] Loss: 0.600555\n",
            "Train Epoch: 20 [15360/45000 (34%)] Loss: 0.483244\n",
            "Train Epoch: 20 [15872/45000 (35%)] Loss: 0.719035\n",
            "Train Epoch: 20 [16384/45000 (36%)] Loss: 0.582336\n",
            "Train Epoch: 20 [16896/45000 (38%)] Loss: 0.669772\n",
            "Train Epoch: 20 [17408/45000 (39%)] Loss: 0.471370\n",
            "Train Epoch: 20 [17920/45000 (40%)] Loss: 0.540903\n",
            "Train Epoch: 20 [18432/45000 (41%)] Loss: 0.654614\n",
            "Train Epoch: 20 [18944/45000 (42%)] Loss: 0.524323\n",
            "Train Epoch: 20 [19456/45000 (43%)] Loss: 0.686788\n",
            "Train Epoch: 20 [19968/45000 (44%)] Loss: 0.557602\n",
            "Train Epoch: 20 [20480/45000 (46%)] Loss: 0.590076\n",
            "Train Epoch: 20 [20992/45000 (47%)] Loss: 0.558534\n",
            "Train Epoch: 20 [21504/45000 (48%)] Loss: 0.679127\n",
            "Train Epoch: 20 [22016/45000 (49%)] Loss: 0.812254\n",
            "Train Epoch: 20 [22528/45000 (50%)] Loss: 0.664295\n",
            "Train Epoch: 20 [23040/45000 (51%)] Loss: 0.751403\n",
            "Train Epoch: 20 [23552/45000 (52%)] Loss: 0.498976\n",
            "Train Epoch: 20 [24064/45000 (53%)] Loss: 0.706009\n",
            "Train Epoch: 20 [24576/45000 (55%)] Loss: 0.395056\n",
            "Train Epoch: 20 [25088/45000 (56%)] Loss: 0.585711\n",
            "Train Epoch: 20 [25600/45000 (57%)] Loss: 0.740401\n",
            "Train Epoch: 20 [26112/45000 (58%)] Loss: 0.668036\n",
            "Train Epoch: 20 [26624/45000 (59%)] Loss: 0.757073\n",
            "Train Epoch: 20 [27136/45000 (60%)] Loss: 0.849043\n",
            "Train Epoch: 20 [27648/45000 (61%)] Loss: 0.517772\n",
            "Train Epoch: 20 [28160/45000 (63%)] Loss: 0.596571\n",
            "Train Epoch: 20 [28672/45000 (64%)] Loss: 0.634969\n",
            "Train Epoch: 20 [29184/45000 (65%)] Loss: 0.691279\n",
            "Train Epoch: 20 [29696/45000 (66%)] Loss: 0.416929\n",
            "Train Epoch: 20 [30208/45000 (67%)] Loss: 0.507330\n",
            "Train Epoch: 20 [30720/45000 (68%)] Loss: 0.493317\n",
            "Train Epoch: 20 [31232/45000 (69%)] Loss: 0.591329\n",
            "Train Epoch: 20 [31744/45000 (71%)] Loss: 0.659738\n",
            "Train Epoch: 20 [32256/45000 (72%)] Loss: 0.704326\n",
            "Train Epoch: 20 [32768/45000 (73%)] Loss: 0.656400\n",
            "Train Epoch: 20 [33280/45000 (74%)] Loss: 0.673150\n",
            "Train Epoch: 20 [33792/45000 (75%)] Loss: 0.618075\n",
            "Train Epoch: 20 [34304/45000 (76%)] Loss: 0.476357\n",
            "Train Epoch: 20 [34816/45000 (77%)] Loss: 0.486158\n",
            "Train Epoch: 20 [35328/45000 (79%)] Loss: 0.539608\n",
            "Train Epoch: 20 [35840/45000 (80%)] Loss: 0.610202\n",
            "Train Epoch: 20 [36352/45000 (81%)] Loss: 0.608393\n",
            "Train Epoch: 20 [36864/45000 (82%)] Loss: 0.481586\n",
            "Train Epoch: 20 [37376/45000 (83%)] Loss: 0.532114\n",
            "Train Epoch: 20 [37888/45000 (84%)] Loss: 0.504200\n",
            "Train Epoch: 20 [38400/45000 (85%)] Loss: 0.555648\n",
            "Train Epoch: 20 [38912/45000 (86%)] Loss: 0.469451\n",
            "Train Epoch: 20 [39424/45000 (88%)] Loss: 0.472565\n",
            "Train Epoch: 20 [39936/45000 (89%)] Loss: 0.570611\n",
            "Train Epoch: 20 [40448/45000 (90%)] Loss: 0.624026\n",
            "Train Epoch: 20 [40960/45000 (91%)] Loss: 0.624624\n",
            "Train Epoch: 20 [41472/45000 (92%)] Loss: 0.677549\n",
            "Train Epoch: 20 [41984/45000 (93%)] Loss: 0.679706\n",
            "Train Epoch: 20 [42496/45000 (94%)] Loss: 0.474650\n",
            "Train Epoch: 20 [43008/45000 (96%)] Loss: 0.428000\n",
            "Train Epoch: 20 [43520/45000 (97%)] Loss: 0.573685\n",
            "Train Epoch: 20 [44032/45000 (98%)] Loss: 0.652820\n",
            "Train Epoch: 20 [44544/45000 (99%)] Loss: 0.470016\n",
            "    epoch          : 20\n",
            "    loss           : 0.5828782892785966\n",
            "    accuracy       : 80.1358309659091\n",
            "    val_loss       : 0.6490709279911427\n",
            "    val_accuracy   : 77.49208860759494\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch20.pth ...\n",
            "Train Epoch: 21 [0/45000 (0%)] Loss: 0.520953\n",
            "Train Epoch: 21 [512/45000 (1%)] Loss: 0.534825\n",
            "Train Epoch: 21 [1024/45000 (2%)] Loss: 0.483927\n",
            "Train Epoch: 21 [1536/45000 (3%)] Loss: 0.511738\n",
            "Train Epoch: 21 [2048/45000 (5%)] Loss: 0.447185\n",
            "Train Epoch: 21 [2560/45000 (6%)] Loss: 0.490822\n",
            "Train Epoch: 21 [3072/45000 (7%)] Loss: 0.741396\n",
            "Train Epoch: 21 [3584/45000 (8%)] Loss: 0.413295\n",
            "Train Epoch: 21 [4096/45000 (9%)] Loss: 0.800464\n",
            "Train Epoch: 21 [4608/45000 (10%)] Loss: 0.516208\n",
            "Train Epoch: 21 [5120/45000 (11%)] Loss: 0.464563\n",
            "Train Epoch: 21 [5632/45000 (13%)] Loss: 0.700064\n",
            "Train Epoch: 21 [6144/45000 (14%)] Loss: 1.056184\n",
            "Train Epoch: 21 [6656/45000 (15%)] Loss: 0.581302\n",
            "Train Epoch: 21 [7168/45000 (16%)] Loss: 0.559543\n",
            "Train Epoch: 21 [7680/45000 (17%)] Loss: 0.736046\n",
            "Train Epoch: 21 [8192/45000 (18%)] Loss: 0.585569\n",
            "Train Epoch: 21 [8704/45000 (19%)] Loss: 0.640498\n",
            "Train Epoch: 21 [9216/45000 (20%)] Loss: 0.534490\n",
            "Train Epoch: 21 [9728/45000 (22%)] Loss: 0.717601\n",
            "Train Epoch: 21 [10240/45000 (23%)] Loss: 0.720960\n",
            "Train Epoch: 21 [10752/45000 (24%)] Loss: 0.353126\n",
            "Train Epoch: 21 [11264/45000 (25%)] Loss: 0.569605\n",
            "Train Epoch: 21 [11776/45000 (26%)] Loss: 0.478811\n",
            "Train Epoch: 21 [12288/45000 (27%)] Loss: 0.628268\n",
            "Train Epoch: 21 [12800/45000 (28%)] Loss: 0.709381\n",
            "Train Epoch: 21 [13312/45000 (30%)] Loss: 0.504544\n",
            "Train Epoch: 21 [13824/45000 (31%)] Loss: 0.483889\n",
            "Train Epoch: 21 [14336/45000 (32%)] Loss: 0.500412\n",
            "Train Epoch: 21 [14848/45000 (33%)] Loss: 0.408595\n",
            "Train Epoch: 21 [15360/45000 (34%)] Loss: 0.411624\n",
            "Train Epoch: 21 [15872/45000 (35%)] Loss: 0.552972\n",
            "Train Epoch: 21 [16384/45000 (36%)] Loss: 0.727672\n",
            "Train Epoch: 21 [16896/45000 (38%)] Loss: 0.600236\n",
            "Train Epoch: 21 [17408/45000 (39%)] Loss: 0.450983\n",
            "Train Epoch: 21 [17920/45000 (40%)] Loss: 0.719469\n",
            "Train Epoch: 21 [18432/45000 (41%)] Loss: 0.443380\n",
            "Train Epoch: 21 [18944/45000 (42%)] Loss: 0.466624\n",
            "Train Epoch: 21 [19456/45000 (43%)] Loss: 0.515699\n",
            "Train Epoch: 21 [19968/45000 (44%)] Loss: 0.491077\n",
            "Train Epoch: 21 [20480/45000 (46%)] Loss: 0.484375\n",
            "Train Epoch: 21 [20992/45000 (47%)] Loss: 0.610177\n",
            "Train Epoch: 21 [21504/45000 (48%)] Loss: 0.667056\n",
            "Train Epoch: 21 [22016/45000 (49%)] Loss: 0.681294\n",
            "Train Epoch: 21 [22528/45000 (50%)] Loss: 0.379009\n",
            "Train Epoch: 21 [23040/45000 (51%)] Loss: 0.654776\n",
            "Train Epoch: 21 [23552/45000 (52%)] Loss: 0.630533\n",
            "Train Epoch: 21 [24064/45000 (53%)] Loss: 0.710714\n",
            "Train Epoch: 21 [24576/45000 (55%)] Loss: 0.404531\n",
            "Train Epoch: 21 [25088/45000 (56%)] Loss: 0.834650\n",
            "Train Epoch: 21 [25600/45000 (57%)] Loss: 0.600265\n",
            "Train Epoch: 21 [26112/45000 (58%)] Loss: 0.605409\n",
            "Train Epoch: 21 [26624/45000 (59%)] Loss: 0.576840\n",
            "Train Epoch: 21 [27136/45000 (60%)] Loss: 0.479765\n",
            "Train Epoch: 21 [27648/45000 (61%)] Loss: 0.444630\n",
            "Train Epoch: 21 [28160/45000 (63%)] Loss: 0.663815\n",
            "Train Epoch: 21 [28672/45000 (64%)] Loss: 0.570646\n",
            "Train Epoch: 21 [29184/45000 (65%)] Loss: 0.559171\n",
            "Train Epoch: 21 [29696/45000 (66%)] Loss: 0.563795\n",
            "Train Epoch: 21 [30208/45000 (67%)] Loss: 0.639266\n",
            "Train Epoch: 21 [30720/45000 (68%)] Loss: 0.603038\n",
            "Train Epoch: 21 [31232/45000 (69%)] Loss: 0.578366\n",
            "Train Epoch: 21 [31744/45000 (71%)] Loss: 0.780446\n",
            "Train Epoch: 21 [32256/45000 (72%)] Loss: 0.546476\n",
            "Train Epoch: 21 [32768/45000 (73%)] Loss: 0.556139\n",
            "Train Epoch: 21 [33280/45000 (74%)] Loss: 0.712918\n",
            "Train Epoch: 21 [33792/45000 (75%)] Loss: 0.515438\n",
            "Train Epoch: 21 [34304/45000 (76%)] Loss: 0.456619\n",
            "Train Epoch: 21 [34816/45000 (77%)] Loss: 0.596284\n",
            "Train Epoch: 21 [35328/45000 (79%)] Loss: 0.567930\n",
            "Train Epoch: 21 [35840/45000 (80%)] Loss: 0.735455\n",
            "Train Epoch: 21 [36352/45000 (81%)] Loss: 0.416828\n",
            "Train Epoch: 21 [36864/45000 (82%)] Loss: 0.563271\n",
            "Train Epoch: 21 [37376/45000 (83%)] Loss: 0.650115\n",
            "Train Epoch: 21 [37888/45000 (84%)] Loss: 0.552249\n",
            "Train Epoch: 21 [38400/45000 (85%)] Loss: 0.355734\n",
            "Train Epoch: 21 [38912/45000 (86%)] Loss: 0.963103\n",
            "Train Epoch: 21 [39424/45000 (88%)] Loss: 0.603847\n",
            "Train Epoch: 21 [39936/45000 (89%)] Loss: 0.535889\n",
            "Train Epoch: 21 [40448/45000 (90%)] Loss: 0.722569\n",
            "Train Epoch: 21 [40960/45000 (91%)] Loss: 0.377196\n",
            "Train Epoch: 21 [41472/45000 (92%)] Loss: 0.390246\n",
            "Train Epoch: 21 [41984/45000 (93%)] Loss: 0.419131\n",
            "Train Epoch: 21 [42496/45000 (94%)] Loss: 0.580565\n",
            "Train Epoch: 21 [43008/45000 (96%)] Loss: 0.649779\n",
            "Train Epoch: 21 [43520/45000 (97%)] Loss: 0.645069\n",
            "Train Epoch: 21 [44032/45000 (98%)] Loss: 0.491280\n",
            "Train Epoch: 21 [44544/45000 (99%)] Loss: 0.620853\n",
            "    epoch          : 21\n",
            "    loss           : 0.5743192712014372\n",
            "    accuracy       : 80.40882457386364\n",
            "    val_loss       : 0.6441042789175541\n",
            "    val_accuracy   : 77.90743670886076\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch21.pth ...\n",
            "Train Epoch: 22 [0/45000 (0%)] Loss: 0.614605\n",
            "Train Epoch: 22 [512/45000 (1%)] Loss: 0.843506\n",
            "Train Epoch: 22 [1024/45000 (2%)] Loss: 0.532234\n",
            "Train Epoch: 22 [1536/45000 (3%)] Loss: 0.487252\n",
            "Train Epoch: 22 [2048/45000 (5%)] Loss: 0.641211\n",
            "Train Epoch: 22 [2560/45000 (6%)] Loss: 0.605114\n",
            "Train Epoch: 22 [3072/45000 (7%)] Loss: 0.480522\n",
            "Train Epoch: 22 [3584/45000 (8%)] Loss: 0.439263\n",
            "Train Epoch: 22 [4096/45000 (9%)] Loss: 0.433158\n",
            "Train Epoch: 22 [4608/45000 (10%)] Loss: 0.613539\n",
            "Train Epoch: 22 [5120/45000 (11%)] Loss: 0.702850\n",
            "Train Epoch: 22 [5632/45000 (13%)] Loss: 0.712986\n",
            "Train Epoch: 22 [6144/45000 (14%)] Loss: 0.420562\n",
            "Train Epoch: 22 [6656/45000 (15%)] Loss: 0.468581\n",
            "Train Epoch: 22 [7168/45000 (16%)] Loss: 0.673008\n",
            "Train Epoch: 22 [7680/45000 (17%)] Loss: 0.743816\n",
            "Train Epoch: 22 [8192/45000 (18%)] Loss: 0.605069\n",
            "Train Epoch: 22 [8704/45000 (19%)] Loss: 0.574823\n",
            "Train Epoch: 22 [9216/45000 (20%)] Loss: 0.702403\n",
            "Train Epoch: 22 [9728/45000 (22%)] Loss: 0.601443\n",
            "Train Epoch: 22 [10240/45000 (23%)] Loss: 0.780151\n",
            "Train Epoch: 22 [10752/45000 (24%)] Loss: 0.764749\n",
            "Train Epoch: 22 [11264/45000 (25%)] Loss: 0.750124\n",
            "Train Epoch: 22 [11776/45000 (26%)] Loss: 0.571846\n",
            "Train Epoch: 22 [12288/45000 (27%)] Loss: 0.641760\n",
            "Train Epoch: 22 [12800/45000 (28%)] Loss: 0.344235\n",
            "Train Epoch: 22 [13312/45000 (30%)] Loss: 0.630588\n",
            "Train Epoch: 22 [13824/45000 (31%)] Loss: 0.472503\n",
            "Train Epoch: 22 [14336/45000 (32%)] Loss: 0.449324\n",
            "Train Epoch: 22 [14848/45000 (33%)] Loss: 0.575512\n",
            "Train Epoch: 22 [15360/45000 (34%)] Loss: 0.520279\n",
            "Train Epoch: 22 [15872/45000 (35%)] Loss: 0.495819\n",
            "Train Epoch: 22 [16384/45000 (36%)] Loss: 0.471368\n",
            "Train Epoch: 22 [16896/45000 (38%)] Loss: 0.566320\n",
            "Train Epoch: 22 [17408/45000 (39%)] Loss: 0.528041\n",
            "Train Epoch: 22 [17920/45000 (40%)] Loss: 0.701113\n",
            "Train Epoch: 22 [18432/45000 (41%)] Loss: 0.510084\n",
            "Train Epoch: 22 [18944/45000 (42%)] Loss: 0.478536\n",
            "Train Epoch: 22 [19456/45000 (43%)] Loss: 0.551421\n",
            "Train Epoch: 22 [19968/45000 (44%)] Loss: 0.692555\n",
            "Train Epoch: 22 [20480/45000 (46%)] Loss: 0.491459\n",
            "Train Epoch: 22 [20992/45000 (47%)] Loss: 0.359219\n",
            "Train Epoch: 22 [21504/45000 (48%)] Loss: 0.672483\n",
            "Train Epoch: 22 [22016/45000 (49%)] Loss: 0.484755\n",
            "Train Epoch: 22 [22528/45000 (50%)] Loss: 0.477768\n",
            "Train Epoch: 22 [23040/45000 (51%)] Loss: 0.663683\n",
            "Train Epoch: 22 [23552/45000 (52%)] Loss: 0.529990\n",
            "Train Epoch: 22 [24064/45000 (53%)] Loss: 0.663597\n",
            "Train Epoch: 22 [24576/45000 (55%)] Loss: 0.481636\n",
            "Train Epoch: 22 [25088/45000 (56%)] Loss: 0.428788\n",
            "Train Epoch: 22 [25600/45000 (57%)] Loss: 0.523624\n",
            "Train Epoch: 22 [26112/45000 (58%)] Loss: 0.552487\n",
            "Train Epoch: 22 [26624/45000 (59%)] Loss: 0.492543\n",
            "Train Epoch: 22 [27136/45000 (60%)] Loss: 0.459192\n",
            "Train Epoch: 22 [27648/45000 (61%)] Loss: 0.579261\n",
            "Train Epoch: 22 [28160/45000 (63%)] Loss: 0.473179\n",
            "Train Epoch: 22 [28672/45000 (64%)] Loss: 0.789337\n",
            "Train Epoch: 22 [29184/45000 (65%)] Loss: 0.373807\n",
            "Train Epoch: 22 [29696/45000 (66%)] Loss: 0.526513\n",
            "Train Epoch: 22 [30208/45000 (67%)] Loss: 0.706132\n",
            "Train Epoch: 22 [30720/45000 (68%)] Loss: 0.653713\n",
            "Train Epoch: 22 [31232/45000 (69%)] Loss: 0.532241\n",
            "Train Epoch: 22 [31744/45000 (71%)] Loss: 0.542575\n",
            "Train Epoch: 22 [32256/45000 (72%)] Loss: 0.561109\n",
            "Train Epoch: 22 [32768/45000 (73%)] Loss: 0.719980\n",
            "Train Epoch: 22 [33280/45000 (74%)] Loss: 0.627311\n",
            "Train Epoch: 22 [33792/45000 (75%)] Loss: 0.486585\n",
            "Train Epoch: 22 [34304/45000 (76%)] Loss: 0.687955\n",
            "Train Epoch: 22 [34816/45000 (77%)] Loss: 0.706235\n",
            "Train Epoch: 22 [35328/45000 (79%)] Loss: 0.453003\n",
            "Train Epoch: 22 [35840/45000 (80%)] Loss: 0.778402\n",
            "Train Epoch: 22 [36352/45000 (81%)] Loss: 0.445356\n",
            "Train Epoch: 22 [36864/45000 (82%)] Loss: 0.545820\n",
            "Train Epoch: 22 [37376/45000 (83%)] Loss: 0.624550\n",
            "Train Epoch: 22 [37888/45000 (84%)] Loss: 0.427625\n",
            "Train Epoch: 22 [38400/45000 (85%)] Loss: 0.712038\n",
            "Train Epoch: 22 [38912/45000 (86%)] Loss: 0.667331\n",
            "Train Epoch: 22 [39424/45000 (88%)] Loss: 0.612837\n",
            "Train Epoch: 22 [39936/45000 (89%)] Loss: 0.479773\n",
            "Train Epoch: 22 [40448/45000 (90%)] Loss: 0.475111\n",
            "Train Epoch: 22 [40960/45000 (91%)] Loss: 0.535323\n",
            "Train Epoch: 22 [41472/45000 (92%)] Loss: 0.478597\n",
            "Train Epoch: 22 [41984/45000 (93%)] Loss: 0.728871\n",
            "Train Epoch: 22 [42496/45000 (94%)] Loss: 0.361506\n",
            "Train Epoch: 22 [43008/45000 (96%)] Loss: 0.646345\n",
            "Train Epoch: 22 [43520/45000 (97%)] Loss: 0.481366\n",
            "Train Epoch: 22 [44032/45000 (98%)] Loss: 0.538410\n",
            "Train Epoch: 22 [44544/45000 (99%)] Loss: 0.553750\n",
            "    epoch          : 22\n",
            "    loss           : 0.5757719176736745\n",
            "    accuracy       : 80.28453480113636\n",
            "    val_loss       : 0.6175244680688351\n",
            "    val_accuracy   : 78.65901898734177\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch22.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 23 [0/45000 (0%)] Loss: 0.422228\n",
            "Train Epoch: 23 [512/45000 (1%)] Loss: 0.828944\n",
            "Train Epoch: 23 [1024/45000 (2%)] Loss: 0.671818\n",
            "Train Epoch: 23 [1536/45000 (3%)] Loss: 0.608016\n",
            "Train Epoch: 23 [2048/45000 (5%)] Loss: 0.375478\n",
            "Train Epoch: 23 [2560/45000 (6%)] Loss: 0.483620\n",
            "Train Epoch: 23 [3072/45000 (7%)] Loss: 0.555334\n",
            "Train Epoch: 23 [3584/45000 (8%)] Loss: 0.685373\n",
            "Train Epoch: 23 [4096/45000 (9%)] Loss: 0.452826\n",
            "Train Epoch: 23 [4608/45000 (10%)] Loss: 0.620492\n",
            "Train Epoch: 23 [5120/45000 (11%)] Loss: 0.538379\n",
            "Train Epoch: 23 [5632/45000 (13%)] Loss: 0.654665\n",
            "Train Epoch: 23 [6144/45000 (14%)] Loss: 0.414365\n",
            "Train Epoch: 23 [6656/45000 (15%)] Loss: 0.493794\n",
            "Train Epoch: 23 [7168/45000 (16%)] Loss: 0.750535\n",
            "Train Epoch: 23 [7680/45000 (17%)] Loss: 0.556567\n",
            "Train Epoch: 23 [8192/45000 (18%)] Loss: 0.483291\n",
            "Train Epoch: 23 [8704/45000 (19%)] Loss: 0.647542\n",
            "Train Epoch: 23 [9216/45000 (20%)] Loss: 0.753950\n",
            "Train Epoch: 23 [9728/45000 (22%)] Loss: 0.446574\n",
            "Train Epoch: 23 [10240/45000 (23%)] Loss: 0.455984\n",
            "Train Epoch: 23 [10752/45000 (24%)] Loss: 0.668509\n",
            "Train Epoch: 23 [11264/45000 (25%)] Loss: 0.476314\n",
            "Train Epoch: 23 [11776/45000 (26%)] Loss: 0.548013\n",
            "Train Epoch: 23 [12288/45000 (27%)] Loss: 0.535305\n",
            "Train Epoch: 23 [12800/45000 (28%)] Loss: 0.423888\n",
            "Train Epoch: 23 [13312/45000 (30%)] Loss: 0.532334\n",
            "Train Epoch: 23 [13824/45000 (31%)] Loss: 0.502076\n",
            "Train Epoch: 23 [14336/45000 (32%)] Loss: 0.556206\n",
            "Train Epoch: 23 [14848/45000 (33%)] Loss: 0.435829\n",
            "Train Epoch: 23 [15360/45000 (34%)] Loss: 0.556241\n",
            "Train Epoch: 23 [15872/45000 (35%)] Loss: 0.609942\n",
            "Train Epoch: 23 [16384/45000 (36%)] Loss: 0.422177\n",
            "Train Epoch: 23 [16896/45000 (38%)] Loss: 0.477204\n",
            "Train Epoch: 23 [17408/45000 (39%)] Loss: 0.566541\n",
            "Train Epoch: 23 [17920/45000 (40%)] Loss: 0.671987\n",
            "Train Epoch: 23 [18432/45000 (41%)] Loss: 0.482923\n",
            "Train Epoch: 23 [18944/45000 (42%)] Loss: 0.409411\n",
            "Train Epoch: 23 [19456/45000 (43%)] Loss: 0.775124\n",
            "Train Epoch: 23 [19968/45000 (44%)] Loss: 0.549899\n",
            "Train Epoch: 23 [20480/45000 (46%)] Loss: 0.685802\n",
            "Train Epoch: 23 [20992/45000 (47%)] Loss: 0.740233\n",
            "Train Epoch: 23 [21504/45000 (48%)] Loss: 0.378593\n",
            "Train Epoch: 23 [22016/45000 (49%)] Loss: 0.479272\n",
            "Train Epoch: 23 [22528/45000 (50%)] Loss: 0.540916\n",
            "Train Epoch: 23 [23040/45000 (51%)] Loss: 0.746818\n",
            "Train Epoch: 23 [23552/45000 (52%)] Loss: 0.693657\n",
            "Train Epoch: 23 [24064/45000 (53%)] Loss: 0.496479\n",
            "Train Epoch: 23 [24576/45000 (55%)] Loss: 0.563109\n",
            "Train Epoch: 23 [25088/45000 (56%)] Loss: 0.362569\n",
            "Train Epoch: 23 [25600/45000 (57%)] Loss: 0.793159\n",
            "Train Epoch: 23 [26112/45000 (58%)] Loss: 0.636047\n",
            "Train Epoch: 23 [26624/45000 (59%)] Loss: 0.629694\n",
            "Train Epoch: 23 [27136/45000 (60%)] Loss: 0.506948\n",
            "Train Epoch: 23 [27648/45000 (61%)] Loss: 0.570544\n",
            "Train Epoch: 23 [28160/45000 (63%)] Loss: 0.576184\n",
            "Train Epoch: 23 [28672/45000 (64%)] Loss: 0.517040\n",
            "Train Epoch: 23 [29184/45000 (65%)] Loss: 0.522033\n",
            "Train Epoch: 23 [29696/45000 (66%)] Loss: 0.702437\n",
            "Train Epoch: 23 [30208/45000 (67%)] Loss: 0.734087\n",
            "Train Epoch: 23 [30720/45000 (68%)] Loss: 0.626279\n",
            "Train Epoch: 23 [31232/45000 (69%)] Loss: 0.502074\n",
            "Train Epoch: 23 [31744/45000 (71%)] Loss: 0.361898\n",
            "Train Epoch: 23 [32256/45000 (72%)] Loss: 0.453036\n",
            "Train Epoch: 23 [32768/45000 (73%)] Loss: 0.858701\n",
            "Train Epoch: 23 [33280/45000 (74%)] Loss: 0.456855\n",
            "Train Epoch: 23 [33792/45000 (75%)] Loss: 0.626598\n",
            "Train Epoch: 23 [34304/45000 (76%)] Loss: 0.754924\n",
            "Train Epoch: 23 [34816/45000 (77%)] Loss: 0.523997\n",
            "Train Epoch: 23 [35328/45000 (79%)] Loss: 0.485798\n",
            "Train Epoch: 23 [35840/45000 (80%)] Loss: 0.632829\n",
            "Train Epoch: 23 [36352/45000 (81%)] Loss: 0.509529\n",
            "Train Epoch: 23 [36864/45000 (82%)] Loss: 0.580402\n",
            "Train Epoch: 23 [37376/45000 (83%)] Loss: 0.652198\n",
            "Train Epoch: 23 [37888/45000 (84%)] Loss: 0.660370\n",
            "Train Epoch: 23 [38400/45000 (85%)] Loss: 0.470193\n",
            "Train Epoch: 23 [38912/45000 (86%)] Loss: 0.378743\n",
            "Train Epoch: 23 [39424/45000 (88%)] Loss: 0.507026\n",
            "Train Epoch: 23 [39936/45000 (89%)] Loss: 0.524360\n",
            "Train Epoch: 23 [40448/45000 (90%)] Loss: 0.629017\n",
            "Train Epoch: 23 [40960/45000 (91%)] Loss: 0.480897\n",
            "Train Epoch: 23 [41472/45000 (92%)] Loss: 0.749339\n",
            "Train Epoch: 23 [41984/45000 (93%)] Loss: 0.571212\n",
            "Train Epoch: 23 [42496/45000 (94%)] Loss: 0.519677\n",
            "Train Epoch: 23 [43008/45000 (96%)] Loss: 0.454536\n",
            "Train Epoch: 23 [43520/45000 (97%)] Loss: 0.531060\n",
            "Train Epoch: 23 [44032/45000 (98%)] Loss: 0.608991\n",
            "Train Epoch: 23 [44544/45000 (99%)] Loss: 0.495475\n",
            "    epoch          : 23\n",
            "    loss           : 0.5668794337490742\n",
            "    accuracy       : 80.49760298295455\n",
            "    val_loss       : 0.6254110023190703\n",
            "    val_accuracy   : 78.85680379746836\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch23.pth ...\n",
            "Train Epoch: 24 [0/45000 (0%)] Loss: 0.422198\n",
            "Train Epoch: 24 [512/45000 (1%)] Loss: 0.822639\n",
            "Train Epoch: 24 [1024/45000 (2%)] Loss: 0.481536\n",
            "Train Epoch: 24 [1536/45000 (3%)] Loss: 0.557156\n",
            "Train Epoch: 24 [2048/45000 (5%)] Loss: 0.478484\n",
            "Train Epoch: 24 [2560/45000 (6%)] Loss: 0.437593\n",
            "Train Epoch: 24 [3072/45000 (7%)] Loss: 0.468692\n",
            "Train Epoch: 24 [3584/45000 (8%)] Loss: 0.456747\n",
            "Train Epoch: 24 [4096/45000 (9%)] Loss: 0.554491\n",
            "Train Epoch: 24 [4608/45000 (10%)] Loss: 0.525748\n",
            "Train Epoch: 24 [5120/45000 (11%)] Loss: 0.444934\n",
            "Train Epoch: 24 [5632/45000 (13%)] Loss: 0.616603\n",
            "Train Epoch: 24 [6144/45000 (14%)] Loss: 0.412566\n",
            "Train Epoch: 24 [6656/45000 (15%)] Loss: 0.459521\n",
            "Train Epoch: 24 [7168/45000 (16%)] Loss: 0.626165\n",
            "Train Epoch: 24 [7680/45000 (17%)] Loss: 0.581973\n",
            "Train Epoch: 24 [8192/45000 (18%)] Loss: 0.752778\n",
            "Train Epoch: 24 [8704/45000 (19%)] Loss: 0.503908\n",
            "Train Epoch: 24 [9216/45000 (20%)] Loss: 0.471856\n",
            "Train Epoch: 24 [9728/45000 (22%)] Loss: 0.523187\n",
            "Train Epoch: 24 [10240/45000 (23%)] Loss: 0.496742\n",
            "Train Epoch: 24 [10752/45000 (24%)] Loss: 0.738290\n",
            "Train Epoch: 24 [11264/45000 (25%)] Loss: 0.558019\n",
            "Train Epoch: 24 [11776/45000 (26%)] Loss: 0.503956\n",
            "Train Epoch: 24 [12288/45000 (27%)] Loss: 0.879324\n",
            "Train Epoch: 24 [12800/45000 (28%)] Loss: 0.664297\n",
            "Train Epoch: 24 [13312/45000 (30%)] Loss: 0.562012\n",
            "Train Epoch: 24 [13824/45000 (31%)] Loss: 0.484962\n",
            "Train Epoch: 24 [14336/45000 (32%)] Loss: 0.618256\n",
            "Train Epoch: 24 [14848/45000 (33%)] Loss: 0.558337\n",
            "Train Epoch: 24 [15360/45000 (34%)] Loss: 0.716584\n",
            "Train Epoch: 24 [15872/45000 (35%)] Loss: 0.617119\n",
            "Train Epoch: 24 [16384/45000 (36%)] Loss: 0.614768\n",
            "Train Epoch: 24 [16896/45000 (38%)] Loss: 0.612296\n",
            "Train Epoch: 24 [17408/45000 (39%)] Loss: 0.557716\n",
            "Train Epoch: 24 [17920/45000 (40%)] Loss: 0.435786\n",
            "Train Epoch: 24 [18432/45000 (41%)] Loss: 0.426857\n",
            "Train Epoch: 24 [18944/45000 (42%)] Loss: 0.522837\n",
            "Train Epoch: 24 [19456/45000 (43%)] Loss: 0.397416\n",
            "Train Epoch: 24 [19968/45000 (44%)] Loss: 0.708201\n",
            "Train Epoch: 24 [20480/45000 (46%)] Loss: 0.854829\n",
            "Train Epoch: 24 [20992/45000 (47%)] Loss: 0.621379\n",
            "Train Epoch: 24 [21504/45000 (48%)] Loss: 0.565142\n",
            "Train Epoch: 24 [22016/45000 (49%)] Loss: 0.418090\n",
            "Train Epoch: 24 [22528/45000 (50%)] Loss: 0.545496\n",
            "Train Epoch: 24 [23040/45000 (51%)] Loss: 0.641984\n",
            "Train Epoch: 24 [23552/45000 (52%)] Loss: 0.504142\n",
            "Train Epoch: 24 [24064/45000 (53%)] Loss: 0.699055\n",
            "Train Epoch: 24 [24576/45000 (55%)] Loss: 0.341247\n",
            "Train Epoch: 24 [25088/45000 (56%)] Loss: 0.469227\n",
            "Train Epoch: 24 [25600/45000 (57%)] Loss: 0.582803\n",
            "Train Epoch: 24 [26112/45000 (58%)] Loss: 0.525780\n",
            "Train Epoch: 24 [26624/45000 (59%)] Loss: 0.582508\n",
            "Train Epoch: 24 [27136/45000 (60%)] Loss: 0.572879\n",
            "Train Epoch: 24 [27648/45000 (61%)] Loss: 0.555051\n",
            "Train Epoch: 24 [28160/45000 (63%)] Loss: 0.487335\n",
            "Train Epoch: 24 [28672/45000 (64%)] Loss: 0.541395\n",
            "Train Epoch: 24 [29184/45000 (65%)] Loss: 0.483125\n",
            "Train Epoch: 24 [29696/45000 (66%)] Loss: 0.421815\n",
            "Train Epoch: 24 [30208/45000 (67%)] Loss: 0.604548\n",
            "Train Epoch: 24 [30720/45000 (68%)] Loss: 0.446599\n",
            "Train Epoch: 24 [31232/45000 (69%)] Loss: 0.512569\n",
            "Train Epoch: 24 [31744/45000 (71%)] Loss: 0.344172\n",
            "Train Epoch: 24 [32256/45000 (72%)] Loss: 0.616602\n",
            "Train Epoch: 24 [32768/45000 (73%)] Loss: 0.590289\n",
            "Train Epoch: 24 [33280/45000 (74%)] Loss: 0.691239\n",
            "Train Epoch: 24 [33792/45000 (75%)] Loss: 0.561938\n",
            "Train Epoch: 24 [34304/45000 (76%)] Loss: 0.443301\n",
            "Train Epoch: 24 [34816/45000 (77%)] Loss: 0.516424\n",
            "Train Epoch: 24 [35328/45000 (79%)] Loss: 0.555563\n",
            "Train Epoch: 24 [35840/45000 (80%)] Loss: 0.617056\n",
            "Train Epoch: 24 [36352/45000 (81%)] Loss: 0.607073\n",
            "Train Epoch: 24 [36864/45000 (82%)] Loss: 0.599277\n",
            "Train Epoch: 24 [37376/45000 (83%)] Loss: 0.592650\n",
            "Train Epoch: 24 [37888/45000 (84%)] Loss: 0.517326\n",
            "Train Epoch: 24 [38400/45000 (85%)] Loss: 0.340357\n",
            "Train Epoch: 24 [38912/45000 (86%)] Loss: 0.596678\n",
            "Train Epoch: 24 [39424/45000 (88%)] Loss: 0.754899\n",
            "Train Epoch: 24 [39936/45000 (89%)] Loss: 0.522681\n",
            "Train Epoch: 24 [40448/45000 (90%)] Loss: 0.602914\n",
            "Train Epoch: 24 [40960/45000 (91%)] Loss: 0.479343\n",
            "Train Epoch: 24 [41472/45000 (92%)] Loss: 0.633747\n",
            "Train Epoch: 24 [41984/45000 (93%)] Loss: 0.670121\n",
            "Train Epoch: 24 [42496/45000 (94%)] Loss: 0.589035\n",
            "Train Epoch: 24 [43008/45000 (96%)] Loss: 0.520626\n",
            "Train Epoch: 24 [43520/45000 (97%)] Loss: 0.351199\n",
            "Train Epoch: 24 [44032/45000 (98%)] Loss: 0.641571\n",
            "Train Epoch: 24 [44544/45000 (99%)] Loss: 0.825658\n",
            "    epoch          : 24\n",
            "    loss           : 0.5614802420816638\n",
            "    accuracy       : 80.85493607954545\n",
            "    val_loss       : 0.6430234580854827\n",
            "    val_accuracy   : 78.0261075949367\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch24.pth ...\n",
            "Train Epoch: 25 [0/45000 (0%)] Loss: 0.494335\n",
            "Train Epoch: 25 [512/45000 (1%)] Loss: 0.558763\n",
            "Train Epoch: 25 [1024/45000 (2%)] Loss: 0.548820\n",
            "Train Epoch: 25 [1536/45000 (3%)] Loss: 0.582308\n",
            "Train Epoch: 25 [2048/45000 (5%)] Loss: 0.363582\n",
            "Train Epoch: 25 [2560/45000 (6%)] Loss: 0.467412\n",
            "Train Epoch: 25 [3072/45000 (7%)] Loss: 0.592545\n",
            "Train Epoch: 25 [3584/45000 (8%)] Loss: 0.569970\n",
            "Train Epoch: 25 [4096/45000 (9%)] Loss: 0.707856\n",
            "Train Epoch: 25 [4608/45000 (10%)] Loss: 0.541430\n",
            "Train Epoch: 25 [5120/45000 (11%)] Loss: 0.668845\n",
            "Train Epoch: 25 [5632/45000 (13%)] Loss: 0.562384\n",
            "Train Epoch: 25 [6144/45000 (14%)] Loss: 0.497437\n",
            "Train Epoch: 25 [6656/45000 (15%)] Loss: 0.622298\n",
            "Train Epoch: 25 [7168/45000 (16%)] Loss: 0.839877\n",
            "Train Epoch: 25 [7680/45000 (17%)] Loss: 0.423261\n",
            "Train Epoch: 25 [8192/45000 (18%)] Loss: 0.446358\n",
            "Train Epoch: 25 [8704/45000 (19%)] Loss: 0.448419\n",
            "Train Epoch: 25 [9216/45000 (20%)] Loss: 0.508102\n",
            "Train Epoch: 25 [9728/45000 (22%)] Loss: 0.303413\n",
            "Train Epoch: 25 [10240/45000 (23%)] Loss: 0.570634\n",
            "Train Epoch: 25 [10752/45000 (24%)] Loss: 0.770036\n",
            "Train Epoch: 25 [11264/45000 (25%)] Loss: 0.553618\n",
            "Train Epoch: 25 [11776/45000 (26%)] Loss: 0.660084\n",
            "Train Epoch: 25 [12288/45000 (27%)] Loss: 0.585968\n",
            "Train Epoch: 25 [12800/45000 (28%)] Loss: 0.489893\n",
            "Train Epoch: 25 [13312/45000 (30%)] Loss: 0.778528\n",
            "Train Epoch: 25 [13824/45000 (31%)] Loss: 0.700062\n",
            "Train Epoch: 25 [14336/45000 (32%)] Loss: 0.600493\n",
            "Train Epoch: 25 [14848/45000 (33%)] Loss: 0.608175\n",
            "Train Epoch: 25 [15360/45000 (34%)] Loss: 0.879498\n",
            "Train Epoch: 25 [15872/45000 (35%)] Loss: 0.473541\n",
            "Train Epoch: 25 [16384/45000 (36%)] Loss: 0.614674\n",
            "Train Epoch: 25 [16896/45000 (38%)] Loss: 0.620706\n",
            "Train Epoch: 25 [17408/45000 (39%)] Loss: 0.565123\n",
            "Train Epoch: 25 [17920/45000 (40%)] Loss: 0.684317\n",
            "Train Epoch: 25 [18432/45000 (41%)] Loss: 0.457977\n",
            "Train Epoch: 25 [18944/45000 (42%)] Loss: 0.790499\n",
            "Train Epoch: 25 [19456/45000 (43%)] Loss: 0.630589\n",
            "Train Epoch: 25 [19968/45000 (44%)] Loss: 0.437148\n",
            "Train Epoch: 25 [20480/45000 (46%)] Loss: 0.362323\n",
            "Train Epoch: 25 [20992/45000 (47%)] Loss: 0.607205\n",
            "Train Epoch: 25 [21504/45000 (48%)] Loss: 0.459368\n",
            "Train Epoch: 25 [22016/45000 (49%)] Loss: 0.562067\n",
            "Train Epoch: 25 [22528/45000 (50%)] Loss: 0.679110\n",
            "Train Epoch: 25 [23040/45000 (51%)] Loss: 0.391191\n",
            "Train Epoch: 25 [23552/45000 (52%)] Loss: 0.666854\n",
            "Train Epoch: 25 [24064/45000 (53%)] Loss: 0.397582\n",
            "Train Epoch: 25 [24576/45000 (55%)] Loss: 0.317531\n",
            "Train Epoch: 25 [25088/45000 (56%)] Loss: 0.516781\n",
            "Train Epoch: 25 [25600/45000 (57%)] Loss: 0.458817\n",
            "Train Epoch: 25 [26112/45000 (58%)] Loss: 0.706687\n",
            "Train Epoch: 25 [26624/45000 (59%)] Loss: 0.648157\n",
            "Train Epoch: 25 [27136/45000 (60%)] Loss: 0.647802\n",
            "Train Epoch: 25 [27648/45000 (61%)] Loss: 0.714245\n",
            "Train Epoch: 25 [28160/45000 (63%)] Loss: 0.492283\n",
            "Train Epoch: 25 [28672/45000 (64%)] Loss: 0.637796\n",
            "Train Epoch: 25 [29184/45000 (65%)] Loss: 0.648247\n",
            "Train Epoch: 25 [29696/45000 (66%)] Loss: 0.711314\n",
            "Train Epoch: 25 [30208/45000 (67%)] Loss: 0.580890\n",
            "Train Epoch: 25 [30720/45000 (68%)] Loss: 0.546943\n",
            "Train Epoch: 25 [31232/45000 (69%)] Loss: 0.902678\n",
            "Train Epoch: 25 [31744/45000 (71%)] Loss: 0.706580\n",
            "Train Epoch: 25 [32256/45000 (72%)] Loss: 0.416786\n",
            "Train Epoch: 25 [32768/45000 (73%)] Loss: 0.680675\n",
            "Train Epoch: 25 [33280/45000 (74%)] Loss: 0.611905\n",
            "Train Epoch: 25 [33792/45000 (75%)] Loss: 0.443374\n",
            "Train Epoch: 25 [34304/45000 (76%)] Loss: 0.387714\n",
            "Train Epoch: 25 [34816/45000 (77%)] Loss: 0.696276\n",
            "Train Epoch: 25 [35328/45000 (79%)] Loss: 0.506017\n",
            "Train Epoch: 25 [35840/45000 (80%)] Loss: 0.433247\n",
            "Train Epoch: 25 [36352/45000 (81%)] Loss: 0.468497\n",
            "Train Epoch: 25 [36864/45000 (82%)] Loss: 0.551371\n",
            "Train Epoch: 25 [37376/45000 (83%)] Loss: 0.637721\n",
            "Train Epoch: 25 [37888/45000 (84%)] Loss: 0.408759\n",
            "Train Epoch: 25 [38400/45000 (85%)] Loss: 0.501140\n",
            "Train Epoch: 25 [38912/45000 (86%)] Loss: 0.576023\n",
            "Train Epoch: 25 [39424/45000 (88%)] Loss: 0.478623\n",
            "Train Epoch: 25 [39936/45000 (89%)] Loss: 0.408422\n",
            "Train Epoch: 25 [40448/45000 (90%)] Loss: 0.487285\n",
            "Train Epoch: 25 [40960/45000 (91%)] Loss: 0.568814\n",
            "Train Epoch: 25 [41472/45000 (92%)] Loss: 0.528294\n",
            "Train Epoch: 25 [41984/45000 (93%)] Loss: 0.666790\n",
            "Train Epoch: 25 [42496/45000 (94%)] Loss: 0.654929\n",
            "Train Epoch: 25 [43008/45000 (96%)] Loss: 0.598834\n",
            "Train Epoch: 25 [43520/45000 (97%)] Loss: 0.491830\n",
            "Train Epoch: 25 [44032/45000 (98%)] Loss: 0.390568\n",
            "Train Epoch: 25 [44544/45000 (99%)] Loss: 0.565672\n",
            "    epoch          : 25\n",
            "    loss           : 0.5613050890070471\n",
            "    accuracy       : 80.8349609375\n",
            "    val_loss       : 0.6175333834901641\n",
            "    val_accuracy   : 78.5996835443038\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch25.pth ...\n",
            "Train Epoch: 26 [0/45000 (0%)] Loss: 0.547916\n",
            "Train Epoch: 26 [512/45000 (1%)] Loss: 0.472113\n",
            "Train Epoch: 26 [1024/45000 (2%)] Loss: 0.425853\n",
            "Train Epoch: 26 [1536/45000 (3%)] Loss: 0.434015\n",
            "Train Epoch: 26 [2048/45000 (5%)] Loss: 0.434181\n",
            "Train Epoch: 26 [2560/45000 (6%)] Loss: 0.644046\n",
            "Train Epoch: 26 [3072/45000 (7%)] Loss: 0.477245\n",
            "Train Epoch: 26 [3584/45000 (8%)] Loss: 0.547631\n",
            "Train Epoch: 26 [4096/45000 (9%)] Loss: 0.587687\n",
            "Train Epoch: 26 [4608/45000 (10%)] Loss: 0.656220\n",
            "Train Epoch: 26 [5120/45000 (11%)] Loss: 0.412203\n",
            "Train Epoch: 26 [5632/45000 (13%)] Loss: 0.545797\n",
            "Train Epoch: 26 [6144/45000 (14%)] Loss: 0.495173\n",
            "Train Epoch: 26 [6656/45000 (15%)] Loss: 0.522146\n",
            "Train Epoch: 26 [7168/45000 (16%)] Loss: 0.477178\n",
            "Train Epoch: 26 [7680/45000 (17%)] Loss: 0.658322\n",
            "Train Epoch: 26 [8192/45000 (18%)] Loss: 0.530676\n",
            "Train Epoch: 26 [8704/45000 (19%)] Loss: 0.507452\n",
            "Train Epoch: 26 [9216/45000 (20%)] Loss: 0.510627\n",
            "Train Epoch: 26 [9728/45000 (22%)] Loss: 0.668575\n",
            "Train Epoch: 26 [10240/45000 (23%)] Loss: 0.591998\n",
            "Train Epoch: 26 [10752/45000 (24%)] Loss: 0.511805\n",
            "Train Epoch: 26 [11264/45000 (25%)] Loss: 0.918941\n",
            "Train Epoch: 26 [11776/45000 (26%)] Loss: 0.487516\n",
            "Train Epoch: 26 [12288/45000 (27%)] Loss: 0.559547\n",
            "Train Epoch: 26 [12800/45000 (28%)] Loss: 0.560957\n",
            "Train Epoch: 26 [13312/45000 (30%)] Loss: 0.699155\n",
            "Train Epoch: 26 [13824/45000 (31%)] Loss: 0.393651\n",
            "Train Epoch: 26 [14336/45000 (32%)] Loss: 0.548244\n",
            "Train Epoch: 26 [14848/45000 (33%)] Loss: 0.720169\n",
            "Train Epoch: 26 [15360/45000 (34%)] Loss: 0.703273\n",
            "Train Epoch: 26 [15872/45000 (35%)] Loss: 0.448763\n",
            "Train Epoch: 26 [16384/45000 (36%)] Loss: 0.609538\n",
            "Train Epoch: 26 [16896/45000 (38%)] Loss: 0.511883\n",
            "Train Epoch: 26 [17408/45000 (39%)] Loss: 0.606979\n",
            "Train Epoch: 26 [17920/45000 (40%)] Loss: 0.567402\n",
            "Train Epoch: 26 [18432/45000 (41%)] Loss: 0.426611\n",
            "Train Epoch: 26 [18944/45000 (42%)] Loss: 0.322249\n",
            "Train Epoch: 26 [19456/45000 (43%)] Loss: 0.468023\n",
            "Train Epoch: 26 [19968/45000 (44%)] Loss: 0.541256\n",
            "Train Epoch: 26 [20480/45000 (46%)] Loss: 0.668563\n",
            "Train Epoch: 26 [20992/45000 (47%)] Loss: 0.373048\n",
            "Train Epoch: 26 [21504/45000 (48%)] Loss: 0.461873\n",
            "Train Epoch: 26 [22016/45000 (49%)] Loss: 0.473112\n",
            "Train Epoch: 26 [22528/45000 (50%)] Loss: 0.389813\n",
            "Train Epoch: 26 [23040/45000 (51%)] Loss: 0.395510\n",
            "Train Epoch: 26 [23552/45000 (52%)] Loss: 0.463284\n",
            "Train Epoch: 26 [24064/45000 (53%)] Loss: 0.505537\n",
            "Train Epoch: 26 [24576/45000 (55%)] Loss: 0.525557\n",
            "Train Epoch: 26 [25088/45000 (56%)] Loss: 0.303209\n",
            "Train Epoch: 26 [25600/45000 (57%)] Loss: 0.479643\n",
            "Train Epoch: 26 [26112/45000 (58%)] Loss: 0.530657\n",
            "Train Epoch: 26 [26624/45000 (59%)] Loss: 0.560697\n",
            "Train Epoch: 26 [27136/45000 (60%)] Loss: 0.559512\n",
            "Train Epoch: 26 [27648/45000 (61%)] Loss: 0.663803\n",
            "Train Epoch: 26 [28160/45000 (63%)] Loss: 0.590894\n",
            "Train Epoch: 26 [28672/45000 (64%)] Loss: 0.785571\n",
            "Train Epoch: 26 [29184/45000 (65%)] Loss: 0.545641\n",
            "Train Epoch: 26 [29696/45000 (66%)] Loss: 0.602464\n",
            "Train Epoch: 26 [30208/45000 (67%)] Loss: 0.590392\n",
            "Train Epoch: 26 [30720/45000 (68%)] Loss: 0.532574\n",
            "Train Epoch: 26 [31232/45000 (69%)] Loss: 0.424201\n",
            "Train Epoch: 26 [31744/45000 (71%)] Loss: 0.589030\n",
            "Train Epoch: 26 [32256/45000 (72%)] Loss: 0.571289\n",
            "Train Epoch: 26 [32768/45000 (73%)] Loss: 0.502502\n",
            "Train Epoch: 26 [33280/45000 (74%)] Loss: 0.729099\n",
            "Train Epoch: 26 [33792/45000 (75%)] Loss: 0.628362\n",
            "Train Epoch: 26 [34304/45000 (76%)] Loss: 0.483296\n",
            "Train Epoch: 26 [34816/45000 (77%)] Loss: 0.598733\n",
            "Train Epoch: 26 [35328/45000 (79%)] Loss: 0.532251\n",
            "Train Epoch: 26 [35840/45000 (80%)] Loss: 0.506742\n",
            "Train Epoch: 26 [36352/45000 (81%)] Loss: 0.588650\n",
            "Train Epoch: 26 [36864/45000 (82%)] Loss: 0.598264\n",
            "Train Epoch: 26 [37376/45000 (83%)] Loss: 0.674712\n",
            "Train Epoch: 26 [37888/45000 (84%)] Loss: 0.528399\n",
            "Train Epoch: 26 [38400/45000 (85%)] Loss: 0.379255\n",
            "Train Epoch: 26 [38912/45000 (86%)] Loss: 0.555529\n",
            "Train Epoch: 26 [39424/45000 (88%)] Loss: 0.571545\n",
            "Train Epoch: 26 [39936/45000 (89%)] Loss: 0.503899\n",
            "Train Epoch: 26 [40448/45000 (90%)] Loss: 0.554263\n",
            "Train Epoch: 26 [40960/45000 (91%)] Loss: 0.458269\n",
            "Train Epoch: 26 [41472/45000 (92%)] Loss: 0.675075\n",
            "Train Epoch: 26 [41984/45000 (93%)] Loss: 0.506796\n",
            "Train Epoch: 26 [42496/45000 (94%)] Loss: 0.511390\n",
            "Train Epoch: 26 [43008/45000 (96%)] Loss: 0.441161\n",
            "Train Epoch: 26 [43520/45000 (97%)] Loss: 0.712308\n",
            "Train Epoch: 26 [44032/45000 (98%)] Loss: 0.479420\n",
            "Train Epoch: 26 [44544/45000 (99%)] Loss: 0.541487\n",
            "    epoch          : 26\n",
            "    loss           : 0.5615385187874463\n",
            "    accuracy       : 80.615234375\n",
            "    val_loss       : 0.6232940407493447\n",
            "    val_accuracy   : 78.79746835443038\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch26.pth ...\n",
            "Train Epoch: 27 [0/45000 (0%)] Loss: 0.503784\n",
            "Train Epoch: 27 [512/45000 (1%)] Loss: 0.567527\n",
            "Train Epoch: 27 [1024/45000 (2%)] Loss: 0.542991\n",
            "Train Epoch: 27 [1536/45000 (3%)] Loss: 0.760041\n",
            "Train Epoch: 27 [2048/45000 (5%)] Loss: 0.715700\n",
            "Train Epoch: 27 [2560/45000 (6%)] Loss: 0.413126\n",
            "Train Epoch: 27 [3072/45000 (7%)] Loss: 0.512572\n",
            "Train Epoch: 27 [3584/45000 (8%)] Loss: 0.696867\n",
            "Train Epoch: 27 [4096/45000 (9%)] Loss: 0.576858\n",
            "Train Epoch: 27 [4608/45000 (10%)] Loss: 0.614646\n",
            "Train Epoch: 27 [5120/45000 (11%)] Loss: 0.300750\n",
            "Train Epoch: 27 [5632/45000 (13%)] Loss: 0.700403\n",
            "Train Epoch: 27 [6144/45000 (14%)] Loss: 0.681970\n",
            "Train Epoch: 27 [6656/45000 (15%)] Loss: 0.641234\n",
            "Train Epoch: 27 [7168/45000 (16%)] Loss: 0.318029\n",
            "Train Epoch: 27 [7680/45000 (17%)] Loss: 0.647542\n",
            "Train Epoch: 27 [8192/45000 (18%)] Loss: 0.590061\n",
            "Train Epoch: 27 [8704/45000 (19%)] Loss: 0.530682\n",
            "Train Epoch: 27 [9216/45000 (20%)] Loss: 0.599511\n",
            "Train Epoch: 27 [9728/45000 (22%)] Loss: 0.469180\n",
            "Train Epoch: 27 [10240/45000 (23%)] Loss: 0.612694\n",
            "Train Epoch: 27 [10752/45000 (24%)] Loss: 0.476376\n",
            "Train Epoch: 27 [11264/45000 (25%)] Loss: 0.502277\n",
            "Train Epoch: 27 [11776/45000 (26%)] Loss: 0.791805\n",
            "Train Epoch: 27 [12288/45000 (27%)] Loss: 0.458754\n",
            "Train Epoch: 27 [12800/45000 (28%)] Loss: 0.460408\n",
            "Train Epoch: 27 [13312/45000 (30%)] Loss: 0.503323\n",
            "Train Epoch: 27 [13824/45000 (31%)] Loss: 0.632108\n",
            "Train Epoch: 27 [14336/45000 (32%)] Loss: 0.487669\n",
            "Train Epoch: 27 [14848/45000 (33%)] Loss: 0.443902\n",
            "Train Epoch: 27 [15360/45000 (34%)] Loss: 0.787761\n",
            "Train Epoch: 27 [15872/45000 (35%)] Loss: 0.671062\n",
            "Train Epoch: 27 [16384/45000 (36%)] Loss: 0.510975\n",
            "Train Epoch: 27 [16896/45000 (38%)] Loss: 0.586241\n",
            "Train Epoch: 27 [17408/45000 (39%)] Loss: 0.457641\n",
            "Train Epoch: 27 [17920/45000 (40%)] Loss: 0.569138\n",
            "Train Epoch: 27 [18432/45000 (41%)] Loss: 0.491816\n",
            "Train Epoch: 27 [18944/45000 (42%)] Loss: 0.649133\n",
            "Train Epoch: 27 [19456/45000 (43%)] Loss: 0.450884\n",
            "Train Epoch: 27 [19968/45000 (44%)] Loss: 0.627624\n",
            "Train Epoch: 27 [20480/45000 (46%)] Loss: 0.489226\n",
            "Train Epoch: 27 [20992/45000 (47%)] Loss: 0.797545\n",
            "Train Epoch: 27 [21504/45000 (48%)] Loss: 0.596422\n",
            "Train Epoch: 27 [22016/45000 (49%)] Loss: 0.468998\n",
            "Train Epoch: 27 [22528/45000 (50%)] Loss: 0.612746\n",
            "Train Epoch: 27 [23040/45000 (51%)] Loss: 0.696426\n",
            "Train Epoch: 27 [23552/45000 (52%)] Loss: 0.563802\n",
            "Train Epoch: 27 [24064/45000 (53%)] Loss: 0.513952\n",
            "Train Epoch: 27 [24576/45000 (55%)] Loss: 0.530674\n",
            "Train Epoch: 27 [25088/45000 (56%)] Loss: 0.661704\n",
            "Train Epoch: 27 [25600/45000 (57%)] Loss: 0.604999\n",
            "Train Epoch: 27 [26112/45000 (58%)] Loss: 0.621463\n",
            "Train Epoch: 27 [26624/45000 (59%)] Loss: 0.586198\n",
            "Train Epoch: 27 [27136/45000 (60%)] Loss: 0.545069\n",
            "Train Epoch: 27 [27648/45000 (61%)] Loss: 0.652378\n",
            "Train Epoch: 27 [28160/45000 (63%)] Loss: 0.529034\n",
            "Train Epoch: 27 [28672/45000 (64%)] Loss: 0.646561\n",
            "Train Epoch: 27 [29184/45000 (65%)] Loss: 0.590394\n",
            "Train Epoch: 27 [29696/45000 (66%)] Loss: 0.569182\n",
            "Train Epoch: 27 [30208/45000 (67%)] Loss: 0.597394\n",
            "Train Epoch: 27 [30720/45000 (68%)] Loss: 0.546607\n",
            "Train Epoch: 27 [31232/45000 (69%)] Loss: 0.508677\n",
            "Train Epoch: 27 [31744/45000 (71%)] Loss: 0.592119\n",
            "Train Epoch: 27 [32256/45000 (72%)] Loss: 0.313267\n",
            "Train Epoch: 27 [32768/45000 (73%)] Loss: 0.677928\n",
            "Train Epoch: 27 [33280/45000 (74%)] Loss: 0.614179\n",
            "Train Epoch: 27 [33792/45000 (75%)] Loss: 0.723751\n",
            "Train Epoch: 27 [34304/45000 (76%)] Loss: 0.336417\n",
            "Train Epoch: 27 [34816/45000 (77%)] Loss: 0.369548\n",
            "Train Epoch: 27 [35328/45000 (79%)] Loss: 0.618617\n",
            "Train Epoch: 27 [35840/45000 (80%)] Loss: 0.662103\n",
            "Train Epoch: 27 [36352/45000 (81%)] Loss: 0.535169\n",
            "Train Epoch: 27 [36864/45000 (82%)] Loss: 0.580745\n",
            "Train Epoch: 27 [37376/45000 (83%)] Loss: 0.601743\n",
            "Train Epoch: 27 [37888/45000 (84%)] Loss: 0.539238\n",
            "Train Epoch: 27 [38400/45000 (85%)] Loss: 0.350379\n",
            "Train Epoch: 27 [38912/45000 (86%)] Loss: 0.486399\n",
            "Train Epoch: 27 [39424/45000 (88%)] Loss: 0.732067\n",
            "Train Epoch: 27 [39936/45000 (89%)] Loss: 0.736704\n",
            "Train Epoch: 27 [40448/45000 (90%)] Loss: 0.369818\n",
            "Train Epoch: 27 [40960/45000 (91%)] Loss: 0.583121\n",
            "Train Epoch: 27 [41472/45000 (92%)] Loss: 0.332234\n",
            "Train Epoch: 27 [41984/45000 (93%)] Loss: 0.609654\n",
            "Train Epoch: 27 [42496/45000 (94%)] Loss: 0.562645\n",
            "Train Epoch: 27 [43008/45000 (96%)] Loss: 0.607774\n",
            "Train Epoch: 27 [43520/45000 (97%)] Loss: 0.488861\n",
            "Train Epoch: 27 [44032/45000 (98%)] Loss: 0.299897\n",
            "Train Epoch: 27 [44544/45000 (99%)] Loss: 0.542449\n",
            "    epoch          : 27\n",
            "    loss           : 0.5534354916731403\n",
            "    accuracy       : 80.96368963068181\n",
            "    val_loss       : 0.6210984376412404\n",
            "    val_accuracy   : 78.3623417721519\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch27.pth ...\n",
            "Train Epoch: 28 [0/45000 (0%)] Loss: 0.594094\n",
            "Train Epoch: 28 [512/45000 (1%)] Loss: 0.676870\n",
            "Train Epoch: 28 [1024/45000 (2%)] Loss: 0.698306\n",
            "Train Epoch: 28 [1536/45000 (3%)] Loss: 0.406075\n",
            "Train Epoch: 28 [2048/45000 (5%)] Loss: 0.535966\n",
            "Train Epoch: 28 [2560/45000 (6%)] Loss: 0.768046\n",
            "Train Epoch: 28 [3072/45000 (7%)] Loss: 0.593443\n",
            "Train Epoch: 28 [3584/45000 (8%)] Loss: 0.428208\n",
            "Train Epoch: 28 [4096/45000 (9%)] Loss: 0.409338\n",
            "Train Epoch: 28 [4608/45000 (10%)] Loss: 0.337848\n",
            "Train Epoch: 28 [5120/45000 (11%)] Loss: 0.431774\n",
            "Train Epoch: 28 [5632/45000 (13%)] Loss: 0.636748\n",
            "Train Epoch: 28 [6144/45000 (14%)] Loss: 0.397102\n",
            "Train Epoch: 28 [6656/45000 (15%)] Loss: 0.613258\n",
            "Train Epoch: 28 [7168/45000 (16%)] Loss: 0.695049\n",
            "Train Epoch: 28 [7680/45000 (17%)] Loss: 0.893269\n",
            "Train Epoch: 28 [8192/45000 (18%)] Loss: 0.721929\n",
            "Train Epoch: 28 [8704/45000 (19%)] Loss: 0.504646\n",
            "Train Epoch: 28 [9216/45000 (20%)] Loss: 0.543039\n",
            "Train Epoch: 28 [9728/45000 (22%)] Loss: 0.758364\n",
            "Train Epoch: 28 [10240/45000 (23%)] Loss: 0.621928\n",
            "Train Epoch: 28 [10752/45000 (24%)] Loss: 0.729330\n",
            "Train Epoch: 28 [11264/45000 (25%)] Loss: 0.563819\n",
            "Train Epoch: 28 [11776/45000 (26%)] Loss: 0.631335\n",
            "Train Epoch: 28 [12288/45000 (27%)] Loss: 0.486771\n",
            "Train Epoch: 28 [12800/45000 (28%)] Loss: 0.554249\n",
            "Train Epoch: 28 [13312/45000 (30%)] Loss: 0.705739\n",
            "Train Epoch: 28 [13824/45000 (31%)] Loss: 0.440725\n",
            "Train Epoch: 28 [14336/45000 (32%)] Loss: 0.586027\n",
            "Train Epoch: 28 [14848/45000 (33%)] Loss: 0.616460\n",
            "Train Epoch: 28 [15360/45000 (34%)] Loss: 0.608181\n",
            "Train Epoch: 28 [15872/45000 (35%)] Loss: 0.626506\n",
            "Train Epoch: 28 [16384/45000 (36%)] Loss: 0.638284\n",
            "Train Epoch: 28 [16896/45000 (38%)] Loss: 0.513634\n",
            "Train Epoch: 28 [17408/45000 (39%)] Loss: 0.708919\n",
            "Train Epoch: 28 [17920/45000 (40%)] Loss: 0.321619\n",
            "Train Epoch: 28 [18432/45000 (41%)] Loss: 0.717980\n",
            "Train Epoch: 28 [18944/45000 (42%)] Loss: 0.573150\n",
            "Train Epoch: 28 [19456/45000 (43%)] Loss: 0.468267\n",
            "Train Epoch: 28 [19968/45000 (44%)] Loss: 0.503524\n",
            "Train Epoch: 28 [20480/45000 (46%)] Loss: 0.609391\n",
            "Train Epoch: 28 [20992/45000 (47%)] Loss: 0.396764\n",
            "Train Epoch: 28 [21504/45000 (48%)] Loss: 0.540989\n",
            "Train Epoch: 28 [22016/45000 (49%)] Loss: 0.477884\n",
            "Train Epoch: 28 [22528/45000 (50%)] Loss: 0.449214\n",
            "Train Epoch: 28 [23040/45000 (51%)] Loss: 0.840180\n",
            "Train Epoch: 28 [23552/45000 (52%)] Loss: 0.557558\n",
            "Train Epoch: 28 [24064/45000 (53%)] Loss: 0.688766\n",
            "Train Epoch: 28 [24576/45000 (55%)] Loss: 0.686766\n",
            "Train Epoch: 28 [25088/45000 (56%)] Loss: 0.633922\n",
            "Train Epoch: 28 [25600/45000 (57%)] Loss: 0.767134\n",
            "Train Epoch: 28 [26112/45000 (58%)] Loss: 0.594294\n",
            "Train Epoch: 28 [26624/45000 (59%)] Loss: 0.525407\n",
            "Train Epoch: 28 [27136/45000 (60%)] Loss: 0.571355\n",
            "Train Epoch: 28 [27648/45000 (61%)] Loss: 0.477442\n",
            "Train Epoch: 28 [28160/45000 (63%)] Loss: 0.406712\n",
            "Train Epoch: 28 [28672/45000 (64%)] Loss: 0.569990\n",
            "Train Epoch: 28 [29184/45000 (65%)] Loss: 0.949900\n",
            "Train Epoch: 28 [29696/45000 (66%)] Loss: 0.586646\n",
            "Train Epoch: 28 [30208/45000 (67%)] Loss: 0.416490\n",
            "Train Epoch: 28 [30720/45000 (68%)] Loss: 0.545839\n",
            "Train Epoch: 28 [31232/45000 (69%)] Loss: 0.551102\n",
            "Train Epoch: 28 [31744/45000 (71%)] Loss: 0.510629\n",
            "Train Epoch: 28 [32256/45000 (72%)] Loss: 0.530712\n",
            "Train Epoch: 28 [32768/45000 (73%)] Loss: 0.560088\n",
            "Train Epoch: 28 [33280/45000 (74%)] Loss: 0.532023\n",
            "Train Epoch: 28 [33792/45000 (75%)] Loss: 0.504549\n",
            "Train Epoch: 28 [34304/45000 (76%)] Loss: 0.486485\n",
            "Train Epoch: 28 [34816/45000 (77%)] Loss: 0.520460\n",
            "Train Epoch: 28 [35328/45000 (79%)] Loss: 0.417465\n",
            "Train Epoch: 28 [35840/45000 (80%)] Loss: 0.629732\n",
            "Train Epoch: 28 [36352/45000 (81%)] Loss: 0.468726\n",
            "Train Epoch: 28 [36864/45000 (82%)] Loss: 0.411496\n",
            "Train Epoch: 28 [37376/45000 (83%)] Loss: 0.584773\n",
            "Train Epoch: 28 [37888/45000 (84%)] Loss: 0.592684\n",
            "Train Epoch: 28 [38400/45000 (85%)] Loss: 0.597337\n",
            "Train Epoch: 28 [38912/45000 (86%)] Loss: 0.401412\n",
            "Train Epoch: 28 [39424/45000 (88%)] Loss: 0.659156\n",
            "Train Epoch: 28 [39936/45000 (89%)] Loss: 0.458629\n",
            "Train Epoch: 28 [40448/45000 (90%)] Loss: 0.667058\n",
            "Train Epoch: 28 [40960/45000 (91%)] Loss: 0.534746\n",
            "Train Epoch: 28 [41472/45000 (92%)] Loss: 0.527213\n",
            "Train Epoch: 28 [41984/45000 (93%)] Loss: 0.587875\n",
            "Train Epoch: 28 [42496/45000 (94%)] Loss: 0.626619\n",
            "Train Epoch: 28 [43008/45000 (96%)] Loss: 0.421815\n",
            "Train Epoch: 28 [43520/45000 (97%)] Loss: 0.433889\n",
            "Train Epoch: 28 [44032/45000 (98%)] Loss: 0.428843\n",
            "Train Epoch: 28 [44544/45000 (99%)] Loss: 0.729432\n",
            "    epoch          : 28\n",
            "    loss           : 0.554531457093121\n",
            "    accuracy       : 81.18119673295455\n",
            "    val_loss       : 0.6130578815937042\n",
            "    val_accuracy   : 78.91613924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch28.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 29 [0/45000 (0%)] Loss: 0.589949\n",
            "Train Epoch: 29 [512/45000 (1%)] Loss: 0.567360\n",
            "Train Epoch: 29 [1024/45000 (2%)] Loss: 0.535715\n",
            "Train Epoch: 29 [1536/45000 (3%)] Loss: 0.675971\n",
            "Train Epoch: 29 [2048/45000 (5%)] Loss: 0.638347\n",
            "Train Epoch: 29 [2560/45000 (6%)] Loss: 0.458628\n",
            "Train Epoch: 29 [3072/45000 (7%)] Loss: 0.522950\n",
            "Train Epoch: 29 [3584/45000 (8%)] Loss: 0.525371\n",
            "Train Epoch: 29 [4096/45000 (9%)] Loss: 0.529511\n",
            "Train Epoch: 29 [4608/45000 (10%)] Loss: 0.494345\n",
            "Train Epoch: 29 [5120/45000 (11%)] Loss: 0.708922\n",
            "Train Epoch: 29 [5632/45000 (13%)] Loss: 0.560009\n",
            "Train Epoch: 29 [6144/45000 (14%)] Loss: 0.719169\n",
            "Train Epoch: 29 [6656/45000 (15%)] Loss: 0.461295\n",
            "Train Epoch: 29 [7168/45000 (16%)] Loss: 0.513089\n",
            "Train Epoch: 29 [7680/45000 (17%)] Loss: 0.508766\n",
            "Train Epoch: 29 [8192/45000 (18%)] Loss: 0.521594\n",
            "Train Epoch: 29 [8704/45000 (19%)] Loss: 0.463193\n",
            "Train Epoch: 29 [9216/45000 (20%)] Loss: 0.560088\n",
            "Train Epoch: 29 [9728/45000 (22%)] Loss: 0.443544\n",
            "Train Epoch: 29 [10240/45000 (23%)] Loss: 0.459116\n",
            "Train Epoch: 29 [10752/45000 (24%)] Loss: 0.434658\n",
            "Train Epoch: 29 [11264/45000 (25%)] Loss: 0.472327\n",
            "Train Epoch: 29 [11776/45000 (26%)] Loss: 0.453284\n",
            "Train Epoch: 29 [12288/45000 (27%)] Loss: 0.598361\n",
            "Train Epoch: 29 [12800/45000 (28%)] Loss: 0.513779\n",
            "Train Epoch: 29 [13312/45000 (30%)] Loss: 0.412044\n",
            "Train Epoch: 29 [13824/45000 (31%)] Loss: 0.724562\n",
            "Train Epoch: 29 [14336/45000 (32%)] Loss: 0.449315\n",
            "Train Epoch: 29 [14848/45000 (33%)] Loss: 0.636801\n",
            "Train Epoch: 29 [15360/45000 (34%)] Loss: 0.313382\n",
            "Train Epoch: 29 [15872/45000 (35%)] Loss: 0.650991\n",
            "Train Epoch: 29 [16384/45000 (36%)] Loss: 0.456749\n",
            "Train Epoch: 29 [16896/45000 (38%)] Loss: 0.543467\n",
            "Train Epoch: 29 [17408/45000 (39%)] Loss: 0.542799\n",
            "Train Epoch: 29 [17920/45000 (40%)] Loss: 0.514942\n",
            "Train Epoch: 29 [18432/45000 (41%)] Loss: 0.496666\n",
            "Train Epoch: 29 [18944/45000 (42%)] Loss: 0.548045\n",
            "Train Epoch: 29 [19456/45000 (43%)] Loss: 0.527397\n",
            "Train Epoch: 29 [19968/45000 (44%)] Loss: 0.603883\n",
            "Train Epoch: 29 [20480/45000 (46%)] Loss: 0.434330\n",
            "Train Epoch: 29 [20992/45000 (47%)] Loss: 0.812022\n",
            "Train Epoch: 29 [21504/45000 (48%)] Loss: 0.562417\n",
            "Train Epoch: 29 [22016/45000 (49%)] Loss: 0.701205\n",
            "Train Epoch: 29 [22528/45000 (50%)] Loss: 0.389253\n",
            "Train Epoch: 29 [23040/45000 (51%)] Loss: 0.539037\n",
            "Train Epoch: 29 [23552/45000 (52%)] Loss: 0.492049\n",
            "Train Epoch: 29 [24064/45000 (53%)] Loss: 0.410481\n",
            "Train Epoch: 29 [24576/45000 (55%)] Loss: 0.512081\n",
            "Train Epoch: 29 [25088/45000 (56%)] Loss: 0.417919\n",
            "Train Epoch: 29 [25600/45000 (57%)] Loss: 0.541107\n",
            "Train Epoch: 29 [26112/45000 (58%)] Loss: 0.485090\n",
            "Train Epoch: 29 [26624/45000 (59%)] Loss: 0.597049\n",
            "Train Epoch: 29 [27136/45000 (60%)] Loss: 0.304263\n",
            "Train Epoch: 29 [27648/45000 (61%)] Loss: 0.661435\n",
            "Train Epoch: 29 [28160/45000 (63%)] Loss: 0.472747\n",
            "Train Epoch: 29 [28672/45000 (64%)] Loss: 0.495601\n",
            "Train Epoch: 29 [29184/45000 (65%)] Loss: 0.479758\n",
            "Train Epoch: 29 [29696/45000 (66%)] Loss: 0.289696\n",
            "Train Epoch: 29 [30208/45000 (67%)] Loss: 0.523635\n",
            "Train Epoch: 29 [30720/45000 (68%)] Loss: 0.568613\n",
            "Train Epoch: 29 [31232/45000 (69%)] Loss: 0.488023\n",
            "Train Epoch: 29 [31744/45000 (71%)] Loss: 0.576892\n",
            "Train Epoch: 29 [32256/45000 (72%)] Loss: 0.533681\n",
            "Train Epoch: 29 [32768/45000 (73%)] Loss: 0.498252\n",
            "Train Epoch: 29 [33280/45000 (74%)] Loss: 0.623425\n",
            "Train Epoch: 29 [33792/45000 (75%)] Loss: 0.297369\n",
            "Train Epoch: 29 [34304/45000 (76%)] Loss: 0.517262\n",
            "Train Epoch: 29 [34816/45000 (77%)] Loss: 0.601879\n",
            "Train Epoch: 29 [35328/45000 (79%)] Loss: 0.467293\n",
            "Train Epoch: 29 [35840/45000 (80%)] Loss: 0.494780\n",
            "Train Epoch: 29 [36352/45000 (81%)] Loss: 0.437230\n",
            "Train Epoch: 29 [36864/45000 (82%)] Loss: 0.639880\n",
            "Train Epoch: 29 [37376/45000 (83%)] Loss: 0.611160\n",
            "Train Epoch: 29 [37888/45000 (84%)] Loss: 0.528967\n",
            "Train Epoch: 29 [38400/45000 (85%)] Loss: 0.698938\n",
            "Train Epoch: 29 [38912/45000 (86%)] Loss: 0.699643\n",
            "Train Epoch: 29 [39424/45000 (88%)] Loss: 0.760536\n",
            "Train Epoch: 29 [39936/45000 (89%)] Loss: 0.571283\n",
            "Train Epoch: 29 [40448/45000 (90%)] Loss: 0.743179\n",
            "Train Epoch: 29 [40960/45000 (91%)] Loss: 0.424263\n",
            "Train Epoch: 29 [41472/45000 (92%)] Loss: 0.596507\n",
            "Train Epoch: 29 [41984/45000 (93%)] Loss: 0.622742\n",
            "Train Epoch: 29 [42496/45000 (94%)] Loss: 0.429825\n",
            "Train Epoch: 29 [43008/45000 (96%)] Loss: 0.535550\n",
            "Train Epoch: 29 [43520/45000 (97%)] Loss: 0.586856\n",
            "Train Epoch: 29 [44032/45000 (98%)] Loss: 0.669990\n",
            "Train Epoch: 29 [44544/45000 (99%)] Loss: 0.446161\n",
            "    epoch          : 29\n",
            "    loss           : 0.5478356007740579\n",
            "    accuracy       : 81.2344637784091\n",
            "    val_loss       : 0.6047568313683136\n",
            "    val_accuracy   : 79.09414556962025\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch29.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 30 [0/45000 (0%)] Loss: 0.561047\n",
            "Train Epoch: 30 [512/45000 (1%)] Loss: 0.386813\n",
            "Train Epoch: 30 [1024/45000 (2%)] Loss: 0.618602\n",
            "Train Epoch: 30 [1536/45000 (3%)] Loss: 0.432408\n",
            "Train Epoch: 30 [2048/45000 (5%)] Loss: 0.422656\n",
            "Train Epoch: 30 [2560/45000 (6%)] Loss: 0.302802\n",
            "Train Epoch: 30 [3072/45000 (7%)] Loss: 0.495602\n",
            "Train Epoch: 30 [3584/45000 (8%)] Loss: 0.482310\n",
            "Train Epoch: 30 [4096/45000 (9%)] Loss: 0.485258\n",
            "Train Epoch: 30 [4608/45000 (10%)] Loss: 0.528477\n",
            "Train Epoch: 30 [5120/45000 (11%)] Loss: 0.459012\n",
            "Train Epoch: 30 [5632/45000 (13%)] Loss: 0.530414\n",
            "Train Epoch: 30 [6144/45000 (14%)] Loss: 0.498079\n",
            "Train Epoch: 30 [6656/45000 (15%)] Loss: 0.535529\n",
            "Train Epoch: 30 [7168/45000 (16%)] Loss: 0.565746\n",
            "Train Epoch: 30 [7680/45000 (17%)] Loss: 0.579314\n",
            "Train Epoch: 30 [8192/45000 (18%)] Loss: 0.561580\n",
            "Train Epoch: 30 [8704/45000 (19%)] Loss: 0.425832\n",
            "Train Epoch: 30 [9216/45000 (20%)] Loss: 0.457806\n",
            "Train Epoch: 30 [9728/45000 (22%)] Loss: 0.601365\n",
            "Train Epoch: 30 [10240/45000 (23%)] Loss: 0.342405\n",
            "Train Epoch: 30 [10752/45000 (24%)] Loss: 0.346939\n",
            "Train Epoch: 30 [11264/45000 (25%)] Loss: 0.403269\n",
            "Train Epoch: 30 [11776/45000 (26%)] Loss: 0.476606\n",
            "Train Epoch: 30 [12288/45000 (27%)] Loss: 0.600308\n",
            "Train Epoch: 30 [12800/45000 (28%)] Loss: 0.495418\n",
            "Train Epoch: 30 [13312/45000 (30%)] Loss: 0.401756\n",
            "Train Epoch: 30 [13824/45000 (31%)] Loss: 0.659417\n",
            "Train Epoch: 30 [14336/45000 (32%)] Loss: 0.663229\n",
            "Train Epoch: 30 [14848/45000 (33%)] Loss: 0.539414\n",
            "Train Epoch: 30 [15360/45000 (34%)] Loss: 0.516153\n",
            "Train Epoch: 30 [15872/45000 (35%)] Loss: 0.654417\n",
            "Train Epoch: 30 [16384/45000 (36%)] Loss: 0.502267\n",
            "Train Epoch: 30 [16896/45000 (38%)] Loss: 0.443238\n",
            "Train Epoch: 30 [17408/45000 (39%)] Loss: 0.501599\n",
            "Train Epoch: 30 [17920/45000 (40%)] Loss: 0.442603\n",
            "Train Epoch: 30 [18432/45000 (41%)] Loss: 0.549193\n",
            "Train Epoch: 30 [18944/45000 (42%)] Loss: 0.334359\n",
            "Train Epoch: 30 [19456/45000 (43%)] Loss: 0.804925\n",
            "Train Epoch: 30 [19968/45000 (44%)] Loss: 0.491201\n",
            "Train Epoch: 30 [20480/45000 (46%)] Loss: 0.626606\n",
            "Train Epoch: 30 [20992/45000 (47%)] Loss: 0.543387\n",
            "Train Epoch: 30 [21504/45000 (48%)] Loss: 0.527733\n",
            "Train Epoch: 30 [22016/45000 (49%)] Loss: 0.549444\n",
            "Train Epoch: 30 [22528/45000 (50%)] Loss: 0.505754\n",
            "Train Epoch: 30 [23040/45000 (51%)] Loss: 0.397626\n",
            "Train Epoch: 30 [23552/45000 (52%)] Loss: 0.620953\n",
            "Train Epoch: 30 [24064/45000 (53%)] Loss: 0.882648\n",
            "Train Epoch: 30 [24576/45000 (55%)] Loss: 0.658502\n",
            "Train Epoch: 30 [25088/45000 (56%)] Loss: 0.540355\n",
            "Train Epoch: 30 [25600/45000 (57%)] Loss: 0.494631\n",
            "Train Epoch: 30 [26112/45000 (58%)] Loss: 0.500541\n",
            "Train Epoch: 30 [26624/45000 (59%)] Loss: 0.564839\n",
            "Train Epoch: 30 [27136/45000 (60%)] Loss: 0.639203\n",
            "Train Epoch: 30 [27648/45000 (61%)] Loss: 0.565569\n",
            "Train Epoch: 30 [28160/45000 (63%)] Loss: 0.632933\n",
            "Train Epoch: 30 [28672/45000 (64%)] Loss: 0.445648\n",
            "Train Epoch: 30 [29184/45000 (65%)] Loss: 0.440603\n",
            "Train Epoch: 30 [29696/45000 (66%)] Loss: 0.544608\n",
            "Train Epoch: 30 [30208/45000 (67%)] Loss: 0.488699\n",
            "Train Epoch: 30 [30720/45000 (68%)] Loss: 0.592125\n",
            "Train Epoch: 30 [31232/45000 (69%)] Loss: 0.452882\n",
            "Train Epoch: 30 [31744/45000 (71%)] Loss: 0.418837\n",
            "Train Epoch: 30 [32256/45000 (72%)] Loss: 0.417731\n",
            "Train Epoch: 30 [32768/45000 (73%)] Loss: 0.650887\n",
            "Train Epoch: 30 [33280/45000 (74%)] Loss: 0.629332\n",
            "Train Epoch: 30 [33792/45000 (75%)] Loss: 0.641178\n",
            "Train Epoch: 30 [34304/45000 (76%)] Loss: 0.571278\n",
            "Train Epoch: 30 [34816/45000 (77%)] Loss: 0.510501\n",
            "Train Epoch: 30 [35328/45000 (79%)] Loss: 0.617968\n",
            "Train Epoch: 30 [35840/45000 (80%)] Loss: 0.555115\n",
            "Train Epoch: 30 [36352/45000 (81%)] Loss: 0.592498\n",
            "Train Epoch: 30 [36864/45000 (82%)] Loss: 0.501680\n",
            "Train Epoch: 30 [37376/45000 (83%)] Loss: 0.495849\n",
            "Train Epoch: 30 [37888/45000 (84%)] Loss: 0.587863\n",
            "Train Epoch: 30 [38400/45000 (85%)] Loss: 0.471911\n",
            "Train Epoch: 30 [38912/45000 (86%)] Loss: 0.486147\n",
            "Train Epoch: 30 [39424/45000 (88%)] Loss: 0.619242\n",
            "Train Epoch: 30 [39936/45000 (89%)] Loss: 0.762397\n",
            "Train Epoch: 30 [40448/45000 (90%)] Loss: 0.499527\n",
            "Train Epoch: 30 [40960/45000 (91%)] Loss: 0.630606\n",
            "Train Epoch: 30 [41472/45000 (92%)] Loss: 0.675671\n",
            "Train Epoch: 30 [41984/45000 (93%)] Loss: 0.623778\n",
            "Train Epoch: 30 [42496/45000 (94%)] Loss: 0.568440\n",
            "Train Epoch: 30 [43008/45000 (96%)] Loss: 0.510048\n",
            "Train Epoch: 30 [43520/45000 (97%)] Loss: 0.772530\n",
            "Train Epoch: 30 [44032/45000 (98%)] Loss: 0.755659\n",
            "Train Epoch: 30 [44544/45000 (99%)] Loss: 0.571123\n",
            "    epoch          : 30\n",
            "    loss           : 0.5491877488622611\n",
            "    accuracy       : 81.1922940340909\n",
            "    val_loss       : 0.6201933954335466\n",
            "    val_accuracy   : 78.5007911392405\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch30.pth ...\n",
            "Train Epoch: 31 [0/45000 (0%)] Loss: 0.415610\n",
            "Train Epoch: 31 [512/45000 (1%)] Loss: 0.484511\n",
            "Train Epoch: 31 [1024/45000 (2%)] Loss: 0.526293\n",
            "Train Epoch: 31 [1536/45000 (3%)] Loss: 0.642431\n",
            "Train Epoch: 31 [2048/45000 (5%)] Loss: 0.421463\n",
            "Train Epoch: 31 [2560/45000 (6%)] Loss: 0.401370\n",
            "Train Epoch: 31 [3072/45000 (7%)] Loss: 0.554931\n",
            "Train Epoch: 31 [3584/45000 (8%)] Loss: 0.418694\n",
            "Train Epoch: 31 [4096/45000 (9%)] Loss: 0.420642\n",
            "Train Epoch: 31 [4608/45000 (10%)] Loss: 0.451508\n",
            "Train Epoch: 31 [5120/45000 (11%)] Loss: 0.568474\n",
            "Train Epoch: 31 [5632/45000 (13%)] Loss: 0.530226\n",
            "Train Epoch: 31 [6144/45000 (14%)] Loss: 0.668535\n",
            "Train Epoch: 31 [6656/45000 (15%)] Loss: 0.553911\n",
            "Train Epoch: 31 [7168/45000 (16%)] Loss: 0.503735\n",
            "Train Epoch: 31 [7680/45000 (17%)] Loss: 0.446486\n",
            "Train Epoch: 31 [8192/45000 (18%)] Loss: 0.534061\n",
            "Train Epoch: 31 [8704/45000 (19%)] Loss: 0.520946\n",
            "Train Epoch: 31 [9216/45000 (20%)] Loss: 0.624017\n",
            "Train Epoch: 31 [9728/45000 (22%)] Loss: 0.654974\n",
            "Train Epoch: 31 [10240/45000 (23%)] Loss: 0.557076\n",
            "Train Epoch: 31 [10752/45000 (24%)] Loss: 0.404606\n",
            "Train Epoch: 31 [11264/45000 (25%)] Loss: 0.877299\n",
            "Train Epoch: 31 [11776/45000 (26%)] Loss: 0.629760\n",
            "Train Epoch: 31 [12288/45000 (27%)] Loss: 0.519478\n",
            "Train Epoch: 31 [12800/45000 (28%)] Loss: 0.405227\n",
            "Train Epoch: 31 [13312/45000 (30%)] Loss: 0.575129\n",
            "Train Epoch: 31 [13824/45000 (31%)] Loss: 0.546373\n",
            "Train Epoch: 31 [14336/45000 (32%)] Loss: 0.371897\n",
            "Train Epoch: 31 [14848/45000 (33%)] Loss: 0.487949\n",
            "Train Epoch: 31 [15360/45000 (34%)] Loss: 0.439158\n",
            "Train Epoch: 31 [15872/45000 (35%)] Loss: 0.488832\n",
            "Train Epoch: 31 [16384/45000 (36%)] Loss: 0.550182\n",
            "Train Epoch: 31 [16896/45000 (38%)] Loss: 0.582203\n",
            "Train Epoch: 31 [17408/45000 (39%)] Loss: 0.525831\n",
            "Train Epoch: 31 [17920/45000 (40%)] Loss: 0.451448\n",
            "Train Epoch: 31 [18432/45000 (41%)] Loss: 0.502582\n",
            "Train Epoch: 31 [18944/45000 (42%)] Loss: 0.516282\n",
            "Train Epoch: 31 [19456/45000 (43%)] Loss: 0.479938\n",
            "Train Epoch: 31 [19968/45000 (44%)] Loss: 0.503366\n",
            "Train Epoch: 31 [20480/45000 (46%)] Loss: 0.338928\n",
            "Train Epoch: 31 [20992/45000 (47%)] Loss: 0.709556\n",
            "Train Epoch: 31 [21504/45000 (48%)] Loss: 0.644602\n",
            "Train Epoch: 31 [22016/45000 (49%)] Loss: 0.511346\n",
            "Train Epoch: 31 [22528/45000 (50%)] Loss: 0.422547\n",
            "Train Epoch: 31 [23040/45000 (51%)] Loss: 0.463356\n",
            "Train Epoch: 31 [23552/45000 (52%)] Loss: 0.629756\n",
            "Train Epoch: 31 [24064/45000 (53%)] Loss: 0.562817\n",
            "Train Epoch: 31 [24576/45000 (55%)] Loss: 0.378021\n",
            "Train Epoch: 31 [25088/45000 (56%)] Loss: 0.389782\n",
            "Train Epoch: 31 [25600/45000 (57%)] Loss: 0.560823\n",
            "Train Epoch: 31 [26112/45000 (58%)] Loss: 0.509976\n",
            "Train Epoch: 31 [26624/45000 (59%)] Loss: 0.581531\n",
            "Train Epoch: 31 [27136/45000 (60%)] Loss: 0.525484\n",
            "Train Epoch: 31 [27648/45000 (61%)] Loss: 0.600950\n",
            "Train Epoch: 31 [28160/45000 (63%)] Loss: 0.498063\n",
            "Train Epoch: 31 [28672/45000 (64%)] Loss: 0.450374\n",
            "Train Epoch: 31 [29184/45000 (65%)] Loss: 0.460213\n",
            "Train Epoch: 31 [29696/45000 (66%)] Loss: 0.510201\n",
            "Train Epoch: 31 [30208/45000 (67%)] Loss: 0.339929\n",
            "Train Epoch: 31 [30720/45000 (68%)] Loss: 0.559458\n",
            "Train Epoch: 31 [31232/45000 (69%)] Loss: 0.386915\n",
            "Train Epoch: 31 [31744/45000 (71%)] Loss: 0.434786\n",
            "Train Epoch: 31 [32256/45000 (72%)] Loss: 0.424312\n",
            "Train Epoch: 31 [32768/45000 (73%)] Loss: 0.365037\n",
            "Train Epoch: 31 [33280/45000 (74%)] Loss: 0.576525\n",
            "Train Epoch: 31 [33792/45000 (75%)] Loss: 0.595160\n",
            "Train Epoch: 31 [34304/45000 (76%)] Loss: 0.518296\n",
            "Train Epoch: 31 [34816/45000 (77%)] Loss: 0.498914\n",
            "Train Epoch: 31 [35328/45000 (79%)] Loss: 0.478791\n",
            "Train Epoch: 31 [35840/45000 (80%)] Loss: 0.597040\n",
            "Train Epoch: 31 [36352/45000 (81%)] Loss: 0.582484\n",
            "Train Epoch: 31 [36864/45000 (82%)] Loss: 0.603770\n",
            "Train Epoch: 31 [37376/45000 (83%)] Loss: 0.586644\n",
            "Train Epoch: 31 [37888/45000 (84%)] Loss: 0.616194\n",
            "Train Epoch: 31 [38400/45000 (85%)] Loss: 0.550654\n",
            "Train Epoch: 31 [38912/45000 (86%)] Loss: 0.675744\n",
            "Train Epoch: 31 [39424/45000 (88%)] Loss: 0.625343\n",
            "Train Epoch: 31 [39936/45000 (89%)] Loss: 0.602998\n",
            "Train Epoch: 31 [40448/45000 (90%)] Loss: 0.479047\n",
            "Train Epoch: 31 [40960/45000 (91%)] Loss: 0.547050\n",
            "Train Epoch: 31 [41472/45000 (92%)] Loss: 0.425422\n",
            "Train Epoch: 31 [41984/45000 (93%)] Loss: 0.722331\n",
            "Train Epoch: 31 [42496/45000 (94%)] Loss: 0.478434\n",
            "Train Epoch: 31 [43008/45000 (96%)] Loss: 0.687687\n",
            "Train Epoch: 31 [43520/45000 (97%)] Loss: 0.481889\n",
            "Train Epoch: 31 [44032/45000 (98%)] Loss: 0.457300\n",
            "Train Epoch: 31 [44544/45000 (99%)] Loss: 0.543762\n",
            "    epoch          : 31\n",
            "    loss           : 0.5412765740924939\n",
            "    accuracy       : 81.3631924715909\n",
            "    val_loss       : 0.6068799507014359\n",
            "    val_accuracy   : 78.63924050632912\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch31.pth ...\n",
            "Train Epoch: 32 [0/45000 (0%)] Loss: 0.479392\n",
            "Train Epoch: 32 [512/45000 (1%)] Loss: 0.594293\n",
            "Train Epoch: 32 [1024/45000 (2%)] Loss: 0.736670\n",
            "Train Epoch: 32 [1536/45000 (3%)] Loss: 0.780304\n",
            "Train Epoch: 32 [2048/45000 (5%)] Loss: 0.549171\n",
            "Train Epoch: 32 [2560/45000 (6%)] Loss: 0.429745\n",
            "Train Epoch: 32 [3072/45000 (7%)] Loss: 0.720925\n",
            "Train Epoch: 32 [3584/45000 (8%)] Loss: 0.458307\n",
            "Train Epoch: 32 [4096/45000 (9%)] Loss: 0.608960\n",
            "Train Epoch: 32 [4608/45000 (10%)] Loss: 0.432263\n",
            "Train Epoch: 32 [5120/45000 (11%)] Loss: 0.699530\n",
            "Train Epoch: 32 [5632/45000 (13%)] Loss: 0.580598\n",
            "Train Epoch: 32 [6144/45000 (14%)] Loss: 0.505030\n",
            "Train Epoch: 32 [6656/45000 (15%)] Loss: 0.469481\n",
            "Train Epoch: 32 [7168/45000 (16%)] Loss: 0.702018\n",
            "Train Epoch: 32 [7680/45000 (17%)] Loss: 0.564986\n",
            "Train Epoch: 32 [8192/45000 (18%)] Loss: 0.555119\n",
            "Train Epoch: 32 [8704/45000 (19%)] Loss: 0.507444\n",
            "Train Epoch: 32 [9216/45000 (20%)] Loss: 0.532143\n",
            "Train Epoch: 32 [9728/45000 (22%)] Loss: 0.631023\n",
            "Train Epoch: 32 [10240/45000 (23%)] Loss: 0.394099\n",
            "Train Epoch: 32 [10752/45000 (24%)] Loss: 0.479707\n",
            "Train Epoch: 32 [11264/45000 (25%)] Loss: 0.414682\n",
            "Train Epoch: 32 [11776/45000 (26%)] Loss: 0.697755\n",
            "Train Epoch: 32 [12288/45000 (27%)] Loss: 0.616366\n",
            "Train Epoch: 32 [12800/45000 (28%)] Loss: 0.534559\n",
            "Train Epoch: 32 [13312/45000 (30%)] Loss: 0.522255\n",
            "Train Epoch: 32 [13824/45000 (31%)] Loss: 0.612791\n",
            "Train Epoch: 32 [14336/45000 (32%)] Loss: 0.393129\n",
            "Train Epoch: 32 [14848/45000 (33%)] Loss: 0.535029\n",
            "Train Epoch: 32 [15360/45000 (34%)] Loss: 0.602702\n",
            "Train Epoch: 32 [15872/45000 (35%)] Loss: 0.543787\n",
            "Train Epoch: 32 [16384/45000 (36%)] Loss: 0.512976\n",
            "Train Epoch: 32 [16896/45000 (38%)] Loss: 0.557428\n",
            "Train Epoch: 32 [17408/45000 (39%)] Loss: 0.675228\n",
            "Train Epoch: 32 [17920/45000 (40%)] Loss: 0.602504\n",
            "Train Epoch: 32 [18432/45000 (41%)] Loss: 0.527346\n",
            "Train Epoch: 32 [18944/45000 (42%)] Loss: 0.374298\n",
            "Train Epoch: 32 [19456/45000 (43%)] Loss: 0.620853\n",
            "Train Epoch: 32 [19968/45000 (44%)] Loss: 0.372613\n",
            "Train Epoch: 32 [20480/45000 (46%)] Loss: 0.405364\n",
            "Train Epoch: 32 [20992/45000 (47%)] Loss: 0.525852\n",
            "Train Epoch: 32 [21504/45000 (48%)] Loss: 0.518665\n",
            "Train Epoch: 32 [22016/45000 (49%)] Loss: 0.447027\n",
            "Train Epoch: 32 [22528/45000 (50%)] Loss: 0.752962\n",
            "Train Epoch: 32 [23040/45000 (51%)] Loss: 0.473296\n",
            "Train Epoch: 32 [23552/45000 (52%)] Loss: 0.436182\n",
            "Train Epoch: 32 [24064/45000 (53%)] Loss: 0.513295\n",
            "Train Epoch: 32 [24576/45000 (55%)] Loss: 0.454931\n",
            "Train Epoch: 32 [25088/45000 (56%)] Loss: 0.444803\n",
            "Train Epoch: 32 [25600/45000 (57%)] Loss: 0.406950\n",
            "Train Epoch: 32 [26112/45000 (58%)] Loss: 0.523403\n",
            "Train Epoch: 32 [26624/45000 (59%)] Loss: 0.555798\n",
            "Train Epoch: 32 [27136/45000 (60%)] Loss: 0.528337\n",
            "Train Epoch: 32 [27648/45000 (61%)] Loss: 0.671642\n",
            "Train Epoch: 32 [28160/45000 (63%)] Loss: 0.592497\n",
            "Train Epoch: 32 [28672/45000 (64%)] Loss: 0.431211\n",
            "Train Epoch: 32 [29184/45000 (65%)] Loss: 0.555137\n",
            "Train Epoch: 32 [29696/45000 (66%)] Loss: 0.355583\n",
            "Train Epoch: 32 [30208/45000 (67%)] Loss: 0.533753\n",
            "Train Epoch: 32 [30720/45000 (68%)] Loss: 0.665959\n",
            "Train Epoch: 32 [31232/45000 (69%)] Loss: 0.631504\n",
            "Train Epoch: 32 [31744/45000 (71%)] Loss: 0.332912\n",
            "Train Epoch: 32 [32256/45000 (72%)] Loss: 0.490725\n",
            "Train Epoch: 32 [32768/45000 (73%)] Loss: 0.549498\n",
            "Train Epoch: 32 [33280/45000 (74%)] Loss: 0.406832\n",
            "Train Epoch: 32 [33792/45000 (75%)] Loss: 0.566400\n",
            "Train Epoch: 32 [34304/45000 (76%)] Loss: 0.568245\n",
            "Train Epoch: 32 [34816/45000 (77%)] Loss: 0.454019\n",
            "Train Epoch: 32 [35328/45000 (79%)] Loss: 0.588575\n",
            "Train Epoch: 32 [35840/45000 (80%)] Loss: 0.457309\n",
            "Train Epoch: 32 [36352/45000 (81%)] Loss: 0.892261\n",
            "Train Epoch: 32 [36864/45000 (82%)] Loss: 0.467234\n",
            "Train Epoch: 32 [37376/45000 (83%)] Loss: 0.518761\n",
            "Train Epoch: 32 [37888/45000 (84%)] Loss: 0.347225\n",
            "Train Epoch: 32 [38400/45000 (85%)] Loss: 0.545843\n",
            "Train Epoch: 32 [38912/45000 (86%)] Loss: 0.683214\n",
            "Train Epoch: 32 [39424/45000 (88%)] Loss: 0.533029\n",
            "Train Epoch: 32 [39936/45000 (89%)] Loss: 0.577269\n",
            "Train Epoch: 32 [40448/45000 (90%)] Loss: 0.580701\n",
            "Train Epoch: 32 [40960/45000 (91%)] Loss: 0.550071\n",
            "Train Epoch: 32 [41472/45000 (92%)] Loss: 0.561181\n",
            "Train Epoch: 32 [41984/45000 (93%)] Loss: 0.584304\n",
            "Train Epoch: 32 [42496/45000 (94%)] Loss: 0.444264\n",
            "Train Epoch: 32 [43008/45000 (96%)] Loss: 0.654357\n",
            "Train Epoch: 32 [43520/45000 (97%)] Loss: 0.530465\n",
            "Train Epoch: 32 [44032/45000 (98%)] Loss: 0.716487\n",
            "Train Epoch: 32 [44544/45000 (99%)] Loss: 0.354509\n",
            "    epoch          : 32\n",
            "    loss           : 0.5386785691688684\n",
            "    accuracy       : 81.57404119318181\n",
            "    val_loss       : 0.6128281287000149\n",
            "    val_accuracy   : 78.75791139240506\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch32.pth ...\n",
            "Train Epoch: 33 [0/45000 (0%)] Loss: 0.633723\n",
            "Train Epoch: 33 [512/45000 (1%)] Loss: 0.727532\n",
            "Train Epoch: 33 [1024/45000 (2%)] Loss: 0.557775\n",
            "Train Epoch: 33 [1536/45000 (3%)] Loss: 0.595396\n",
            "Train Epoch: 33 [2048/45000 (5%)] Loss: 0.525474\n",
            "Train Epoch: 33 [2560/45000 (6%)] Loss: 0.530158\n",
            "Train Epoch: 33 [3072/45000 (7%)] Loss: 0.814557\n",
            "Train Epoch: 33 [3584/45000 (8%)] Loss: 0.418401\n",
            "Train Epoch: 33 [4096/45000 (9%)] Loss: 0.465133\n",
            "Train Epoch: 33 [4608/45000 (10%)] Loss: 0.585306\n",
            "Train Epoch: 33 [5120/45000 (11%)] Loss: 0.860854\n",
            "Train Epoch: 33 [5632/45000 (13%)] Loss: 0.546228\n",
            "Train Epoch: 33 [6144/45000 (14%)] Loss: 0.433673\n",
            "Train Epoch: 33 [6656/45000 (15%)] Loss: 0.562618\n",
            "Train Epoch: 33 [7168/45000 (16%)] Loss: 0.560395\n",
            "Train Epoch: 33 [7680/45000 (17%)] Loss: 0.565664\n",
            "Train Epoch: 33 [8192/45000 (18%)] Loss: 0.627365\n",
            "Train Epoch: 33 [8704/45000 (19%)] Loss: 0.498425\n",
            "Train Epoch: 33 [9216/45000 (20%)] Loss: 0.665768\n",
            "Train Epoch: 33 [9728/45000 (22%)] Loss: 0.533009\n",
            "Train Epoch: 33 [10240/45000 (23%)] Loss: 0.418133\n",
            "Train Epoch: 33 [10752/45000 (24%)] Loss: 0.495241\n",
            "Train Epoch: 33 [11264/45000 (25%)] Loss: 0.553284\n",
            "Train Epoch: 33 [11776/45000 (26%)] Loss: 0.335530\n",
            "Train Epoch: 33 [12288/45000 (27%)] Loss: 0.661378\n",
            "Train Epoch: 33 [12800/45000 (28%)] Loss: 0.341318\n",
            "Train Epoch: 33 [13312/45000 (30%)] Loss: 0.414205\n",
            "Train Epoch: 33 [13824/45000 (31%)] Loss: 0.445254\n",
            "Train Epoch: 33 [14336/45000 (32%)] Loss: 0.636076\n",
            "Train Epoch: 33 [14848/45000 (33%)] Loss: 0.664885\n",
            "Train Epoch: 33 [15360/45000 (34%)] Loss: 0.423111\n",
            "Train Epoch: 33 [15872/45000 (35%)] Loss: 0.755727\n",
            "Train Epoch: 33 [16384/45000 (36%)] Loss: 0.572478\n",
            "Train Epoch: 33 [16896/45000 (38%)] Loss: 0.536971\n",
            "Train Epoch: 33 [17408/45000 (39%)] Loss: 0.508621\n",
            "Train Epoch: 33 [17920/45000 (40%)] Loss: 0.378423\n",
            "Train Epoch: 33 [18432/45000 (41%)] Loss: 0.524606\n",
            "Train Epoch: 33 [18944/45000 (42%)] Loss: 0.493963\n",
            "Train Epoch: 33 [19456/45000 (43%)] Loss: 0.427094\n",
            "Train Epoch: 33 [19968/45000 (44%)] Loss: 0.536478\n",
            "Train Epoch: 33 [20480/45000 (46%)] Loss: 0.587168\n",
            "Train Epoch: 33 [20992/45000 (47%)] Loss: 0.481274\n",
            "Train Epoch: 33 [21504/45000 (48%)] Loss: 0.487200\n",
            "Train Epoch: 33 [22016/45000 (49%)] Loss: 0.472932\n",
            "Train Epoch: 33 [22528/45000 (50%)] Loss: 0.518587\n",
            "Train Epoch: 33 [23040/45000 (51%)] Loss: 0.567551\n",
            "Train Epoch: 33 [23552/45000 (52%)] Loss: 0.381066\n",
            "Train Epoch: 33 [24064/45000 (53%)] Loss: 0.462873\n",
            "Train Epoch: 33 [24576/45000 (55%)] Loss: 0.415048\n",
            "Train Epoch: 33 [25088/45000 (56%)] Loss: 0.458013\n",
            "Train Epoch: 33 [25600/45000 (57%)] Loss: 0.792479\n",
            "Train Epoch: 33 [26112/45000 (58%)] Loss: 0.641938\n",
            "Train Epoch: 33 [26624/45000 (59%)] Loss: 0.729974\n",
            "Train Epoch: 33 [27136/45000 (60%)] Loss: 0.688799\n",
            "Train Epoch: 33 [27648/45000 (61%)] Loss: 0.478105\n",
            "Train Epoch: 33 [28160/45000 (63%)] Loss: 0.474367\n",
            "Train Epoch: 33 [28672/45000 (64%)] Loss: 0.474376\n",
            "Train Epoch: 33 [29184/45000 (65%)] Loss: 0.595396\n",
            "Train Epoch: 33 [29696/45000 (66%)] Loss: 0.600421\n",
            "Train Epoch: 33 [30208/45000 (67%)] Loss: 0.379733\n",
            "Train Epoch: 33 [30720/45000 (68%)] Loss: 0.648840\n",
            "Train Epoch: 33 [31232/45000 (69%)] Loss: 0.433186\n",
            "Train Epoch: 33 [31744/45000 (71%)] Loss: 0.414521\n",
            "Train Epoch: 33 [32256/45000 (72%)] Loss: 0.665388\n",
            "Train Epoch: 33 [32768/45000 (73%)] Loss: 0.486367\n",
            "Train Epoch: 33 [33280/45000 (74%)] Loss: 0.467047\n",
            "Train Epoch: 33 [33792/45000 (75%)] Loss: 0.467857\n",
            "Train Epoch: 33 [34304/45000 (76%)] Loss: 0.583504\n",
            "Train Epoch: 33 [34816/45000 (77%)] Loss: 0.597951\n",
            "Train Epoch: 33 [35328/45000 (79%)] Loss: 0.548429\n",
            "Train Epoch: 33 [35840/45000 (80%)] Loss: 0.606441\n",
            "Train Epoch: 33 [36352/45000 (81%)] Loss: 0.448391\n",
            "Train Epoch: 33 [36864/45000 (82%)] Loss: 0.397777\n",
            "Train Epoch: 33 [37376/45000 (83%)] Loss: 0.460701\n",
            "Train Epoch: 33 [37888/45000 (84%)] Loss: 0.432027\n",
            "Train Epoch: 33 [38400/45000 (85%)] Loss: 0.719263\n",
            "Train Epoch: 33 [38912/45000 (86%)] Loss: 0.421326\n",
            "Train Epoch: 33 [39424/45000 (88%)] Loss: 0.786724\n",
            "Train Epoch: 33 [39936/45000 (89%)] Loss: 0.390069\n",
            "Train Epoch: 33 [40448/45000 (90%)] Loss: 0.419531\n",
            "Train Epoch: 33 [40960/45000 (91%)] Loss: 0.708431\n",
            "Train Epoch: 33 [41472/45000 (92%)] Loss: 0.790338\n",
            "Train Epoch: 33 [41984/45000 (93%)] Loss: 0.670171\n",
            "Train Epoch: 33 [42496/45000 (94%)] Loss: 0.636525\n",
            "Train Epoch: 33 [43008/45000 (96%)] Loss: 0.716259\n",
            "Train Epoch: 33 [43520/45000 (97%)] Loss: 0.432335\n",
            "Train Epoch: 33 [44032/45000 (98%)] Loss: 0.709317\n",
            "Train Epoch: 33 [44544/45000 (99%)] Loss: 0.923250\n",
            "    epoch          : 33\n",
            "    loss           : 0.5416627718897705\n",
            "    accuracy       : 81.40092329545455\n",
            "    val_loss       : 0.6020670067283171\n",
            "    val_accuracy   : 79.29193037974683\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch33.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 34 [0/45000 (0%)] Loss: 0.543749\n",
            "Train Epoch: 34 [512/45000 (1%)] Loss: 0.409132\n",
            "Train Epoch: 34 [1024/45000 (2%)] Loss: 0.577716\n",
            "Train Epoch: 34 [1536/45000 (3%)] Loss: 0.559817\n",
            "Train Epoch: 34 [2048/45000 (5%)] Loss: 0.483103\n",
            "Train Epoch: 34 [2560/45000 (6%)] Loss: 0.472115\n",
            "Train Epoch: 34 [3072/45000 (7%)] Loss: 0.543656\n",
            "Train Epoch: 34 [3584/45000 (8%)] Loss: 0.708251\n",
            "Train Epoch: 34 [4096/45000 (9%)] Loss: 0.468778\n",
            "Train Epoch: 34 [4608/45000 (10%)] Loss: 0.483415\n",
            "Train Epoch: 34 [5120/45000 (11%)] Loss: 0.670870\n",
            "Train Epoch: 34 [5632/45000 (13%)] Loss: 0.562880\n",
            "Train Epoch: 34 [6144/45000 (14%)] Loss: 0.631226\n",
            "Train Epoch: 34 [6656/45000 (15%)] Loss: 0.568708\n",
            "Train Epoch: 34 [7168/45000 (16%)] Loss: 0.534906\n",
            "Train Epoch: 34 [7680/45000 (17%)] Loss: 0.631759\n",
            "Train Epoch: 34 [8192/45000 (18%)] Loss: 0.833362\n",
            "Train Epoch: 34 [8704/45000 (19%)] Loss: 0.351039\n",
            "Train Epoch: 34 [9216/45000 (20%)] Loss: 0.584044\n",
            "Train Epoch: 34 [9728/45000 (22%)] Loss: 0.573775\n",
            "Train Epoch: 34 [10240/45000 (23%)] Loss: 0.494056\n",
            "Train Epoch: 34 [10752/45000 (24%)] Loss: 0.549986\n",
            "Train Epoch: 34 [11264/45000 (25%)] Loss: 0.644117\n",
            "Train Epoch: 34 [11776/45000 (26%)] Loss: 0.739603\n",
            "Train Epoch: 34 [12288/45000 (27%)] Loss: 0.571299\n",
            "Train Epoch: 34 [12800/45000 (28%)] Loss: 0.611752\n",
            "Train Epoch: 34 [13312/45000 (30%)] Loss: 0.698912\n",
            "Train Epoch: 34 [13824/45000 (31%)] Loss: 0.635360\n",
            "Train Epoch: 34 [14336/45000 (32%)] Loss: 0.496557\n",
            "Train Epoch: 34 [14848/45000 (33%)] Loss: 0.480054\n",
            "Train Epoch: 34 [15360/45000 (34%)] Loss: 0.533493\n",
            "Train Epoch: 34 [15872/45000 (35%)] Loss: 0.513482\n",
            "Train Epoch: 34 [16384/45000 (36%)] Loss: 0.699415\n",
            "Train Epoch: 34 [16896/45000 (38%)] Loss: 0.712247\n",
            "Train Epoch: 34 [17408/45000 (39%)] Loss: 0.522380\n",
            "Train Epoch: 34 [17920/45000 (40%)] Loss: 0.546018\n",
            "Train Epoch: 34 [18432/45000 (41%)] Loss: 0.573475\n",
            "Train Epoch: 34 [18944/45000 (42%)] Loss: 0.394605\n",
            "Train Epoch: 34 [19456/45000 (43%)] Loss: 0.624770\n",
            "Train Epoch: 34 [19968/45000 (44%)] Loss: 0.446442\n",
            "Train Epoch: 34 [20480/45000 (46%)] Loss: 0.573256\n",
            "Train Epoch: 34 [20992/45000 (47%)] Loss: 0.573007\n",
            "Train Epoch: 34 [21504/45000 (48%)] Loss: 0.379785\n",
            "Train Epoch: 34 [22016/45000 (49%)] Loss: 0.496816\n",
            "Train Epoch: 34 [22528/45000 (50%)] Loss: 0.566899\n",
            "Train Epoch: 34 [23040/45000 (51%)] Loss: 0.576993\n",
            "Train Epoch: 34 [23552/45000 (52%)] Loss: 0.570773\n",
            "Train Epoch: 34 [24064/45000 (53%)] Loss: 0.536672\n",
            "Train Epoch: 34 [24576/45000 (55%)] Loss: 0.572794\n",
            "Train Epoch: 34 [25088/45000 (56%)] Loss: 0.314274\n",
            "Train Epoch: 34 [25600/45000 (57%)] Loss: 0.637863\n",
            "Train Epoch: 34 [26112/45000 (58%)] Loss: 0.630327\n",
            "Train Epoch: 34 [26624/45000 (59%)] Loss: 0.463115\n",
            "Train Epoch: 34 [27136/45000 (60%)] Loss: 0.760211\n",
            "Train Epoch: 34 [27648/45000 (61%)] Loss: 0.303435\n",
            "Train Epoch: 34 [28160/45000 (63%)] Loss: 0.653422\n",
            "Train Epoch: 34 [28672/45000 (64%)] Loss: 0.508141\n",
            "Train Epoch: 34 [29184/45000 (65%)] Loss: 0.650660\n",
            "Train Epoch: 34 [29696/45000 (66%)] Loss: 0.523795\n",
            "Train Epoch: 34 [30208/45000 (67%)] Loss: 0.289290\n",
            "Train Epoch: 34 [30720/45000 (68%)] Loss: 0.350812\n",
            "Train Epoch: 34 [31232/45000 (69%)] Loss: 0.514331\n",
            "Train Epoch: 34 [31744/45000 (71%)] Loss: 0.471174\n",
            "Train Epoch: 34 [32256/45000 (72%)] Loss: 0.503331\n",
            "Train Epoch: 34 [32768/45000 (73%)] Loss: 0.465075\n",
            "Train Epoch: 34 [33280/45000 (74%)] Loss: 0.526176\n",
            "Train Epoch: 34 [33792/45000 (75%)] Loss: 0.558258\n",
            "Train Epoch: 34 [34304/45000 (76%)] Loss: 0.579540\n",
            "Train Epoch: 34 [34816/45000 (77%)] Loss: 0.668895\n",
            "Train Epoch: 34 [35328/45000 (79%)] Loss: 0.544961\n",
            "Train Epoch: 34 [35840/45000 (80%)] Loss: 0.470185\n",
            "Train Epoch: 34 [36352/45000 (81%)] Loss: 0.532195\n",
            "Train Epoch: 34 [36864/45000 (82%)] Loss: 0.623572\n",
            "Train Epoch: 34 [37376/45000 (83%)] Loss: 0.622317\n",
            "Train Epoch: 34 [37888/45000 (84%)] Loss: 0.402220\n",
            "Train Epoch: 34 [38400/45000 (85%)] Loss: 0.658429\n",
            "Train Epoch: 34 [38912/45000 (86%)] Loss: 0.525354\n",
            "Train Epoch: 34 [39424/45000 (88%)] Loss: 0.579165\n",
            "Train Epoch: 34 [39936/45000 (89%)] Loss: 0.632366\n",
            "Train Epoch: 34 [40448/45000 (90%)] Loss: 0.658924\n",
            "Train Epoch: 34 [40960/45000 (91%)] Loss: 0.401227\n",
            "Train Epoch: 34 [41472/45000 (92%)] Loss: 0.611090\n",
            "Train Epoch: 34 [41984/45000 (93%)] Loss: 0.586684\n",
            "Train Epoch: 34 [42496/45000 (94%)] Loss: 0.541299\n",
            "Train Epoch: 34 [43008/45000 (96%)] Loss: 0.420173\n",
            "Train Epoch: 34 [43520/45000 (97%)] Loss: 0.581767\n",
            "Train Epoch: 34 [44032/45000 (98%)] Loss: 0.643430\n",
            "Train Epoch: 34 [44544/45000 (99%)] Loss: 0.436514\n",
            "    epoch          : 34\n",
            "    loss           : 0.5417229962873865\n",
            "    accuracy       : 81.66725852272727\n",
            "    val_loss       : 0.6209229419503031\n",
            "    val_accuracy   : 79.01503164556962\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch34.pth ...\n",
            "Train Epoch: 35 [0/45000 (0%)] Loss: 0.595562\n",
            "Train Epoch: 35 [512/45000 (1%)] Loss: 0.550075\n",
            "Train Epoch: 35 [1024/45000 (2%)] Loss: 0.440819\n",
            "Train Epoch: 35 [1536/45000 (3%)] Loss: 0.586832\n",
            "Train Epoch: 35 [2048/45000 (5%)] Loss: 0.428387\n",
            "Train Epoch: 35 [2560/45000 (6%)] Loss: 0.563607\n",
            "Train Epoch: 35 [3072/45000 (7%)] Loss: 0.560870\n",
            "Train Epoch: 35 [3584/45000 (8%)] Loss: 0.368150\n",
            "Train Epoch: 35 [4096/45000 (9%)] Loss: 0.439728\n",
            "Train Epoch: 35 [4608/45000 (10%)] Loss: 0.433349\n",
            "Train Epoch: 35 [5120/45000 (11%)] Loss: 0.454902\n",
            "Train Epoch: 35 [5632/45000 (13%)] Loss: 0.304603\n",
            "Train Epoch: 35 [6144/45000 (14%)] Loss: 0.455696\n",
            "Train Epoch: 35 [6656/45000 (15%)] Loss: 0.390305\n",
            "Train Epoch: 35 [7168/45000 (16%)] Loss: 0.457946\n",
            "Train Epoch: 35 [7680/45000 (17%)] Loss: 0.438819\n",
            "Train Epoch: 35 [8192/45000 (18%)] Loss: 0.419737\n",
            "Train Epoch: 35 [8704/45000 (19%)] Loss: 0.475439\n",
            "Train Epoch: 35 [9216/45000 (20%)] Loss: 0.635647\n",
            "Train Epoch: 35 [9728/45000 (22%)] Loss: 0.546158\n",
            "Train Epoch: 35 [10240/45000 (23%)] Loss: 0.458706\n",
            "Train Epoch: 35 [10752/45000 (24%)] Loss: 0.444666\n",
            "Train Epoch: 35 [11264/45000 (25%)] Loss: 0.685792\n",
            "Train Epoch: 35 [11776/45000 (26%)] Loss: 0.634285\n",
            "Train Epoch: 35 [12288/45000 (27%)] Loss: 0.583531\n",
            "Train Epoch: 35 [12800/45000 (28%)] Loss: 0.502914\n",
            "Train Epoch: 35 [13312/45000 (30%)] Loss: 0.681108\n",
            "Train Epoch: 35 [13824/45000 (31%)] Loss: 0.569664\n",
            "Train Epoch: 35 [14336/45000 (32%)] Loss: 0.439136\n",
            "Train Epoch: 35 [14848/45000 (33%)] Loss: 0.454689\n",
            "Train Epoch: 35 [15360/45000 (34%)] Loss: 0.569266\n",
            "Train Epoch: 35 [15872/45000 (35%)] Loss: 0.577100\n",
            "Train Epoch: 35 [16384/45000 (36%)] Loss: 0.596117\n",
            "Train Epoch: 35 [16896/45000 (38%)] Loss: 0.669787\n",
            "Train Epoch: 35 [17408/45000 (39%)] Loss: 0.523675\n",
            "Train Epoch: 35 [17920/45000 (40%)] Loss: 0.578837\n",
            "Train Epoch: 35 [18432/45000 (41%)] Loss: 0.563315\n",
            "Train Epoch: 35 [18944/45000 (42%)] Loss: 0.495408\n",
            "Train Epoch: 35 [19456/45000 (43%)] Loss: 0.492910\n",
            "Train Epoch: 35 [19968/45000 (44%)] Loss: 0.516431\n",
            "Train Epoch: 35 [20480/45000 (46%)] Loss: 0.459412\n",
            "Train Epoch: 35 [20992/45000 (47%)] Loss: 0.566838\n",
            "Train Epoch: 35 [21504/45000 (48%)] Loss: 0.533770\n",
            "Train Epoch: 35 [22016/45000 (49%)] Loss: 0.589800\n",
            "Train Epoch: 35 [22528/45000 (50%)] Loss: 0.796554\n",
            "Train Epoch: 35 [23040/45000 (51%)] Loss: 0.629762\n",
            "Train Epoch: 35 [23552/45000 (52%)] Loss: 0.313727\n",
            "Train Epoch: 35 [24064/45000 (53%)] Loss: 0.572410\n",
            "Train Epoch: 35 [24576/45000 (55%)] Loss: 0.530444\n",
            "Train Epoch: 35 [25088/45000 (56%)] Loss: 0.681248\n",
            "Train Epoch: 35 [25600/45000 (57%)] Loss: 0.472883\n",
            "Train Epoch: 35 [26112/45000 (58%)] Loss: 0.424943\n",
            "Train Epoch: 35 [26624/45000 (59%)] Loss: 0.433361\n",
            "Train Epoch: 35 [27136/45000 (60%)] Loss: 0.512100\n",
            "Train Epoch: 35 [27648/45000 (61%)] Loss: 0.571675\n",
            "Train Epoch: 35 [28160/45000 (63%)] Loss: 0.526861\n",
            "Train Epoch: 35 [28672/45000 (64%)] Loss: 0.397422\n",
            "Train Epoch: 35 [29184/45000 (65%)] Loss: 0.520909\n",
            "Train Epoch: 35 [29696/45000 (66%)] Loss: 0.633469\n",
            "Train Epoch: 35 [30208/45000 (67%)] Loss: 0.562326\n",
            "Train Epoch: 35 [30720/45000 (68%)] Loss: 0.527503\n",
            "Train Epoch: 35 [31232/45000 (69%)] Loss: 0.593204\n",
            "Train Epoch: 35 [31744/45000 (71%)] Loss: 0.576519\n",
            "Train Epoch: 35 [32256/45000 (72%)] Loss: 0.556437\n",
            "Train Epoch: 35 [32768/45000 (73%)] Loss: 0.484853\n",
            "Train Epoch: 35 [33280/45000 (74%)] Loss: 0.557830\n",
            "Train Epoch: 35 [33792/45000 (75%)] Loss: 0.482100\n",
            "Train Epoch: 35 [34304/45000 (76%)] Loss: 0.530582\n",
            "Train Epoch: 35 [34816/45000 (77%)] Loss: 0.588591\n",
            "Train Epoch: 35 [35328/45000 (79%)] Loss: 0.534085\n",
            "Train Epoch: 35 [35840/45000 (80%)] Loss: 0.837379\n",
            "Train Epoch: 35 [36352/45000 (81%)] Loss: 0.532510\n",
            "Train Epoch: 35 [36864/45000 (82%)] Loss: 0.538757\n",
            "Train Epoch: 35 [37376/45000 (83%)] Loss: 0.584715\n",
            "Train Epoch: 35 [37888/45000 (84%)] Loss: 0.602752\n",
            "Train Epoch: 35 [38400/45000 (85%)] Loss: 0.496248\n",
            "Train Epoch: 35 [38912/45000 (86%)] Loss: 0.633991\n",
            "Train Epoch: 35 [39424/45000 (88%)] Loss: 0.494130\n",
            "Train Epoch: 35 [39936/45000 (89%)] Loss: 0.392007\n",
            "Train Epoch: 35 [40448/45000 (90%)] Loss: 0.507914\n",
            "Train Epoch: 35 [40960/45000 (91%)] Loss: 0.578788\n",
            "Train Epoch: 35 [41472/45000 (92%)] Loss: 0.292561\n",
            "Train Epoch: 35 [41984/45000 (93%)] Loss: 0.421637\n",
            "Train Epoch: 35 [42496/45000 (94%)] Loss: 0.506832\n",
            "Train Epoch: 35 [43008/45000 (96%)] Loss: 0.387102\n",
            "Train Epoch: 35 [43520/45000 (97%)] Loss: 0.655484\n",
            "Train Epoch: 35 [44032/45000 (98%)] Loss: 0.705258\n",
            "Train Epoch: 35 [44544/45000 (99%)] Loss: 0.507545\n",
            "    epoch          : 35\n",
            "    loss           : 0.541532183997333\n",
            "    accuracy       : 81.45862926136364\n",
            "    val_loss       : 0.6343818374826938\n",
            "    val_accuracy   : 78.32278481012658\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch35.pth ...\n",
            "Train Epoch: 36 [0/45000 (0%)] Loss: 0.431117\n",
            "Train Epoch: 36 [512/45000 (1%)] Loss: 0.552597\n",
            "Train Epoch: 36 [1024/45000 (2%)] Loss: 0.601393\n",
            "Train Epoch: 36 [1536/45000 (3%)] Loss: 0.637082\n",
            "Train Epoch: 36 [2048/45000 (5%)] Loss: 0.558318\n",
            "Train Epoch: 36 [2560/45000 (6%)] Loss: 0.563693\n",
            "Train Epoch: 36 [3072/45000 (7%)] Loss: 0.491602\n",
            "Train Epoch: 36 [3584/45000 (8%)] Loss: 0.598373\n",
            "Train Epoch: 36 [4096/45000 (9%)] Loss: 0.526936\n",
            "Train Epoch: 36 [4608/45000 (10%)] Loss: 0.398806\n",
            "Train Epoch: 36 [5120/45000 (11%)] Loss: 0.640413\n",
            "Train Epoch: 36 [5632/45000 (13%)] Loss: 0.449899\n",
            "Train Epoch: 36 [6144/45000 (14%)] Loss: 0.767675\n",
            "Train Epoch: 36 [6656/45000 (15%)] Loss: 0.527460\n",
            "Train Epoch: 36 [7168/45000 (16%)] Loss: 0.375748\n",
            "Train Epoch: 36 [7680/45000 (17%)] Loss: 0.436970\n",
            "Train Epoch: 36 [8192/45000 (18%)] Loss: 0.426885\n",
            "Train Epoch: 36 [8704/45000 (19%)] Loss: 0.482218\n",
            "Train Epoch: 36 [9216/45000 (20%)] Loss: 0.661697\n",
            "Train Epoch: 36 [9728/45000 (22%)] Loss: 0.475521\n",
            "Train Epoch: 36 [10240/45000 (23%)] Loss: 0.381280\n",
            "Train Epoch: 36 [10752/45000 (24%)] Loss: 0.691521\n",
            "Train Epoch: 36 [11264/45000 (25%)] Loss: 0.508087\n",
            "Train Epoch: 36 [11776/45000 (26%)] Loss: 0.576657\n",
            "Train Epoch: 36 [12288/45000 (27%)] Loss: 0.591000\n",
            "Train Epoch: 36 [12800/45000 (28%)] Loss: 0.439880\n",
            "Train Epoch: 36 [13312/45000 (30%)] Loss: 0.462427\n",
            "Train Epoch: 36 [13824/45000 (31%)] Loss: 0.632412\n",
            "Train Epoch: 36 [14336/45000 (32%)] Loss: 0.622509\n",
            "Train Epoch: 36 [14848/45000 (33%)] Loss: 0.456312\n",
            "Train Epoch: 36 [15360/45000 (34%)] Loss: 0.672483\n",
            "Train Epoch: 36 [15872/45000 (35%)] Loss: 0.576076\n",
            "Train Epoch: 36 [16384/45000 (36%)] Loss: 0.376451\n",
            "Train Epoch: 36 [16896/45000 (38%)] Loss: 0.390746\n",
            "Train Epoch: 36 [17408/45000 (39%)] Loss: 0.394804\n",
            "Train Epoch: 36 [17920/45000 (40%)] Loss: 0.629479\n",
            "Train Epoch: 36 [18432/45000 (41%)] Loss: 0.565026\n",
            "Train Epoch: 36 [18944/45000 (42%)] Loss: 0.682447\n",
            "Train Epoch: 36 [19456/45000 (43%)] Loss: 0.516786\n",
            "Train Epoch: 36 [19968/45000 (44%)] Loss: 0.459064\n",
            "Train Epoch: 36 [20480/45000 (46%)] Loss: 0.557515\n",
            "Train Epoch: 36 [20992/45000 (47%)] Loss: 0.529587\n",
            "Train Epoch: 36 [21504/45000 (48%)] Loss: 0.657202\n",
            "Train Epoch: 36 [22016/45000 (49%)] Loss: 0.322082\n",
            "Train Epoch: 36 [22528/45000 (50%)] Loss: 0.588329\n",
            "Train Epoch: 36 [23040/45000 (51%)] Loss: 0.511079\n",
            "Train Epoch: 36 [23552/45000 (52%)] Loss: 0.512293\n",
            "Train Epoch: 36 [24064/45000 (53%)] Loss: 0.487230\n",
            "Train Epoch: 36 [24576/45000 (55%)] Loss: 0.692528\n",
            "Train Epoch: 36 [25088/45000 (56%)] Loss: 0.494734\n",
            "Train Epoch: 36 [25600/45000 (57%)] Loss: 0.569015\n",
            "Train Epoch: 36 [26112/45000 (58%)] Loss: 0.413406\n",
            "Train Epoch: 36 [26624/45000 (59%)] Loss: 0.476589\n",
            "Train Epoch: 36 [27136/45000 (60%)] Loss: 0.631073\n",
            "Train Epoch: 36 [27648/45000 (61%)] Loss: 0.444282\n",
            "Train Epoch: 36 [28160/45000 (63%)] Loss: 0.536825\n",
            "Train Epoch: 36 [28672/45000 (64%)] Loss: 0.470185\n",
            "Train Epoch: 36 [29184/45000 (65%)] Loss: 0.555333\n",
            "Train Epoch: 36 [29696/45000 (66%)] Loss: 0.546227\n",
            "Train Epoch: 36 [30208/45000 (67%)] Loss: 0.456121\n",
            "Train Epoch: 36 [30720/45000 (68%)] Loss: 0.418127\n",
            "Train Epoch: 36 [31232/45000 (69%)] Loss: 0.534891\n",
            "Train Epoch: 36 [31744/45000 (71%)] Loss: 0.589334\n",
            "Train Epoch: 36 [32256/45000 (72%)] Loss: 0.627025\n",
            "Train Epoch: 36 [32768/45000 (73%)] Loss: 0.603345\n",
            "Train Epoch: 36 [33280/45000 (74%)] Loss: 0.494934\n",
            "Train Epoch: 36 [33792/45000 (75%)] Loss: 0.458237\n",
            "Train Epoch: 36 [34304/45000 (76%)] Loss: 0.544617\n",
            "Train Epoch: 36 [34816/45000 (77%)] Loss: 0.471572\n",
            "Train Epoch: 36 [35328/45000 (79%)] Loss: 0.555651\n",
            "Train Epoch: 36 [35840/45000 (80%)] Loss: 0.402055\n",
            "Train Epoch: 36 [36352/45000 (81%)] Loss: 0.514851\n",
            "Train Epoch: 36 [36864/45000 (82%)] Loss: 0.622138\n",
            "Train Epoch: 36 [37376/45000 (83%)] Loss: 0.509738\n",
            "Train Epoch: 36 [37888/45000 (84%)] Loss: 0.661450\n",
            "Train Epoch: 36 [38400/45000 (85%)] Loss: 0.388655\n",
            "Train Epoch: 36 [38912/45000 (86%)] Loss: 0.718691\n",
            "Train Epoch: 36 [39424/45000 (88%)] Loss: 0.438481\n",
            "Train Epoch: 36 [39936/45000 (89%)] Loss: 0.480823\n",
            "Train Epoch: 36 [40448/45000 (90%)] Loss: 0.508505\n",
            "Train Epoch: 36 [40960/45000 (91%)] Loss: 0.344463\n",
            "Train Epoch: 36 [41472/45000 (92%)] Loss: 0.451701\n",
            "Train Epoch: 36 [41984/45000 (93%)] Loss: 0.671810\n",
            "Train Epoch: 36 [42496/45000 (94%)] Loss: 0.619707\n",
            "Train Epoch: 36 [43008/45000 (96%)] Loss: 0.563601\n",
            "Train Epoch: 36 [43520/45000 (97%)] Loss: 0.524411\n",
            "Train Epoch: 36 [44032/45000 (98%)] Loss: 0.657276\n",
            "Train Epoch: 36 [44544/45000 (99%)] Loss: 0.648944\n",
            "    epoch          : 36\n",
            "    loss           : 0.5350177847060629\n",
            "    accuracy       : 81.66947798295455\n",
            "    val_loss       : 0.6164174660851683\n",
            "    val_accuracy   : 79.13370253164557\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch36.pth ...\n",
            "Train Epoch: 37 [0/45000 (0%)] Loss: 0.418882\n",
            "Train Epoch: 37 [512/45000 (1%)] Loss: 0.579791\n",
            "Train Epoch: 37 [1024/45000 (2%)] Loss: 0.505570\n",
            "Train Epoch: 37 [1536/45000 (3%)] Loss: 0.551333\n",
            "Train Epoch: 37 [2048/45000 (5%)] Loss: 0.490356\n",
            "Train Epoch: 37 [2560/45000 (6%)] Loss: 0.473890\n",
            "Train Epoch: 37 [3072/45000 (7%)] Loss: 0.859546\n",
            "Train Epoch: 37 [3584/45000 (8%)] Loss: 0.436070\n",
            "Train Epoch: 37 [4096/45000 (9%)] Loss: 0.397769\n",
            "Train Epoch: 37 [4608/45000 (10%)] Loss: 0.465304\n",
            "Train Epoch: 37 [5120/45000 (11%)] Loss: 0.604239\n",
            "Train Epoch: 37 [5632/45000 (13%)] Loss: 0.427032\n",
            "Train Epoch: 37 [6144/45000 (14%)] Loss: 0.468227\n",
            "Train Epoch: 37 [6656/45000 (15%)] Loss: 0.419818\n",
            "Train Epoch: 37 [7168/45000 (16%)] Loss: 0.413274\n",
            "Train Epoch: 37 [7680/45000 (17%)] Loss: 0.502447\n",
            "Train Epoch: 37 [8192/45000 (18%)] Loss: 0.586343\n",
            "Train Epoch: 37 [8704/45000 (19%)] Loss: 0.517556\n",
            "Train Epoch: 37 [9216/45000 (20%)] Loss: 0.429392\n",
            "Train Epoch: 37 [9728/45000 (22%)] Loss: 0.451754\n",
            "Train Epoch: 37 [10240/45000 (23%)] Loss: 0.509189\n",
            "Train Epoch: 37 [10752/45000 (24%)] Loss: 0.483687\n",
            "Train Epoch: 37 [11264/45000 (25%)] Loss: 0.417230\n",
            "Train Epoch: 37 [11776/45000 (26%)] Loss: 0.520829\n",
            "Train Epoch: 37 [12288/45000 (27%)] Loss: 0.441583\n",
            "Train Epoch: 37 [12800/45000 (28%)] Loss: 0.530675\n",
            "Train Epoch: 37 [13312/45000 (30%)] Loss: 0.467869\n",
            "Train Epoch: 37 [13824/45000 (31%)] Loss: 0.501025\n",
            "Train Epoch: 37 [14336/45000 (32%)] Loss: 0.518301\n",
            "Train Epoch: 37 [14848/45000 (33%)] Loss: 0.465320\n",
            "Train Epoch: 37 [15360/45000 (34%)] Loss: 0.604583\n",
            "Train Epoch: 37 [15872/45000 (35%)] Loss: 0.725643\n",
            "Train Epoch: 37 [16384/45000 (36%)] Loss: 0.440949\n",
            "Train Epoch: 37 [16896/45000 (38%)] Loss: 0.489701\n",
            "Train Epoch: 37 [17408/45000 (39%)] Loss: 0.477660\n",
            "Train Epoch: 37 [17920/45000 (40%)] Loss: 0.456623\n",
            "Train Epoch: 37 [18432/45000 (41%)] Loss: 0.553408\n",
            "Train Epoch: 37 [18944/45000 (42%)] Loss: 0.570419\n",
            "Train Epoch: 37 [19456/45000 (43%)] Loss: 0.423790\n",
            "Train Epoch: 37 [19968/45000 (44%)] Loss: 0.617666\n",
            "Train Epoch: 37 [20480/45000 (46%)] Loss: 0.468881\n",
            "Train Epoch: 37 [20992/45000 (47%)] Loss: 0.336646\n",
            "Train Epoch: 37 [21504/45000 (48%)] Loss: 0.434199\n",
            "Train Epoch: 37 [22016/45000 (49%)] Loss: 0.404916\n",
            "Train Epoch: 37 [22528/45000 (50%)] Loss: 0.484140\n",
            "Train Epoch: 37 [23040/45000 (51%)] Loss: 0.453446\n",
            "Train Epoch: 37 [23552/45000 (52%)] Loss: 0.609890\n",
            "Train Epoch: 37 [24064/45000 (53%)] Loss: 0.762321\n",
            "Train Epoch: 37 [24576/45000 (55%)] Loss: 0.490814\n",
            "Train Epoch: 37 [25088/45000 (56%)] Loss: 0.481050\n",
            "Train Epoch: 37 [25600/45000 (57%)] Loss: 0.489953\n",
            "Train Epoch: 37 [26112/45000 (58%)] Loss: 0.606876\n",
            "Train Epoch: 37 [26624/45000 (59%)] Loss: 0.508833\n",
            "Train Epoch: 37 [27136/45000 (60%)] Loss: 0.561904\n",
            "Train Epoch: 37 [27648/45000 (61%)] Loss: 0.520625\n",
            "Train Epoch: 37 [28160/45000 (63%)] Loss: 0.569462\n",
            "Train Epoch: 37 [28672/45000 (64%)] Loss: 0.541792\n",
            "Train Epoch: 37 [29184/45000 (65%)] Loss: 0.322511\n",
            "Train Epoch: 37 [29696/45000 (66%)] Loss: 0.641420\n",
            "Train Epoch: 37 [30208/45000 (67%)] Loss: 0.559652\n",
            "Train Epoch: 37 [30720/45000 (68%)] Loss: 0.557949\n",
            "Train Epoch: 37 [31232/45000 (69%)] Loss: 0.652355\n",
            "Train Epoch: 37 [31744/45000 (71%)] Loss: 0.566836\n",
            "Train Epoch: 37 [32256/45000 (72%)] Loss: 0.590175\n",
            "Train Epoch: 37 [32768/45000 (73%)] Loss: 0.473147\n",
            "Train Epoch: 37 [33280/45000 (74%)] Loss: 0.280709\n",
            "Train Epoch: 37 [33792/45000 (75%)] Loss: 0.669948\n",
            "Train Epoch: 37 [34304/45000 (76%)] Loss: 0.584480\n",
            "Train Epoch: 37 [34816/45000 (77%)] Loss: 0.620499\n",
            "Train Epoch: 37 [35328/45000 (79%)] Loss: 0.493133\n",
            "Train Epoch: 37 [35840/45000 (80%)] Loss: 0.491414\n",
            "Train Epoch: 37 [36352/45000 (81%)] Loss: 0.518434\n",
            "Train Epoch: 37 [36864/45000 (82%)] Loss: 0.566631\n",
            "Train Epoch: 37 [37376/45000 (83%)] Loss: 0.391950\n",
            "Train Epoch: 37 [37888/45000 (84%)] Loss: 0.601411\n",
            "Train Epoch: 37 [38400/45000 (85%)] Loss: 0.408766\n",
            "Train Epoch: 37 [38912/45000 (86%)] Loss: 0.371601\n",
            "Train Epoch: 37 [39424/45000 (88%)] Loss: 0.469980\n",
            "Train Epoch: 37 [39936/45000 (89%)] Loss: 0.483034\n",
            "Train Epoch: 37 [40448/45000 (90%)] Loss: 0.388637\n",
            "Train Epoch: 37 [40960/45000 (91%)] Loss: 0.609010\n",
            "Train Epoch: 37 [41472/45000 (92%)] Loss: 0.398922\n",
            "Train Epoch: 37 [41984/45000 (93%)] Loss: 0.576181\n",
            "Train Epoch: 37 [42496/45000 (94%)] Loss: 0.685425\n",
            "Train Epoch: 37 [43008/45000 (96%)] Loss: 0.557726\n",
            "Train Epoch: 37 [43520/45000 (97%)] Loss: 0.465210\n",
            "Train Epoch: 37 [44032/45000 (98%)] Loss: 0.516724\n",
            "Train Epoch: 37 [44544/45000 (99%)] Loss: 0.597230\n",
            "    epoch          : 37\n",
            "    loss           : 0.537109408442947\n",
            "    accuracy       : 81.8758877840909\n",
            "    val_loss       : 0.6060731544902053\n",
            "    val_accuracy   : 79.48971518987342\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch37.pth ...\n",
            "Train Epoch: 38 [0/45000 (0%)] Loss: 0.685049\n",
            "Train Epoch: 38 [512/45000 (1%)] Loss: 0.394373\n",
            "Train Epoch: 38 [1024/45000 (2%)] Loss: 0.619029\n",
            "Train Epoch: 38 [1536/45000 (3%)] Loss: 0.463393\n",
            "Train Epoch: 38 [2048/45000 (5%)] Loss: 0.562708\n",
            "Train Epoch: 38 [2560/45000 (6%)] Loss: 0.568681\n",
            "Train Epoch: 38 [3072/45000 (7%)] Loss: 0.530208\n",
            "Train Epoch: 38 [3584/45000 (8%)] Loss: 0.539723\n",
            "Train Epoch: 38 [4096/45000 (9%)] Loss: 0.313764\n",
            "Train Epoch: 38 [4608/45000 (10%)] Loss: 0.411241\n",
            "Train Epoch: 38 [5120/45000 (11%)] Loss: 0.495799\n",
            "Train Epoch: 38 [5632/45000 (13%)] Loss: 0.363888\n",
            "Train Epoch: 38 [6144/45000 (14%)] Loss: 0.672411\n",
            "Train Epoch: 38 [6656/45000 (15%)] Loss: 0.490663\n",
            "Train Epoch: 38 [7168/45000 (16%)] Loss: 0.388104\n",
            "Train Epoch: 38 [7680/45000 (17%)] Loss: 0.788712\n",
            "Train Epoch: 38 [8192/45000 (18%)] Loss: 0.624289\n",
            "Train Epoch: 38 [8704/45000 (19%)] Loss: 0.539548\n",
            "Train Epoch: 38 [9216/45000 (20%)] Loss: 0.544733\n",
            "Train Epoch: 38 [9728/45000 (22%)] Loss: 0.568661\n",
            "Train Epoch: 38 [10240/45000 (23%)] Loss: 0.384179\n",
            "Train Epoch: 38 [10752/45000 (24%)] Loss: 0.516796\n",
            "Train Epoch: 38 [11264/45000 (25%)] Loss: 0.459865\n",
            "Train Epoch: 38 [11776/45000 (26%)] Loss: 0.473769\n",
            "Train Epoch: 38 [12288/45000 (27%)] Loss: 0.553147\n",
            "Train Epoch: 38 [12800/45000 (28%)] Loss: 0.372757\n",
            "Train Epoch: 38 [13312/45000 (30%)] Loss: 0.526336\n",
            "Train Epoch: 38 [13824/45000 (31%)] Loss: 0.365387\n",
            "Train Epoch: 38 [14336/45000 (32%)] Loss: 0.674884\n",
            "Train Epoch: 38 [14848/45000 (33%)] Loss: 0.648254\n",
            "Train Epoch: 38 [15360/45000 (34%)] Loss: 0.572887\n",
            "Train Epoch: 38 [15872/45000 (35%)] Loss: 0.562283\n",
            "Train Epoch: 38 [16384/45000 (36%)] Loss: 0.822347\n",
            "Train Epoch: 38 [16896/45000 (38%)] Loss: 0.547498\n",
            "Train Epoch: 38 [17408/45000 (39%)] Loss: 0.578048\n",
            "Train Epoch: 38 [17920/45000 (40%)] Loss: 0.633613\n",
            "Train Epoch: 38 [18432/45000 (41%)] Loss: 0.551513\n",
            "Train Epoch: 38 [18944/45000 (42%)] Loss: 0.437483\n",
            "Train Epoch: 38 [19456/45000 (43%)] Loss: 0.536865\n",
            "Train Epoch: 38 [19968/45000 (44%)] Loss: 0.534297\n",
            "Train Epoch: 38 [20480/45000 (46%)] Loss: 0.347853\n",
            "Train Epoch: 38 [20992/45000 (47%)] Loss: 0.505358\n",
            "Train Epoch: 38 [21504/45000 (48%)] Loss: 0.510655\n",
            "Train Epoch: 38 [22016/45000 (49%)] Loss: 0.451400\n",
            "Train Epoch: 38 [22528/45000 (50%)] Loss: 0.629699\n",
            "Train Epoch: 38 [23040/45000 (51%)] Loss: 0.332541\n",
            "Train Epoch: 38 [23552/45000 (52%)] Loss: 0.633202\n",
            "Train Epoch: 38 [24064/45000 (53%)] Loss: 0.595850\n",
            "Train Epoch: 38 [24576/45000 (55%)] Loss: 0.553922\n",
            "Train Epoch: 38 [25088/45000 (56%)] Loss: 0.547776\n",
            "Train Epoch: 38 [25600/45000 (57%)] Loss: 0.475762\n",
            "Train Epoch: 38 [26112/45000 (58%)] Loss: 0.619312\n",
            "Train Epoch: 38 [26624/45000 (59%)] Loss: 0.510489\n",
            "Train Epoch: 38 [27136/45000 (60%)] Loss: 0.665524\n",
            "Train Epoch: 38 [27648/45000 (61%)] Loss: 0.473937\n",
            "Train Epoch: 38 [28160/45000 (63%)] Loss: 0.444279\n",
            "Train Epoch: 38 [28672/45000 (64%)] Loss: 0.556913\n",
            "Train Epoch: 38 [29184/45000 (65%)] Loss: 0.588471\n",
            "Train Epoch: 38 [29696/45000 (66%)] Loss: 0.369583\n",
            "Train Epoch: 38 [30208/45000 (67%)] Loss: 0.363439\n",
            "Train Epoch: 38 [30720/45000 (68%)] Loss: 0.433898\n",
            "Train Epoch: 38 [31232/45000 (69%)] Loss: 0.607157\n",
            "Train Epoch: 38 [31744/45000 (71%)] Loss: 0.621399\n",
            "Train Epoch: 38 [32256/45000 (72%)] Loss: 0.524021\n",
            "Train Epoch: 38 [32768/45000 (73%)] Loss: 0.371854\n",
            "Train Epoch: 38 [33280/45000 (74%)] Loss: 0.546924\n",
            "Train Epoch: 38 [33792/45000 (75%)] Loss: 0.496696\n",
            "Train Epoch: 38 [34304/45000 (76%)] Loss: 0.673520\n",
            "Train Epoch: 38 [34816/45000 (77%)] Loss: 0.535803\n",
            "Train Epoch: 38 [35328/45000 (79%)] Loss: 0.571630\n",
            "Train Epoch: 38 [35840/45000 (80%)] Loss: 0.418023\n",
            "Train Epoch: 38 [36352/45000 (81%)] Loss: 0.620268\n",
            "Train Epoch: 38 [36864/45000 (82%)] Loss: 0.618314\n",
            "Train Epoch: 38 [37376/45000 (83%)] Loss: 0.665186\n",
            "Train Epoch: 38 [37888/45000 (84%)] Loss: 0.584135\n",
            "Train Epoch: 38 [38400/45000 (85%)] Loss: 0.629332\n",
            "Train Epoch: 38 [38912/45000 (86%)] Loss: 0.558455\n",
            "Train Epoch: 38 [39424/45000 (88%)] Loss: 0.383048\n",
            "Train Epoch: 38 [39936/45000 (89%)] Loss: 0.561355\n",
            "Train Epoch: 38 [40448/45000 (90%)] Loss: 0.397236\n",
            "Train Epoch: 38 [40960/45000 (91%)] Loss: 0.819216\n",
            "Train Epoch: 38 [41472/45000 (92%)] Loss: 0.455821\n",
            "Train Epoch: 38 [41984/45000 (93%)] Loss: 0.504304\n",
            "Train Epoch: 38 [42496/45000 (94%)] Loss: 0.498996\n",
            "Train Epoch: 38 [43008/45000 (96%)] Loss: 0.670263\n",
            "Train Epoch: 38 [43520/45000 (97%)] Loss: 0.723426\n",
            "Train Epoch: 38 [44032/45000 (98%)] Loss: 0.665408\n",
            "Train Epoch: 38 [44544/45000 (99%)] Loss: 0.697999\n",
            "    epoch          : 38\n",
            "    loss           : 0.5337998281148347\n",
            "    accuracy       : 81.76935369318181\n",
            "    val_loss       : 0.6160890580732611\n",
            "    val_accuracy   : 79.19303797468355\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch38.pth ...\n",
            "Train Epoch: 39 [0/45000 (0%)] Loss: 0.585597\n",
            "Train Epoch: 39 [512/45000 (1%)] Loss: 0.651263\n",
            "Train Epoch: 39 [1024/45000 (2%)] Loss: 0.439412\n",
            "Train Epoch: 39 [1536/45000 (3%)] Loss: 0.730215\n",
            "Train Epoch: 39 [2048/45000 (5%)] Loss: 0.361001\n",
            "Train Epoch: 39 [2560/45000 (6%)] Loss: 0.664087\n",
            "Train Epoch: 39 [3072/45000 (7%)] Loss: 0.613985\n",
            "Train Epoch: 39 [3584/45000 (8%)] Loss: 0.386437\n",
            "Train Epoch: 39 [4096/45000 (9%)] Loss: 0.572452\n",
            "Train Epoch: 39 [4608/45000 (10%)] Loss: 0.566339\n",
            "Train Epoch: 39 [5120/45000 (11%)] Loss: 0.588416\n",
            "Train Epoch: 39 [5632/45000 (13%)] Loss: 0.583222\n",
            "Train Epoch: 39 [6144/45000 (14%)] Loss: 0.644679\n",
            "Train Epoch: 39 [6656/45000 (15%)] Loss: 0.568161\n",
            "Train Epoch: 39 [7168/45000 (16%)] Loss: 0.439589\n",
            "Train Epoch: 39 [7680/45000 (17%)] Loss: 0.643903\n",
            "Train Epoch: 39 [8192/45000 (18%)] Loss: 0.603102\n",
            "Train Epoch: 39 [8704/45000 (19%)] Loss: 0.572432\n",
            "Train Epoch: 39 [9216/45000 (20%)] Loss: 0.711208\n",
            "Train Epoch: 39 [9728/45000 (22%)] Loss: 0.374016\n",
            "Train Epoch: 39 [10240/45000 (23%)] Loss: 0.534074\n",
            "Train Epoch: 39 [10752/45000 (24%)] Loss: 0.777913\n",
            "Train Epoch: 39 [11264/45000 (25%)] Loss: 0.538191\n",
            "Train Epoch: 39 [11776/45000 (26%)] Loss: 0.604578\n",
            "Train Epoch: 39 [12288/45000 (27%)] Loss: 0.417277\n",
            "Train Epoch: 39 [12800/45000 (28%)] Loss: 0.571123\n",
            "Train Epoch: 39 [13312/45000 (30%)] Loss: 0.722661\n",
            "Train Epoch: 39 [13824/45000 (31%)] Loss: 0.445349\n",
            "Train Epoch: 39 [14336/45000 (32%)] Loss: 0.591991\n",
            "Train Epoch: 39 [14848/45000 (33%)] Loss: 0.429261\n",
            "Train Epoch: 39 [15360/45000 (34%)] Loss: 0.469174\n",
            "Train Epoch: 39 [15872/45000 (35%)] Loss: 0.395918\n",
            "Train Epoch: 39 [16384/45000 (36%)] Loss: 0.523632\n",
            "Train Epoch: 39 [16896/45000 (38%)] Loss: 0.665454\n",
            "Train Epoch: 39 [17408/45000 (39%)] Loss: 0.482610\n",
            "Train Epoch: 39 [17920/45000 (40%)] Loss: 0.444617\n",
            "Train Epoch: 39 [18432/45000 (41%)] Loss: 0.537303\n",
            "Train Epoch: 39 [18944/45000 (42%)] Loss: 0.866482\n",
            "Train Epoch: 39 [19456/45000 (43%)] Loss: 0.710128\n",
            "Train Epoch: 39 [19968/45000 (44%)] Loss: 0.553776\n",
            "Train Epoch: 39 [20480/45000 (46%)] Loss: 0.646950\n",
            "Train Epoch: 39 [20992/45000 (47%)] Loss: 0.504117\n",
            "Train Epoch: 39 [21504/45000 (48%)] Loss: 0.718883\n",
            "Train Epoch: 39 [22016/45000 (49%)] Loss: 0.687121\n",
            "Train Epoch: 39 [22528/45000 (50%)] Loss: 0.526373\n",
            "Train Epoch: 39 [23040/45000 (51%)] Loss: 0.550243\n",
            "Train Epoch: 39 [23552/45000 (52%)] Loss: 0.512907\n",
            "Train Epoch: 39 [24064/45000 (53%)] Loss: 0.609035\n",
            "Train Epoch: 39 [24576/45000 (55%)] Loss: 0.407791\n",
            "Train Epoch: 39 [25088/45000 (56%)] Loss: 0.469793\n",
            "Train Epoch: 39 [25600/45000 (57%)] Loss: 0.543440\n",
            "Train Epoch: 39 [26112/45000 (58%)] Loss: 0.489572\n",
            "Train Epoch: 39 [26624/45000 (59%)] Loss: 0.558033\n",
            "Train Epoch: 39 [27136/45000 (60%)] Loss: 0.453317\n",
            "Train Epoch: 39 [27648/45000 (61%)] Loss: 0.550925\n",
            "Train Epoch: 39 [28160/45000 (63%)] Loss: 0.328060\n",
            "Train Epoch: 39 [28672/45000 (64%)] Loss: 0.496944\n",
            "Train Epoch: 39 [29184/45000 (65%)] Loss: 0.551609\n",
            "Train Epoch: 39 [29696/45000 (66%)] Loss: 0.499553\n",
            "Train Epoch: 39 [30208/45000 (67%)] Loss: 0.559997\n",
            "Train Epoch: 39 [30720/45000 (68%)] Loss: 0.442552\n",
            "Train Epoch: 39 [31232/45000 (69%)] Loss: 0.572125\n",
            "Train Epoch: 39 [31744/45000 (71%)] Loss: 0.670954\n",
            "Train Epoch: 39 [32256/45000 (72%)] Loss: 0.524262\n",
            "Train Epoch: 39 [32768/45000 (73%)] Loss: 0.638364\n",
            "Train Epoch: 39 [33280/45000 (74%)] Loss: 0.423352\n",
            "Train Epoch: 39 [33792/45000 (75%)] Loss: 0.446412\n",
            "Train Epoch: 39 [34304/45000 (76%)] Loss: 0.608952\n",
            "Train Epoch: 39 [34816/45000 (77%)] Loss: 0.718425\n",
            "Train Epoch: 39 [35328/45000 (79%)] Loss: 0.656154\n",
            "Train Epoch: 39 [35840/45000 (80%)] Loss: 0.497458\n",
            "Train Epoch: 39 [36352/45000 (81%)] Loss: 0.537666\n",
            "Train Epoch: 39 [36864/45000 (82%)] Loss: 0.711802\n",
            "Train Epoch: 39 [37376/45000 (83%)] Loss: 0.501157\n",
            "Train Epoch: 39 [37888/45000 (84%)] Loss: 0.623908\n",
            "Train Epoch: 39 [38400/45000 (85%)] Loss: 0.646445\n",
            "Train Epoch: 39 [38912/45000 (86%)] Loss: 0.601568\n",
            "Train Epoch: 39 [39424/45000 (88%)] Loss: 0.485253\n",
            "Train Epoch: 39 [39936/45000 (89%)] Loss: 0.448331\n",
            "Train Epoch: 39 [40448/45000 (90%)] Loss: 0.456328\n",
            "Train Epoch: 39 [40960/45000 (91%)] Loss: 0.536005\n",
            "Train Epoch: 39 [41472/45000 (92%)] Loss: 0.360307\n",
            "Train Epoch: 39 [41984/45000 (93%)] Loss: 0.631045\n",
            "Train Epoch: 39 [42496/45000 (94%)] Loss: 0.567408\n",
            "Train Epoch: 39 [43008/45000 (96%)] Loss: 0.522065\n",
            "Train Epoch: 39 [43520/45000 (97%)] Loss: 0.558801\n",
            "Train Epoch: 39 [44032/45000 (98%)] Loss: 0.539096\n",
            "Train Epoch: 39 [44544/45000 (99%)] Loss: 0.636249\n",
            "    epoch          : 39\n",
            "    loss           : 0.5352625197053633\n",
            "    accuracy       : 81.77601207386364\n",
            "    val_loss       : 0.6048357999777492\n",
            "    val_accuracy   : 79.11392405063292\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch39.pth ...\n",
            "Train Epoch: 40 [0/45000 (0%)] Loss: 0.699298\n",
            "Train Epoch: 40 [512/45000 (1%)] Loss: 0.476635\n",
            "Train Epoch: 40 [1024/45000 (2%)] Loss: 0.550863\n",
            "Train Epoch: 40 [1536/45000 (3%)] Loss: 0.542025\n",
            "Train Epoch: 40 [2048/45000 (5%)] Loss: 0.496342\n",
            "Train Epoch: 40 [2560/45000 (6%)] Loss: 0.694841\n",
            "Train Epoch: 40 [3072/45000 (7%)] Loss: 0.481915\n",
            "Train Epoch: 40 [3584/45000 (8%)] Loss: 0.579009\n",
            "Train Epoch: 40 [4096/45000 (9%)] Loss: 0.600362\n",
            "Train Epoch: 40 [4608/45000 (10%)] Loss: 0.722959\n",
            "Train Epoch: 40 [5120/45000 (11%)] Loss: 0.360901\n",
            "Train Epoch: 40 [5632/45000 (13%)] Loss: 0.496056\n",
            "Train Epoch: 40 [6144/45000 (14%)] Loss: 0.577739\n",
            "Train Epoch: 40 [6656/45000 (15%)] Loss: 0.516837\n",
            "Train Epoch: 40 [7168/45000 (16%)] Loss: 0.465974\n",
            "Train Epoch: 40 [7680/45000 (17%)] Loss: 0.477651\n",
            "Train Epoch: 40 [8192/45000 (18%)] Loss: 0.458383\n",
            "Train Epoch: 40 [8704/45000 (19%)] Loss: 0.602804\n",
            "Train Epoch: 40 [9216/45000 (20%)] Loss: 0.589709\n",
            "Train Epoch: 40 [9728/45000 (22%)] Loss: 0.401186\n",
            "Train Epoch: 40 [10240/45000 (23%)] Loss: 0.681446\n",
            "Train Epoch: 40 [10752/45000 (24%)] Loss: 0.439952\n",
            "Train Epoch: 40 [11264/45000 (25%)] Loss: 0.447220\n",
            "Train Epoch: 40 [11776/45000 (26%)] Loss: 0.627017\n",
            "Train Epoch: 40 [12288/45000 (27%)] Loss: 0.576649\n",
            "Train Epoch: 40 [12800/45000 (28%)] Loss: 0.489621\n",
            "Train Epoch: 40 [13312/45000 (30%)] Loss: 0.338691\n",
            "Train Epoch: 40 [13824/45000 (31%)] Loss: 0.434501\n",
            "Train Epoch: 40 [14336/45000 (32%)] Loss: 0.575030\n",
            "Train Epoch: 40 [14848/45000 (33%)] Loss: 0.654584\n",
            "Train Epoch: 40 [15360/45000 (34%)] Loss: 0.478980\n",
            "Train Epoch: 40 [15872/45000 (35%)] Loss: 0.542025\n",
            "Train Epoch: 40 [16384/45000 (36%)] Loss: 0.547241\n",
            "Train Epoch: 40 [16896/45000 (38%)] Loss: 0.481395\n",
            "Train Epoch: 40 [17408/45000 (39%)] Loss: 0.370302\n",
            "Train Epoch: 40 [17920/45000 (40%)] Loss: 0.461289\n",
            "Train Epoch: 40 [18432/45000 (41%)] Loss: 0.435322\n",
            "Train Epoch: 40 [18944/45000 (42%)] Loss: 0.654365\n",
            "Train Epoch: 40 [19456/45000 (43%)] Loss: 0.609326\n",
            "Train Epoch: 40 [19968/45000 (44%)] Loss: 0.590941\n",
            "Train Epoch: 40 [20480/45000 (46%)] Loss: 0.494879\n",
            "Train Epoch: 40 [20992/45000 (47%)] Loss: 0.537267\n",
            "Train Epoch: 40 [21504/45000 (48%)] Loss: 0.572408\n",
            "Train Epoch: 40 [22016/45000 (49%)] Loss: 0.448429\n",
            "Train Epoch: 40 [22528/45000 (50%)] Loss: 0.534928\n",
            "Train Epoch: 40 [23040/45000 (51%)] Loss: 0.691080\n",
            "Train Epoch: 40 [23552/45000 (52%)] Loss: 0.498904\n",
            "Train Epoch: 40 [24064/45000 (53%)] Loss: 0.490489\n",
            "Train Epoch: 40 [24576/45000 (55%)] Loss: 0.580515\n",
            "Train Epoch: 40 [25088/45000 (56%)] Loss: 0.508119\n",
            "Train Epoch: 40 [25600/45000 (57%)] Loss: 0.595180\n",
            "Train Epoch: 40 [26112/45000 (58%)] Loss: 0.502945\n",
            "Train Epoch: 40 [26624/45000 (59%)] Loss: 0.644287\n",
            "Train Epoch: 40 [27136/45000 (60%)] Loss: 0.516368\n",
            "Train Epoch: 40 [27648/45000 (61%)] Loss: 0.553665\n",
            "Train Epoch: 40 [28160/45000 (63%)] Loss: 0.537874\n",
            "Train Epoch: 40 [28672/45000 (64%)] Loss: 0.513205\n",
            "Train Epoch: 40 [29184/45000 (65%)] Loss: 0.477380\n",
            "Train Epoch: 40 [29696/45000 (66%)] Loss: 0.556822\n",
            "Train Epoch: 40 [30208/45000 (67%)] Loss: 0.672837\n",
            "Train Epoch: 40 [30720/45000 (68%)] Loss: 0.498345\n",
            "Train Epoch: 40 [31232/45000 (69%)] Loss: 0.626648\n",
            "Train Epoch: 40 [31744/45000 (71%)] Loss: 0.600436\n",
            "Train Epoch: 40 [32256/45000 (72%)] Loss: 0.466798\n",
            "Train Epoch: 40 [32768/45000 (73%)] Loss: 0.539343\n",
            "Train Epoch: 40 [33280/45000 (74%)] Loss: 0.564655\n",
            "Train Epoch: 40 [33792/45000 (75%)] Loss: 0.492516\n",
            "Train Epoch: 40 [34304/45000 (76%)] Loss: 0.486430\n",
            "Train Epoch: 40 [34816/45000 (77%)] Loss: 0.692970\n",
            "Train Epoch: 40 [35328/45000 (79%)] Loss: 0.457409\n",
            "Train Epoch: 40 [35840/45000 (80%)] Loss: 0.538902\n",
            "Train Epoch: 40 [36352/45000 (81%)] Loss: 0.690217\n",
            "Train Epoch: 40 [36864/45000 (82%)] Loss: 0.622407\n",
            "Train Epoch: 40 [37376/45000 (83%)] Loss: 0.488545\n",
            "Train Epoch: 40 [37888/45000 (84%)] Loss: 0.456108\n",
            "Train Epoch: 40 [38400/45000 (85%)] Loss: 0.471510\n",
            "Train Epoch: 40 [38912/45000 (86%)] Loss: 0.517360\n",
            "Train Epoch: 40 [39424/45000 (88%)] Loss: 0.422758\n",
            "Train Epoch: 40 [39936/45000 (89%)] Loss: 0.463744\n",
            "Train Epoch: 40 [40448/45000 (90%)] Loss: 0.512919\n",
            "Train Epoch: 40 [40960/45000 (91%)] Loss: 0.484645\n",
            "Train Epoch: 40 [41472/45000 (92%)] Loss: 0.429541\n",
            "Train Epoch: 40 [41984/45000 (93%)] Loss: 0.676709\n",
            "Train Epoch: 40 [42496/45000 (94%)] Loss: 0.406250\n",
            "Train Epoch: 40 [43008/45000 (96%)] Loss: 0.658027\n",
            "Train Epoch: 40 [43520/45000 (97%)] Loss: 0.474615\n",
            "Train Epoch: 40 [44032/45000 (98%)] Loss: 0.492928\n",
            "Train Epoch: 40 [44544/45000 (99%)] Loss: 0.366926\n",
            "    epoch          : 40\n",
            "    loss           : 0.5321125754536215\n",
            "    accuracy       : 81.88032670454545\n",
            "    val_loss       : 0.6095441870297058\n",
            "    val_accuracy   : 79.35126582278481\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch40.pth ...\n",
            "Train Epoch: 41 [0/45000 (0%)] Loss: 0.408977\n",
            "Train Epoch: 41 [512/45000 (1%)] Loss: 0.430261\n",
            "Train Epoch: 41 [1024/45000 (2%)] Loss: 0.740654\n",
            "Train Epoch: 41 [1536/45000 (3%)] Loss: 0.421879\n",
            "Train Epoch: 41 [2048/45000 (5%)] Loss: 0.731658\n",
            "Train Epoch: 41 [2560/45000 (6%)] Loss: 0.482479\n",
            "Train Epoch: 41 [3072/45000 (7%)] Loss: 0.536970\n",
            "Train Epoch: 41 [3584/45000 (8%)] Loss: 0.517127\n",
            "Train Epoch: 41 [4096/45000 (9%)] Loss: 0.456153\n",
            "Train Epoch: 41 [4608/45000 (10%)] Loss: 0.314575\n",
            "Train Epoch: 41 [5120/45000 (11%)] Loss: 0.509499\n",
            "Train Epoch: 41 [5632/45000 (13%)] Loss: 0.568116\n",
            "Train Epoch: 41 [6144/45000 (14%)] Loss: 0.389481\n",
            "Train Epoch: 41 [6656/45000 (15%)] Loss: 0.511536\n",
            "Train Epoch: 41 [7168/45000 (16%)] Loss: 0.702249\n",
            "Train Epoch: 41 [7680/45000 (17%)] Loss: 0.627595\n",
            "Train Epoch: 41 [8192/45000 (18%)] Loss: 0.503672\n",
            "Train Epoch: 41 [8704/45000 (19%)] Loss: 0.436286\n",
            "Train Epoch: 41 [9216/45000 (20%)] Loss: 0.484176\n",
            "Train Epoch: 41 [9728/45000 (22%)] Loss: 0.445617\n",
            "Train Epoch: 41 [10240/45000 (23%)] Loss: 0.556827\n",
            "Train Epoch: 41 [10752/45000 (24%)] Loss: 0.629578\n",
            "Train Epoch: 41 [11264/45000 (25%)] Loss: 0.680446\n",
            "Train Epoch: 41 [11776/45000 (26%)] Loss: 0.427861\n",
            "Train Epoch: 41 [12288/45000 (27%)] Loss: 0.604849\n",
            "Train Epoch: 41 [12800/45000 (28%)] Loss: 0.296479\n",
            "Train Epoch: 41 [13312/45000 (30%)] Loss: 0.412665\n",
            "Train Epoch: 41 [13824/45000 (31%)] Loss: 0.475777\n",
            "Train Epoch: 41 [14336/45000 (32%)] Loss: 0.365762\n",
            "Train Epoch: 41 [14848/45000 (33%)] Loss: 0.697585\n",
            "Train Epoch: 41 [15360/45000 (34%)] Loss: 0.418948\n",
            "Train Epoch: 41 [15872/45000 (35%)] Loss: 0.527666\n",
            "Train Epoch: 41 [16384/45000 (36%)] Loss: 0.779573\n",
            "Train Epoch: 41 [16896/45000 (38%)] Loss: 0.381459\n",
            "Train Epoch: 41 [17408/45000 (39%)] Loss: 0.529125\n",
            "Train Epoch: 41 [17920/45000 (40%)] Loss: 0.582880\n",
            "Train Epoch: 41 [18432/45000 (41%)] Loss: 0.676231\n",
            "Train Epoch: 41 [18944/45000 (42%)] Loss: 0.456222\n",
            "Train Epoch: 41 [19456/45000 (43%)] Loss: 0.388893\n",
            "Train Epoch: 41 [19968/45000 (44%)] Loss: 0.542933\n",
            "Train Epoch: 41 [20480/45000 (46%)] Loss: 0.543668\n",
            "Train Epoch: 41 [20992/45000 (47%)] Loss: 0.548106\n",
            "Train Epoch: 41 [21504/45000 (48%)] Loss: 0.712952\n",
            "Train Epoch: 41 [22016/45000 (49%)] Loss: 0.722492\n",
            "Train Epoch: 41 [22528/45000 (50%)] Loss: 0.378102\n",
            "Train Epoch: 41 [23040/45000 (51%)] Loss: 0.357538\n",
            "Train Epoch: 41 [23552/45000 (52%)] Loss: 0.411645\n",
            "Train Epoch: 41 [24064/45000 (53%)] Loss: 0.617138\n",
            "Train Epoch: 41 [24576/45000 (55%)] Loss: 0.694128\n",
            "Train Epoch: 41 [25088/45000 (56%)] Loss: 0.602296\n",
            "Train Epoch: 41 [25600/45000 (57%)] Loss: 0.561278\n",
            "Train Epoch: 41 [26112/45000 (58%)] Loss: 0.596699\n",
            "Train Epoch: 41 [26624/45000 (59%)] Loss: 0.497340\n",
            "Train Epoch: 41 [27136/45000 (60%)] Loss: 0.602544\n",
            "Train Epoch: 41 [27648/45000 (61%)] Loss: 0.649541\n",
            "Train Epoch: 41 [28160/45000 (63%)] Loss: 0.599969\n",
            "Train Epoch: 41 [28672/45000 (64%)] Loss: 0.662391\n",
            "Train Epoch: 41 [29184/45000 (65%)] Loss: 0.479389\n",
            "Train Epoch: 41 [29696/45000 (66%)] Loss: 0.666455\n",
            "Train Epoch: 41 [30208/45000 (67%)] Loss: 0.337839\n",
            "Train Epoch: 41 [30720/45000 (68%)] Loss: 0.542426\n",
            "Train Epoch: 41 [31232/45000 (69%)] Loss: 0.465724\n",
            "Train Epoch: 41 [31744/45000 (71%)] Loss: 0.621085\n",
            "Train Epoch: 41 [32256/45000 (72%)] Loss: 0.574039\n",
            "Train Epoch: 41 [32768/45000 (73%)] Loss: 0.539462\n",
            "Train Epoch: 41 [33280/45000 (74%)] Loss: 0.726492\n",
            "Train Epoch: 41 [33792/45000 (75%)] Loss: 0.605441\n",
            "Train Epoch: 41 [34304/45000 (76%)] Loss: 0.613620\n",
            "Train Epoch: 41 [34816/45000 (77%)] Loss: 0.618243\n",
            "Train Epoch: 41 [35328/45000 (79%)] Loss: 0.493383\n",
            "Train Epoch: 41 [35840/45000 (80%)] Loss: 0.466679\n",
            "Train Epoch: 41 [36352/45000 (81%)] Loss: 0.415121\n",
            "Train Epoch: 41 [36864/45000 (82%)] Loss: 0.483071\n",
            "Train Epoch: 41 [37376/45000 (83%)] Loss: 0.583500\n",
            "Train Epoch: 41 [37888/45000 (84%)] Loss: 0.370654\n",
            "Train Epoch: 41 [38400/45000 (85%)] Loss: 0.374263\n",
            "Train Epoch: 41 [38912/45000 (86%)] Loss: 0.347996\n",
            "Train Epoch: 41 [39424/45000 (88%)] Loss: 0.452878\n",
            "Train Epoch: 41 [39936/45000 (89%)] Loss: 0.585535\n",
            "Train Epoch: 41 [40448/45000 (90%)] Loss: 0.651342\n",
            "Train Epoch: 41 [40960/45000 (91%)] Loss: 0.708553\n",
            "Train Epoch: 41 [41472/45000 (92%)] Loss: 0.486248\n",
            "Train Epoch: 41 [41984/45000 (93%)] Loss: 0.580041\n",
            "Train Epoch: 41 [42496/45000 (94%)] Loss: 0.694207\n",
            "Train Epoch: 41 [43008/45000 (96%)] Loss: 0.457067\n",
            "Train Epoch: 41 [43520/45000 (97%)] Loss: 0.356158\n",
            "Train Epoch: 41 [44032/45000 (98%)] Loss: 0.601064\n",
            "Train Epoch: 41 [44544/45000 (99%)] Loss: 0.493483\n",
            "    epoch          : 41\n",
            "    loss           : 0.5323638568462973\n",
            "    accuracy       : 81.79154829545455\n",
            "    val_loss       : 0.6115363192143319\n",
            "    val_accuracy   : 79.27215189873418\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch41.pth ...\n",
            "Train Epoch: 42 [0/45000 (0%)] Loss: 0.697395\n",
            "Train Epoch: 42 [512/45000 (1%)] Loss: 0.475466\n",
            "Train Epoch: 42 [1024/45000 (2%)] Loss: 0.542179\n",
            "Train Epoch: 42 [1536/45000 (3%)] Loss: 0.662263\n",
            "Train Epoch: 42 [2048/45000 (5%)] Loss: 0.657351\n",
            "Train Epoch: 42 [2560/45000 (6%)] Loss: 0.449394\n",
            "Train Epoch: 42 [3072/45000 (7%)] Loss: 0.486213\n",
            "Train Epoch: 42 [3584/45000 (8%)] Loss: 0.502583\n",
            "Train Epoch: 42 [4096/45000 (9%)] Loss: 0.422819\n",
            "Train Epoch: 42 [4608/45000 (10%)] Loss: 0.827892\n",
            "Train Epoch: 42 [5120/45000 (11%)] Loss: 0.525275\n",
            "Train Epoch: 42 [5632/45000 (13%)] Loss: 0.451853\n",
            "Train Epoch: 42 [6144/45000 (14%)] Loss: 0.421937\n",
            "Train Epoch: 42 [6656/45000 (15%)] Loss: 0.595952\n",
            "Train Epoch: 42 [7168/45000 (16%)] Loss: 0.542895\n",
            "Train Epoch: 42 [7680/45000 (17%)] Loss: 0.412254\n",
            "Train Epoch: 42 [8192/45000 (18%)] Loss: 0.646223\n",
            "Train Epoch: 42 [8704/45000 (19%)] Loss: 0.490433\n",
            "Train Epoch: 42 [9216/45000 (20%)] Loss: 0.501817\n",
            "Train Epoch: 42 [9728/45000 (22%)] Loss: 0.524648\n",
            "Train Epoch: 42 [10240/45000 (23%)] Loss: 0.845739\n",
            "Train Epoch: 42 [10752/45000 (24%)] Loss: 0.592641\n",
            "Train Epoch: 42 [11264/45000 (25%)] Loss: 0.517497\n",
            "Train Epoch: 42 [11776/45000 (26%)] Loss: 0.530985\n",
            "Train Epoch: 42 [12288/45000 (27%)] Loss: 0.475237\n",
            "Train Epoch: 42 [12800/45000 (28%)] Loss: 0.580947\n",
            "Train Epoch: 42 [13312/45000 (30%)] Loss: 0.644113\n",
            "Train Epoch: 42 [13824/45000 (31%)] Loss: 0.715876\n",
            "Train Epoch: 42 [14336/45000 (32%)] Loss: 0.479549\n",
            "Train Epoch: 42 [14848/45000 (33%)] Loss: 0.533252\n",
            "Train Epoch: 42 [15360/45000 (34%)] Loss: 0.419950\n",
            "Train Epoch: 42 [15872/45000 (35%)] Loss: 0.718640\n",
            "Train Epoch: 42 [16384/45000 (36%)] Loss: 0.417087\n",
            "Train Epoch: 42 [16896/45000 (38%)] Loss: 0.363477\n",
            "Train Epoch: 42 [17408/45000 (39%)] Loss: 0.486721\n",
            "Train Epoch: 42 [17920/45000 (40%)] Loss: 0.608921\n",
            "Train Epoch: 42 [18432/45000 (41%)] Loss: 0.411690\n",
            "Train Epoch: 42 [18944/45000 (42%)] Loss: 0.600337\n",
            "Train Epoch: 42 [19456/45000 (43%)] Loss: 0.487454\n",
            "Train Epoch: 42 [19968/45000 (44%)] Loss: 0.548137\n",
            "Train Epoch: 42 [20480/45000 (46%)] Loss: 0.423369\n",
            "Train Epoch: 42 [20992/45000 (47%)] Loss: 0.748248\n",
            "Train Epoch: 42 [21504/45000 (48%)] Loss: 0.651852\n",
            "Train Epoch: 42 [22016/45000 (49%)] Loss: 0.525507\n",
            "Train Epoch: 42 [22528/45000 (50%)] Loss: 0.584184\n",
            "Train Epoch: 42 [23040/45000 (51%)] Loss: 0.697258\n",
            "Train Epoch: 42 [23552/45000 (52%)] Loss: 0.604942\n",
            "Train Epoch: 42 [24064/45000 (53%)] Loss: 0.516789\n",
            "Train Epoch: 42 [24576/45000 (55%)] Loss: 0.550694\n",
            "Train Epoch: 42 [25088/45000 (56%)] Loss: 0.382543\n",
            "Train Epoch: 42 [25600/45000 (57%)] Loss: 0.501973\n",
            "Train Epoch: 42 [26112/45000 (58%)] Loss: 0.692052\n",
            "Train Epoch: 42 [26624/45000 (59%)] Loss: 0.830469\n",
            "Train Epoch: 42 [27136/45000 (60%)] Loss: 0.762096\n",
            "Train Epoch: 42 [27648/45000 (61%)] Loss: 0.420740\n",
            "Train Epoch: 42 [28160/45000 (63%)] Loss: 0.531465\n",
            "Train Epoch: 42 [28672/45000 (64%)] Loss: 0.528817\n",
            "Train Epoch: 42 [29184/45000 (65%)] Loss: 0.733197\n",
            "Train Epoch: 42 [29696/45000 (66%)] Loss: 0.430576\n",
            "Train Epoch: 42 [30208/45000 (67%)] Loss: 0.573032\n",
            "Train Epoch: 42 [30720/45000 (68%)] Loss: 0.606905\n",
            "Train Epoch: 42 [31232/45000 (69%)] Loss: 0.374354\n",
            "Train Epoch: 42 [31744/45000 (71%)] Loss: 0.485813\n",
            "Train Epoch: 42 [32256/45000 (72%)] Loss: 0.512716\n",
            "Train Epoch: 42 [32768/45000 (73%)] Loss: 0.531433\n",
            "Train Epoch: 42 [33280/45000 (74%)] Loss: 0.785515\n",
            "Train Epoch: 42 [33792/45000 (75%)] Loss: 0.588330\n",
            "Train Epoch: 42 [34304/45000 (76%)] Loss: 0.548222\n",
            "Train Epoch: 42 [34816/45000 (77%)] Loss: 0.531802\n",
            "Train Epoch: 42 [35328/45000 (79%)] Loss: 0.482304\n",
            "Train Epoch: 42 [35840/45000 (80%)] Loss: 0.719935\n",
            "Train Epoch: 42 [36352/45000 (81%)] Loss: 0.397260\n",
            "Train Epoch: 42 [36864/45000 (82%)] Loss: 0.475174\n",
            "Train Epoch: 42 [37376/45000 (83%)] Loss: 0.513496\n",
            "Train Epoch: 42 [37888/45000 (84%)] Loss: 0.324269\n",
            "Train Epoch: 42 [38400/45000 (85%)] Loss: 0.621411\n",
            "Train Epoch: 42 [38912/45000 (86%)] Loss: 0.476091\n",
            "Train Epoch: 42 [39424/45000 (88%)] Loss: 0.483421\n",
            "Train Epoch: 42 [39936/45000 (89%)] Loss: 0.736065\n",
            "Train Epoch: 42 [40448/45000 (90%)] Loss: 0.613340\n",
            "Train Epoch: 42 [40960/45000 (91%)] Loss: 0.574991\n",
            "Train Epoch: 42 [41472/45000 (92%)] Loss: 0.500854\n",
            "Train Epoch: 42 [41984/45000 (93%)] Loss: 0.488066\n",
            "Train Epoch: 42 [42496/45000 (94%)] Loss: 0.474737\n",
            "Train Epoch: 42 [43008/45000 (96%)] Loss: 0.502614\n",
            "Train Epoch: 42 [43520/45000 (97%)] Loss: 0.521289\n",
            "Train Epoch: 42 [44032/45000 (98%)] Loss: 0.612618\n",
            "Train Epoch: 42 [44544/45000 (99%)] Loss: 0.477199\n",
            "    epoch          : 42\n",
            "    loss           : 0.5337428402113304\n",
            "    accuracy       : 81.72496448863636\n",
            "    val_loss       : 0.6077244406259512\n",
            "    val_accuracy   : 78.91613924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch42.pth ...\n",
            "Train Epoch: 43 [0/45000 (0%)] Loss: 0.691408\n",
            "Train Epoch: 43 [512/45000 (1%)] Loss: 0.530150\n",
            "Train Epoch: 43 [1024/45000 (2%)] Loss: 0.533031\n",
            "Train Epoch: 43 [1536/45000 (3%)] Loss: 0.464003\n",
            "Train Epoch: 43 [2048/45000 (5%)] Loss: 0.512001\n",
            "Train Epoch: 43 [2560/45000 (6%)] Loss: 0.347827\n",
            "Train Epoch: 43 [3072/45000 (7%)] Loss: 0.391154\n",
            "Train Epoch: 43 [3584/45000 (8%)] Loss: 0.627453\n",
            "Train Epoch: 43 [4096/45000 (9%)] Loss: 0.587767\n",
            "Train Epoch: 43 [4608/45000 (10%)] Loss: 0.520128\n",
            "Train Epoch: 43 [5120/45000 (11%)] Loss: 0.447988\n",
            "Train Epoch: 43 [5632/45000 (13%)] Loss: 0.636948\n",
            "Train Epoch: 43 [6144/45000 (14%)] Loss: 0.498244\n",
            "Train Epoch: 43 [6656/45000 (15%)] Loss: 0.702261\n",
            "Train Epoch: 43 [7168/45000 (16%)] Loss: 0.279447\n",
            "Train Epoch: 43 [7680/45000 (17%)] Loss: 0.747584\n",
            "Train Epoch: 43 [8192/45000 (18%)] Loss: 0.551855\n",
            "Train Epoch: 43 [8704/45000 (19%)] Loss: 0.692782\n",
            "Train Epoch: 43 [9216/45000 (20%)] Loss: 0.600910\n",
            "Train Epoch: 43 [9728/45000 (22%)] Loss: 0.784473\n",
            "Train Epoch: 43 [10240/45000 (23%)] Loss: 0.553689\n",
            "Train Epoch: 43 [10752/45000 (24%)] Loss: 0.458304\n",
            "Train Epoch: 43 [11264/45000 (25%)] Loss: 0.624167\n",
            "Train Epoch: 43 [11776/45000 (26%)] Loss: 0.599975\n",
            "Train Epoch: 43 [12288/45000 (27%)] Loss: 0.385295\n",
            "Train Epoch: 43 [12800/45000 (28%)] Loss: 0.517461\n",
            "Train Epoch: 43 [13312/45000 (30%)] Loss: 0.301045\n",
            "Train Epoch: 43 [13824/45000 (31%)] Loss: 0.521677\n",
            "Train Epoch: 43 [14336/45000 (32%)] Loss: 0.491436\n",
            "Train Epoch: 43 [14848/45000 (33%)] Loss: 0.472686\n",
            "Train Epoch: 43 [15360/45000 (34%)] Loss: 0.332400\n",
            "Train Epoch: 43 [15872/45000 (35%)] Loss: 0.319379\n",
            "Train Epoch: 43 [16384/45000 (36%)] Loss: 0.955198\n",
            "Train Epoch: 43 [16896/45000 (38%)] Loss: 0.666213\n",
            "Train Epoch: 43 [17408/45000 (39%)] Loss: 0.527126\n",
            "Train Epoch: 43 [17920/45000 (40%)] Loss: 0.457941\n",
            "Train Epoch: 43 [18432/45000 (41%)] Loss: 0.554100\n",
            "Train Epoch: 43 [18944/45000 (42%)] Loss: 0.382902\n",
            "Train Epoch: 43 [19456/45000 (43%)] Loss: 0.510425\n",
            "Train Epoch: 43 [19968/45000 (44%)] Loss: 0.736887\n",
            "Train Epoch: 43 [20480/45000 (46%)] Loss: 0.630943\n",
            "Train Epoch: 43 [20992/45000 (47%)] Loss: 0.447736\n",
            "Train Epoch: 43 [21504/45000 (48%)] Loss: 0.415723\n",
            "Train Epoch: 43 [22016/45000 (49%)] Loss: 0.667429\n",
            "Train Epoch: 43 [22528/45000 (50%)] Loss: 0.462058\n",
            "Train Epoch: 43 [23040/45000 (51%)] Loss: 0.488534\n",
            "Train Epoch: 43 [23552/45000 (52%)] Loss: 0.580643\n",
            "Train Epoch: 43 [24064/45000 (53%)] Loss: 0.377614\n",
            "Train Epoch: 43 [24576/45000 (55%)] Loss: 0.675259\n",
            "Train Epoch: 43 [25088/45000 (56%)] Loss: 0.503982\n",
            "Train Epoch: 43 [25600/45000 (57%)] Loss: 0.788348\n",
            "Train Epoch: 43 [26112/45000 (58%)] Loss: 0.563135\n",
            "Train Epoch: 43 [26624/45000 (59%)] Loss: 0.583957\n",
            "Train Epoch: 43 [27136/45000 (60%)] Loss: 0.570696\n",
            "Train Epoch: 43 [27648/45000 (61%)] Loss: 0.539339\n",
            "Train Epoch: 43 [28160/45000 (63%)] Loss: 0.678871\n",
            "Train Epoch: 43 [28672/45000 (64%)] Loss: 0.466865\n",
            "Train Epoch: 43 [29184/45000 (65%)] Loss: 0.444411\n",
            "Train Epoch: 43 [29696/45000 (66%)] Loss: 0.506673\n",
            "Train Epoch: 43 [30208/45000 (67%)] Loss: 0.536808\n",
            "Train Epoch: 43 [30720/45000 (68%)] Loss: 0.433408\n",
            "Train Epoch: 43 [31232/45000 (69%)] Loss: 0.599663\n",
            "Train Epoch: 43 [31744/45000 (71%)] Loss: 0.672675\n",
            "Train Epoch: 43 [32256/45000 (72%)] Loss: 0.508863\n",
            "Train Epoch: 43 [32768/45000 (73%)] Loss: 0.538787\n",
            "Train Epoch: 43 [33280/45000 (74%)] Loss: 0.526290\n",
            "Train Epoch: 43 [33792/45000 (75%)] Loss: 0.429357\n",
            "Train Epoch: 43 [34304/45000 (76%)] Loss: 0.618616\n",
            "Train Epoch: 43 [34816/45000 (77%)] Loss: 0.694631\n",
            "Train Epoch: 43 [35328/45000 (79%)] Loss: 0.511723\n",
            "Train Epoch: 43 [35840/45000 (80%)] Loss: 0.389881\n",
            "Train Epoch: 43 [36352/45000 (81%)] Loss: 0.584760\n",
            "Train Epoch: 43 [36864/45000 (82%)] Loss: 0.732479\n",
            "Train Epoch: 43 [37376/45000 (83%)] Loss: 0.687696\n",
            "Train Epoch: 43 [37888/45000 (84%)] Loss: 0.727277\n",
            "Train Epoch: 43 [38400/45000 (85%)] Loss: 0.441956\n",
            "Train Epoch: 43 [38912/45000 (86%)] Loss: 0.597678\n",
            "Train Epoch: 43 [39424/45000 (88%)] Loss: 0.440730\n",
            "Train Epoch: 43 [39936/45000 (89%)] Loss: 0.712692\n",
            "Train Epoch: 43 [40448/45000 (90%)] Loss: 0.512887\n",
            "Train Epoch: 43 [40960/45000 (91%)] Loss: 0.474331\n",
            "Train Epoch: 43 [41472/45000 (92%)] Loss: 0.304051\n",
            "Train Epoch: 43 [41984/45000 (93%)] Loss: 0.622261\n",
            "Train Epoch: 43 [42496/45000 (94%)] Loss: 0.716622\n",
            "Train Epoch: 43 [43008/45000 (96%)] Loss: 0.418509\n",
            "Train Epoch: 43 [43520/45000 (97%)] Loss: 0.676959\n",
            "Train Epoch: 43 [44032/45000 (98%)] Loss: 0.478419\n",
            "Train Epoch: 43 [44544/45000 (99%)] Loss: 0.573524\n",
            "    epoch          : 43\n",
            "    loss           : 0.5335205974353646\n",
            "    accuracy       : 81.7294034090909\n",
            "    val_loss       : 0.6111381351947784\n",
            "    val_accuracy   : 79.09414556962025\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch43.pth ...\n",
            "Train Epoch: 44 [0/45000 (0%)] Loss: 0.411205\n",
            "Train Epoch: 44 [512/45000 (1%)] Loss: 0.429422\n",
            "Train Epoch: 44 [1024/45000 (2%)] Loss: 0.468722\n",
            "Train Epoch: 44 [1536/45000 (3%)] Loss: 0.424225\n",
            "Train Epoch: 44 [2048/45000 (5%)] Loss: 0.414728\n",
            "Train Epoch: 44 [2560/45000 (6%)] Loss: 0.659617\n",
            "Train Epoch: 44 [3072/45000 (7%)] Loss: 0.618963\n",
            "Train Epoch: 44 [3584/45000 (8%)] Loss: 0.432672\n",
            "Train Epoch: 44 [4096/45000 (9%)] Loss: 0.790496\n",
            "Train Epoch: 44 [4608/45000 (10%)] Loss: 0.822580\n",
            "Train Epoch: 44 [5120/45000 (11%)] Loss: 0.526876\n",
            "Train Epoch: 44 [5632/45000 (13%)] Loss: 0.578783\n",
            "Train Epoch: 44 [6144/45000 (14%)] Loss: 0.603866\n",
            "Train Epoch: 44 [6656/45000 (15%)] Loss: 0.780213\n",
            "Train Epoch: 44 [7168/45000 (16%)] Loss: 0.688755\n",
            "Train Epoch: 44 [7680/45000 (17%)] Loss: 0.533181\n",
            "Train Epoch: 44 [8192/45000 (18%)] Loss: 0.509893\n",
            "Train Epoch: 44 [8704/45000 (19%)] Loss: 0.503830\n",
            "Train Epoch: 44 [9216/45000 (20%)] Loss: 0.546748\n",
            "Train Epoch: 44 [9728/45000 (22%)] Loss: 0.388447\n",
            "Train Epoch: 44 [10240/45000 (23%)] Loss: 0.762435\n",
            "Train Epoch: 44 [10752/45000 (24%)] Loss: 0.572834\n",
            "Train Epoch: 44 [11264/45000 (25%)] Loss: 0.505480\n",
            "Train Epoch: 44 [11776/45000 (26%)] Loss: 0.619378\n",
            "Train Epoch: 44 [12288/45000 (27%)] Loss: 0.435826\n",
            "Train Epoch: 44 [12800/45000 (28%)] Loss: 0.402642\n",
            "Train Epoch: 44 [13312/45000 (30%)] Loss: 0.587913\n",
            "Train Epoch: 44 [13824/45000 (31%)] Loss: 0.384229\n",
            "Train Epoch: 44 [14336/45000 (32%)] Loss: 0.505060\n",
            "Train Epoch: 44 [14848/45000 (33%)] Loss: 0.600672\n",
            "Train Epoch: 44 [15360/45000 (34%)] Loss: 0.502533\n",
            "Train Epoch: 44 [15872/45000 (35%)] Loss: 0.482256\n",
            "Train Epoch: 44 [16384/45000 (36%)] Loss: 0.482466\n",
            "Train Epoch: 44 [16896/45000 (38%)] Loss: 0.551852\n",
            "Train Epoch: 44 [17408/45000 (39%)] Loss: 0.475988\n",
            "Train Epoch: 44 [17920/45000 (40%)] Loss: 0.502804\n",
            "Train Epoch: 44 [18432/45000 (41%)] Loss: 0.559056\n",
            "Train Epoch: 44 [18944/45000 (42%)] Loss: 0.600333\n",
            "Train Epoch: 44 [19456/45000 (43%)] Loss: 0.657943\n",
            "Train Epoch: 44 [19968/45000 (44%)] Loss: 0.627536\n",
            "Train Epoch: 44 [20480/45000 (46%)] Loss: 0.715218\n",
            "Train Epoch: 44 [20992/45000 (47%)] Loss: 0.762264\n",
            "Train Epoch: 44 [21504/45000 (48%)] Loss: 0.380643\n",
            "Train Epoch: 44 [22016/45000 (49%)] Loss: 0.361079\n",
            "Train Epoch: 44 [22528/45000 (50%)] Loss: 0.381989\n",
            "Train Epoch: 44 [23040/45000 (51%)] Loss: 0.752159\n",
            "Train Epoch: 44 [23552/45000 (52%)] Loss: 0.558733\n",
            "Train Epoch: 44 [24064/45000 (53%)] Loss: 0.299069\n",
            "Train Epoch: 44 [24576/45000 (55%)] Loss: 0.458858\n",
            "Train Epoch: 44 [25088/45000 (56%)] Loss: 0.463491\n",
            "Train Epoch: 44 [25600/45000 (57%)] Loss: 0.893865\n",
            "Train Epoch: 44 [26112/45000 (58%)] Loss: 0.539624\n",
            "Train Epoch: 44 [26624/45000 (59%)] Loss: 0.525054\n",
            "Train Epoch: 44 [27136/45000 (60%)] Loss: 0.641649\n",
            "Train Epoch: 44 [27648/45000 (61%)] Loss: 0.602432\n",
            "Train Epoch: 44 [28160/45000 (63%)] Loss: 0.669676\n",
            "Train Epoch: 44 [28672/45000 (64%)] Loss: 0.501760\n",
            "Train Epoch: 44 [29184/45000 (65%)] Loss: 0.578356\n",
            "Train Epoch: 44 [29696/45000 (66%)] Loss: 0.608031\n",
            "Train Epoch: 44 [30208/45000 (67%)] Loss: 0.487210\n",
            "Train Epoch: 44 [30720/45000 (68%)] Loss: 0.613144\n",
            "Train Epoch: 44 [31232/45000 (69%)] Loss: 0.372488\n",
            "Train Epoch: 44 [31744/45000 (71%)] Loss: 0.602489\n",
            "Train Epoch: 44 [32256/45000 (72%)] Loss: 0.438130\n",
            "Train Epoch: 44 [32768/45000 (73%)] Loss: 0.569667\n",
            "Train Epoch: 44 [33280/45000 (74%)] Loss: 0.560723\n",
            "Train Epoch: 44 [33792/45000 (75%)] Loss: 0.412175\n",
            "Train Epoch: 44 [34304/45000 (76%)] Loss: 0.572000\n",
            "Train Epoch: 44 [34816/45000 (77%)] Loss: 0.315409\n",
            "Train Epoch: 44 [35328/45000 (79%)] Loss: 0.644337\n",
            "Train Epoch: 44 [35840/45000 (80%)] Loss: 0.472152\n",
            "Train Epoch: 44 [36352/45000 (81%)] Loss: 0.572466\n",
            "Train Epoch: 44 [36864/45000 (82%)] Loss: 0.447228\n",
            "Train Epoch: 44 [37376/45000 (83%)] Loss: 0.501860\n",
            "Train Epoch: 44 [37888/45000 (84%)] Loss: 0.576591\n",
            "Train Epoch: 44 [38400/45000 (85%)] Loss: 0.420220\n",
            "Train Epoch: 44 [38912/45000 (86%)] Loss: 0.537537\n",
            "Train Epoch: 44 [39424/45000 (88%)] Loss: 0.674058\n",
            "Train Epoch: 44 [39936/45000 (89%)] Loss: 0.522622\n",
            "Train Epoch: 44 [40448/45000 (90%)] Loss: 0.577235\n",
            "Train Epoch: 44 [40960/45000 (91%)] Loss: 0.651835\n",
            "Train Epoch: 44 [41472/45000 (92%)] Loss: 0.522065\n",
            "Train Epoch: 44 [41984/45000 (93%)] Loss: 0.650318\n",
            "Train Epoch: 44 [42496/45000 (94%)] Loss: 0.525912\n",
            "Train Epoch: 44 [43008/45000 (96%)] Loss: 0.515871\n",
            "Train Epoch: 44 [43520/45000 (97%)] Loss: 0.507506\n",
            "Train Epoch: 44 [44032/45000 (98%)] Loss: 0.588762\n",
            "Train Epoch: 44 [44544/45000 (99%)] Loss: 0.527749\n",
            "    epoch          : 44\n",
            "    loss           : 0.5334946626204659\n",
            "    accuracy       : 81.66947798295455\n",
            "    val_loss       : 0.6139768995816195\n",
            "    val_accuracy   : 79.2128164556962\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch44.pth ...\n",
            "Train Epoch: 45 [0/45000 (0%)] Loss: 0.403485\n",
            "Train Epoch: 45 [512/45000 (1%)] Loss: 0.384371\n",
            "Train Epoch: 45 [1024/45000 (2%)] Loss: 0.519913\n",
            "Train Epoch: 45 [1536/45000 (3%)] Loss: 0.629913\n",
            "Train Epoch: 45 [2048/45000 (5%)] Loss: 0.562849\n",
            "Train Epoch: 45 [2560/45000 (6%)] Loss: 0.544668\n",
            "Train Epoch: 45 [3072/45000 (7%)] Loss: 0.613884\n",
            "Train Epoch: 45 [3584/45000 (8%)] Loss: 0.498136\n",
            "Train Epoch: 45 [4096/45000 (9%)] Loss: 0.542262\n",
            "Train Epoch: 45 [4608/45000 (10%)] Loss: 0.560485\n",
            "Train Epoch: 45 [5120/45000 (11%)] Loss: 0.485580\n",
            "Train Epoch: 45 [5632/45000 (13%)] Loss: 0.528962\n",
            "Train Epoch: 45 [6144/45000 (14%)] Loss: 0.398260\n",
            "Train Epoch: 45 [6656/45000 (15%)] Loss: 0.657736\n",
            "Train Epoch: 45 [7168/45000 (16%)] Loss: 0.481932\n",
            "Train Epoch: 45 [7680/45000 (17%)] Loss: 0.842176\n",
            "Train Epoch: 45 [8192/45000 (18%)] Loss: 0.435725\n",
            "Train Epoch: 45 [8704/45000 (19%)] Loss: 0.391036\n",
            "Train Epoch: 45 [9216/45000 (20%)] Loss: 0.467953\n",
            "Train Epoch: 45 [9728/45000 (22%)] Loss: 0.350773\n",
            "Train Epoch: 45 [10240/45000 (23%)] Loss: 0.382881\n",
            "Train Epoch: 45 [10752/45000 (24%)] Loss: 0.476494\n",
            "Train Epoch: 45 [11264/45000 (25%)] Loss: 0.457299\n",
            "Train Epoch: 45 [11776/45000 (26%)] Loss: 0.625635\n",
            "Train Epoch: 45 [12288/45000 (27%)] Loss: 0.608066\n",
            "Train Epoch: 45 [12800/45000 (28%)] Loss: 0.399287\n",
            "Train Epoch: 45 [13312/45000 (30%)] Loss: 0.490692\n",
            "Train Epoch: 45 [13824/45000 (31%)] Loss: 0.523077\n",
            "Train Epoch: 45 [14336/45000 (32%)] Loss: 0.534744\n",
            "Train Epoch: 45 [14848/45000 (33%)] Loss: 0.556041\n",
            "Train Epoch: 45 [15360/45000 (34%)] Loss: 0.256215\n",
            "Train Epoch: 45 [15872/45000 (35%)] Loss: 0.638750\n",
            "Train Epoch: 45 [16384/45000 (36%)] Loss: 0.600747\n",
            "Train Epoch: 45 [16896/45000 (38%)] Loss: 0.566752\n",
            "Train Epoch: 45 [17408/45000 (39%)] Loss: 0.542671\n",
            "Train Epoch: 45 [17920/45000 (40%)] Loss: 0.351215\n",
            "Train Epoch: 45 [18432/45000 (41%)] Loss: 0.485663\n",
            "Train Epoch: 45 [18944/45000 (42%)] Loss: 0.355343\n",
            "Train Epoch: 45 [19456/45000 (43%)] Loss: 0.554532\n",
            "Train Epoch: 45 [19968/45000 (44%)] Loss: 0.524742\n",
            "Train Epoch: 45 [20480/45000 (46%)] Loss: 0.548520\n",
            "Train Epoch: 45 [20992/45000 (47%)] Loss: 0.547881\n",
            "Train Epoch: 45 [21504/45000 (48%)] Loss: 0.575096\n",
            "Train Epoch: 45 [22016/45000 (49%)] Loss: 0.556360\n",
            "Train Epoch: 45 [22528/45000 (50%)] Loss: 0.590518\n",
            "Train Epoch: 45 [23040/45000 (51%)] Loss: 0.562896\n",
            "Train Epoch: 45 [23552/45000 (52%)] Loss: 0.841892\n",
            "Train Epoch: 45 [24064/45000 (53%)] Loss: 0.490844\n",
            "Train Epoch: 45 [24576/45000 (55%)] Loss: 0.558196\n",
            "Train Epoch: 45 [25088/45000 (56%)] Loss: 0.604895\n",
            "Train Epoch: 45 [25600/45000 (57%)] Loss: 0.576845\n",
            "Train Epoch: 45 [26112/45000 (58%)] Loss: 0.485500\n",
            "Train Epoch: 45 [26624/45000 (59%)] Loss: 0.461151\n",
            "Train Epoch: 45 [27136/45000 (60%)] Loss: 0.371528\n",
            "Train Epoch: 45 [27648/45000 (61%)] Loss: 0.702608\n",
            "Train Epoch: 45 [28160/45000 (63%)] Loss: 0.693025\n",
            "Train Epoch: 45 [28672/45000 (64%)] Loss: 0.616305\n",
            "Train Epoch: 45 [29184/45000 (65%)] Loss: 0.466499\n",
            "Train Epoch: 45 [29696/45000 (66%)] Loss: 0.478507\n",
            "Train Epoch: 45 [30208/45000 (67%)] Loss: 0.595616\n",
            "Train Epoch: 45 [30720/45000 (68%)] Loss: 0.633124\n",
            "Train Epoch: 45 [31232/45000 (69%)] Loss: 0.826847\n",
            "Train Epoch: 45 [31744/45000 (71%)] Loss: 0.695085\n",
            "Train Epoch: 45 [32256/45000 (72%)] Loss: 0.389228\n",
            "Train Epoch: 45 [32768/45000 (73%)] Loss: 0.654016\n",
            "Train Epoch: 45 [33280/45000 (74%)] Loss: 0.505392\n",
            "Train Epoch: 45 [33792/45000 (75%)] Loss: 0.355245\n",
            "Train Epoch: 45 [34304/45000 (76%)] Loss: 0.406814\n",
            "Train Epoch: 45 [34816/45000 (77%)] Loss: 0.612318\n",
            "Train Epoch: 45 [35328/45000 (79%)] Loss: 0.608153\n",
            "Train Epoch: 45 [35840/45000 (80%)] Loss: 0.398556\n",
            "Train Epoch: 45 [36352/45000 (81%)] Loss: 0.699543\n",
            "Train Epoch: 45 [36864/45000 (82%)] Loss: 0.618664\n",
            "Train Epoch: 45 [37376/45000 (83%)] Loss: 0.533215\n",
            "Train Epoch: 45 [37888/45000 (84%)] Loss: 0.597057\n",
            "Train Epoch: 45 [38400/45000 (85%)] Loss: 0.438293\n",
            "Train Epoch: 45 [38912/45000 (86%)] Loss: 0.445836\n",
            "Train Epoch: 45 [39424/45000 (88%)] Loss: 0.584383\n",
            "Train Epoch: 45 [39936/45000 (89%)] Loss: 0.696846\n",
            "Train Epoch: 45 [40448/45000 (90%)] Loss: 0.668233\n",
            "Train Epoch: 45 [40960/45000 (91%)] Loss: 0.627904\n",
            "Train Epoch: 45 [41472/45000 (92%)] Loss: 0.400095\n",
            "Train Epoch: 45 [41984/45000 (93%)] Loss: 0.568062\n",
            "Train Epoch: 45 [42496/45000 (94%)] Loss: 0.389475\n",
            "Train Epoch: 45 [43008/45000 (96%)] Loss: 0.500205\n",
            "Train Epoch: 45 [43520/45000 (97%)] Loss: 0.574966\n",
            "Train Epoch: 45 [44032/45000 (98%)] Loss: 0.578425\n",
            "Train Epoch: 45 [44544/45000 (99%)] Loss: 0.462361\n",
            "    epoch          : 45\n",
            "    loss           : 0.5317379109434445\n",
            "    accuracy       : 81.76047585227273\n",
            "    val_loss       : 0.613921995781645\n",
            "    val_accuracy   : 78.3623417721519\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch45.pth ...\n",
            "Train Epoch: 46 [0/45000 (0%)] Loss: 0.396998\n",
            "Train Epoch: 46 [512/45000 (1%)] Loss: 0.469630\n",
            "Train Epoch: 46 [1024/45000 (2%)] Loss: 0.470340\n",
            "Train Epoch: 46 [1536/45000 (3%)] Loss: 0.919795\n",
            "Train Epoch: 46 [2048/45000 (5%)] Loss: 0.525027\n",
            "Train Epoch: 46 [2560/45000 (6%)] Loss: 0.642009\n",
            "Train Epoch: 46 [3072/45000 (7%)] Loss: 0.624241\n",
            "Train Epoch: 46 [3584/45000 (8%)] Loss: 0.311374\n",
            "Train Epoch: 46 [4096/45000 (9%)] Loss: 0.599334\n",
            "Train Epoch: 46 [4608/45000 (10%)] Loss: 0.417055\n",
            "Train Epoch: 46 [5120/45000 (11%)] Loss: 0.625935\n",
            "Train Epoch: 46 [5632/45000 (13%)] Loss: 0.526733\n",
            "Train Epoch: 46 [6144/45000 (14%)] Loss: 0.377390\n",
            "Train Epoch: 46 [6656/45000 (15%)] Loss: 0.475273\n",
            "Train Epoch: 46 [7168/45000 (16%)] Loss: 0.701640\n",
            "Train Epoch: 46 [7680/45000 (17%)] Loss: 0.647604\n",
            "Train Epoch: 46 [8192/45000 (18%)] Loss: 0.460533\n",
            "Train Epoch: 46 [8704/45000 (19%)] Loss: 0.454014\n",
            "Train Epoch: 46 [9216/45000 (20%)] Loss: 0.477831\n",
            "Train Epoch: 46 [9728/45000 (22%)] Loss: 0.564854\n",
            "Train Epoch: 46 [10240/45000 (23%)] Loss: 0.516678\n",
            "Train Epoch: 46 [10752/45000 (24%)] Loss: 0.445944\n",
            "Train Epoch: 46 [11264/45000 (25%)] Loss: 0.456561\n",
            "Train Epoch: 46 [11776/45000 (26%)] Loss: 0.577439\n",
            "Train Epoch: 46 [12288/45000 (27%)] Loss: 0.456123\n",
            "Train Epoch: 46 [12800/45000 (28%)] Loss: 0.485897\n",
            "Train Epoch: 46 [13312/45000 (30%)] Loss: 0.578434\n",
            "Train Epoch: 46 [13824/45000 (31%)] Loss: 0.485505\n",
            "Train Epoch: 46 [14336/45000 (32%)] Loss: 0.452906\n",
            "Train Epoch: 46 [14848/45000 (33%)] Loss: 0.472591\n",
            "Train Epoch: 46 [15360/45000 (34%)] Loss: 0.514103\n",
            "Train Epoch: 46 [15872/45000 (35%)] Loss: 0.515859\n",
            "Train Epoch: 46 [16384/45000 (36%)] Loss: 0.731702\n",
            "Train Epoch: 46 [16896/45000 (38%)] Loss: 0.446091\n",
            "Train Epoch: 46 [17408/45000 (39%)] Loss: 0.743535\n",
            "Train Epoch: 46 [17920/45000 (40%)] Loss: 0.581231\n",
            "Train Epoch: 46 [18432/45000 (41%)] Loss: 0.470567\n",
            "Train Epoch: 46 [18944/45000 (42%)] Loss: 0.728509\n",
            "Train Epoch: 46 [19456/45000 (43%)] Loss: 0.704833\n",
            "Train Epoch: 46 [19968/45000 (44%)] Loss: 0.568440\n",
            "Train Epoch: 46 [20480/45000 (46%)] Loss: 0.529317\n",
            "Train Epoch: 46 [20992/45000 (47%)] Loss: 0.389450\n",
            "Train Epoch: 46 [21504/45000 (48%)] Loss: 0.511974\n",
            "Train Epoch: 46 [22016/45000 (49%)] Loss: 0.440185\n",
            "Train Epoch: 46 [22528/45000 (50%)] Loss: 0.662221\n",
            "Train Epoch: 46 [23040/45000 (51%)] Loss: 0.701157\n",
            "Train Epoch: 46 [23552/45000 (52%)] Loss: 0.430720\n",
            "Train Epoch: 46 [24064/45000 (53%)] Loss: 0.476444\n",
            "Train Epoch: 46 [24576/45000 (55%)] Loss: 0.533118\n",
            "Train Epoch: 46 [25088/45000 (56%)] Loss: 0.663065\n",
            "Train Epoch: 46 [25600/45000 (57%)] Loss: 0.472056\n",
            "Train Epoch: 46 [26112/45000 (58%)] Loss: 0.289845\n",
            "Train Epoch: 46 [26624/45000 (59%)] Loss: 0.545806\n",
            "Train Epoch: 46 [27136/45000 (60%)] Loss: 0.445508\n",
            "Train Epoch: 46 [27648/45000 (61%)] Loss: 0.387210\n",
            "Train Epoch: 46 [28160/45000 (63%)] Loss: 0.356452\n",
            "Train Epoch: 46 [28672/45000 (64%)] Loss: 0.473434\n",
            "Train Epoch: 46 [29184/45000 (65%)] Loss: 0.542176\n",
            "Train Epoch: 46 [29696/45000 (66%)] Loss: 0.426351\n",
            "Train Epoch: 46 [30208/45000 (67%)] Loss: 0.618992\n",
            "Train Epoch: 46 [30720/45000 (68%)] Loss: 0.562986\n",
            "Train Epoch: 46 [31232/45000 (69%)] Loss: 0.424892\n",
            "Train Epoch: 46 [31744/45000 (71%)] Loss: 0.451987\n",
            "Train Epoch: 46 [32256/45000 (72%)] Loss: 0.603458\n",
            "Train Epoch: 46 [32768/45000 (73%)] Loss: 0.655035\n",
            "Train Epoch: 46 [33280/45000 (74%)] Loss: 0.525786\n",
            "Train Epoch: 46 [33792/45000 (75%)] Loss: 0.470130\n",
            "Train Epoch: 46 [34304/45000 (76%)] Loss: 0.567140\n",
            "Train Epoch: 46 [34816/45000 (77%)] Loss: 0.333241\n",
            "Train Epoch: 46 [35328/45000 (79%)] Loss: 0.584289\n",
            "Train Epoch: 46 [35840/45000 (80%)] Loss: 0.409727\n",
            "Train Epoch: 46 [36352/45000 (81%)] Loss: 0.505507\n",
            "Train Epoch: 46 [36864/45000 (82%)] Loss: 0.665566\n",
            "Train Epoch: 46 [37376/45000 (83%)] Loss: 0.385809\n",
            "Train Epoch: 46 [37888/45000 (84%)] Loss: 0.693270\n",
            "Train Epoch: 46 [38400/45000 (85%)] Loss: 0.542020\n",
            "Train Epoch: 46 [38912/45000 (86%)] Loss: 0.436685\n",
            "Train Epoch: 46 [39424/45000 (88%)] Loss: 0.723451\n",
            "Train Epoch: 46 [39936/45000 (89%)] Loss: 0.384519\n",
            "Train Epoch: 46 [40448/45000 (90%)] Loss: 0.415940\n",
            "Train Epoch: 46 [40960/45000 (91%)] Loss: 0.704037\n",
            "Train Epoch: 46 [41472/45000 (92%)] Loss: 0.743147\n",
            "Train Epoch: 46 [41984/45000 (93%)] Loss: 0.454843\n",
            "Train Epoch: 46 [42496/45000 (94%)] Loss: 0.716465\n",
            "Train Epoch: 46 [43008/45000 (96%)] Loss: 0.516118\n",
            "Train Epoch: 46 [43520/45000 (97%)] Loss: 0.363735\n",
            "Train Epoch: 46 [44032/45000 (98%)] Loss: 0.464525\n",
            "Train Epoch: 46 [44544/45000 (99%)] Loss: 0.510944\n",
            "    epoch          : 46\n",
            "    loss           : 0.527466294736686\n",
            "    accuracy       : 81.94691051136364\n",
            "    val_loss       : 0.6042963322959368\n",
            "    val_accuracy   : 79.27215189873418\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch46.pth ...\n",
            "Train Epoch: 47 [0/45000 (0%)] Loss: 0.484019\n",
            "Train Epoch: 47 [512/45000 (1%)] Loss: 0.443315\n",
            "Train Epoch: 47 [1024/45000 (2%)] Loss: 0.482576\n",
            "Train Epoch: 47 [1536/45000 (3%)] Loss: 0.527391\n",
            "Train Epoch: 47 [2048/45000 (5%)] Loss: 0.524944\n",
            "Train Epoch: 47 [2560/45000 (6%)] Loss: 0.510527\n",
            "Train Epoch: 47 [3072/45000 (7%)] Loss: 0.589908\n",
            "Train Epoch: 47 [3584/45000 (8%)] Loss: 0.641484\n",
            "Train Epoch: 47 [4096/45000 (9%)] Loss: 0.615157\n",
            "Train Epoch: 47 [4608/45000 (10%)] Loss: 0.482165\n",
            "Train Epoch: 47 [5120/45000 (11%)] Loss: 0.496898\n",
            "Train Epoch: 47 [5632/45000 (13%)] Loss: 0.480824\n",
            "Train Epoch: 47 [6144/45000 (14%)] Loss: 0.611171\n",
            "Train Epoch: 47 [6656/45000 (15%)] Loss: 0.735927\n",
            "Train Epoch: 47 [7168/45000 (16%)] Loss: 0.338539\n",
            "Train Epoch: 47 [7680/45000 (17%)] Loss: 0.657920\n",
            "Train Epoch: 47 [8192/45000 (18%)] Loss: 0.684897\n",
            "Train Epoch: 47 [8704/45000 (19%)] Loss: 0.524686\n",
            "Train Epoch: 47 [9216/45000 (20%)] Loss: 0.548484\n",
            "Train Epoch: 47 [9728/45000 (22%)] Loss: 0.754453\n",
            "Train Epoch: 47 [10240/45000 (23%)] Loss: 0.385819\n",
            "Train Epoch: 47 [10752/45000 (24%)] Loss: 0.457441\n",
            "Train Epoch: 47 [11264/45000 (25%)] Loss: 0.480936\n",
            "Train Epoch: 47 [11776/45000 (26%)] Loss: 0.522487\n",
            "Train Epoch: 47 [12288/45000 (27%)] Loss: 0.521679\n",
            "Train Epoch: 47 [12800/45000 (28%)] Loss: 0.455304\n",
            "Train Epoch: 47 [13312/45000 (30%)] Loss: 0.563656\n",
            "Train Epoch: 47 [13824/45000 (31%)] Loss: 0.442272\n",
            "Train Epoch: 47 [14336/45000 (32%)] Loss: 0.488254\n",
            "Train Epoch: 47 [14848/45000 (33%)] Loss: 0.557327\n",
            "Train Epoch: 47 [15360/45000 (34%)] Loss: 0.568065\n",
            "Train Epoch: 47 [15872/45000 (35%)] Loss: 0.496550\n",
            "Train Epoch: 47 [16384/45000 (36%)] Loss: 0.436638\n",
            "Train Epoch: 47 [16896/45000 (38%)] Loss: 0.486279\n",
            "Train Epoch: 47 [17408/45000 (39%)] Loss: 0.645445\n",
            "Train Epoch: 47 [17920/45000 (40%)] Loss: 0.477600\n",
            "Train Epoch: 47 [18432/45000 (41%)] Loss: 0.436186\n",
            "Train Epoch: 47 [18944/45000 (42%)] Loss: 0.625988\n",
            "Train Epoch: 47 [19456/45000 (43%)] Loss: 0.669620\n",
            "Train Epoch: 47 [19968/45000 (44%)] Loss: 0.332273\n",
            "Train Epoch: 47 [20480/45000 (46%)] Loss: 0.545775\n",
            "Train Epoch: 47 [20992/45000 (47%)] Loss: 0.347293\n",
            "Train Epoch: 47 [21504/45000 (48%)] Loss: 0.574895\n",
            "Train Epoch: 47 [22016/45000 (49%)] Loss: 0.509326\n",
            "Train Epoch: 47 [22528/45000 (50%)] Loss: 0.376618\n",
            "Train Epoch: 47 [23040/45000 (51%)] Loss: 0.855738\n",
            "Train Epoch: 47 [23552/45000 (52%)] Loss: 0.395972\n",
            "Train Epoch: 47 [24064/45000 (53%)] Loss: 0.444914\n",
            "Train Epoch: 47 [24576/45000 (55%)] Loss: 0.537890\n",
            "Train Epoch: 47 [25088/45000 (56%)] Loss: 0.490035\n",
            "Train Epoch: 47 [25600/45000 (57%)] Loss: 0.543474\n",
            "Train Epoch: 47 [26112/45000 (58%)] Loss: 0.656231\n",
            "Train Epoch: 47 [26624/45000 (59%)] Loss: 0.266345\n",
            "Train Epoch: 47 [27136/45000 (60%)] Loss: 0.369621\n",
            "Train Epoch: 47 [27648/45000 (61%)] Loss: 0.651770\n",
            "Train Epoch: 47 [28160/45000 (63%)] Loss: 0.562761\n",
            "Train Epoch: 47 [28672/45000 (64%)] Loss: 0.471470\n",
            "Train Epoch: 47 [29184/45000 (65%)] Loss: 0.522160\n",
            "Train Epoch: 47 [29696/45000 (66%)] Loss: 0.507293\n",
            "Train Epoch: 47 [30208/45000 (67%)] Loss: 0.632340\n",
            "Train Epoch: 47 [30720/45000 (68%)] Loss: 0.733174\n",
            "Train Epoch: 47 [31232/45000 (69%)] Loss: 0.407389\n",
            "Train Epoch: 47 [31744/45000 (71%)] Loss: 0.372421\n",
            "Train Epoch: 47 [32256/45000 (72%)] Loss: 0.609155\n",
            "Train Epoch: 47 [32768/45000 (73%)] Loss: 0.465081\n",
            "Train Epoch: 47 [33280/45000 (74%)] Loss: 0.473014\n",
            "Train Epoch: 47 [33792/45000 (75%)] Loss: 0.385205\n",
            "Train Epoch: 47 [34304/45000 (76%)] Loss: 0.606393\n",
            "Train Epoch: 47 [34816/45000 (77%)] Loss: 0.508884\n",
            "Train Epoch: 47 [35328/45000 (79%)] Loss: 0.585987\n",
            "Train Epoch: 47 [35840/45000 (80%)] Loss: 0.440436\n",
            "Train Epoch: 47 [36352/45000 (81%)] Loss: 0.352293\n",
            "Train Epoch: 47 [36864/45000 (82%)] Loss: 0.707597\n",
            "Train Epoch: 47 [37376/45000 (83%)] Loss: 0.568926\n",
            "Train Epoch: 47 [37888/45000 (84%)] Loss: 0.542989\n",
            "Train Epoch: 47 [38400/45000 (85%)] Loss: 0.507424\n",
            "Train Epoch: 47 [38912/45000 (86%)] Loss: 0.734938\n",
            "Train Epoch: 47 [39424/45000 (88%)] Loss: 0.545947\n",
            "Train Epoch: 47 [39936/45000 (89%)] Loss: 0.454845\n",
            "Train Epoch: 47 [40448/45000 (90%)] Loss: 0.397381\n",
            "Train Epoch: 47 [40960/45000 (91%)] Loss: 0.377389\n",
            "Train Epoch: 47 [41472/45000 (92%)] Loss: 0.516452\n",
            "Train Epoch: 47 [41984/45000 (93%)] Loss: 0.656093\n",
            "Train Epoch: 47 [42496/45000 (94%)] Loss: 0.548354\n",
            "Train Epoch: 47 [43008/45000 (96%)] Loss: 0.620717\n",
            "Train Epoch: 47 [43520/45000 (97%)] Loss: 0.354089\n",
            "Train Epoch: 47 [44032/45000 (98%)] Loss: 0.489932\n",
            "Train Epoch: 47 [44544/45000 (99%)] Loss: 0.479001\n",
            "    epoch          : 47\n",
            "    loss           : 0.5296905794688924\n",
            "    accuracy       : 81.7626953125\n",
            "    val_loss       : 0.6009231315383429\n",
            "    val_accuracy   : 79.52927215189874\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch47.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 48 [0/45000 (0%)] Loss: 0.474224\n",
            "Train Epoch: 48 [512/45000 (1%)] Loss: 0.636532\n",
            "Train Epoch: 48 [1024/45000 (2%)] Loss: 0.365444\n",
            "Train Epoch: 48 [1536/45000 (3%)] Loss: 0.642978\n",
            "Train Epoch: 48 [2048/45000 (5%)] Loss: 0.443790\n",
            "Train Epoch: 48 [2560/45000 (6%)] Loss: 0.398043\n",
            "Train Epoch: 48 [3072/45000 (7%)] Loss: 0.409556\n",
            "Train Epoch: 48 [3584/45000 (8%)] Loss: 0.502839\n",
            "Train Epoch: 48 [4096/45000 (9%)] Loss: 0.265924\n",
            "Train Epoch: 48 [4608/45000 (10%)] Loss: 0.550556\n",
            "Train Epoch: 48 [5120/45000 (11%)] Loss: 0.782755\n",
            "Train Epoch: 48 [5632/45000 (13%)] Loss: 0.539650\n",
            "Train Epoch: 48 [6144/45000 (14%)] Loss: 0.419053\n",
            "Train Epoch: 48 [6656/45000 (15%)] Loss: 0.612072\n",
            "Train Epoch: 48 [7168/45000 (16%)] Loss: 0.493569\n",
            "Train Epoch: 48 [7680/45000 (17%)] Loss: 0.529846\n",
            "Train Epoch: 48 [8192/45000 (18%)] Loss: 0.642707\n",
            "Train Epoch: 48 [8704/45000 (19%)] Loss: 0.495820\n",
            "Train Epoch: 48 [9216/45000 (20%)] Loss: 0.710471\n",
            "Train Epoch: 48 [9728/45000 (22%)] Loss: 0.488450\n",
            "Train Epoch: 48 [10240/45000 (23%)] Loss: 0.476670\n",
            "Train Epoch: 48 [10752/45000 (24%)] Loss: 0.540918\n",
            "Train Epoch: 48 [11264/45000 (25%)] Loss: 0.629670\n",
            "Train Epoch: 48 [11776/45000 (26%)] Loss: 0.575719\n",
            "Train Epoch: 48 [12288/45000 (27%)] Loss: 0.458580\n",
            "Train Epoch: 48 [12800/45000 (28%)] Loss: 0.627157\n",
            "Train Epoch: 48 [13312/45000 (30%)] Loss: 0.402864\n",
            "Train Epoch: 48 [13824/45000 (31%)] Loss: 0.621648\n",
            "Train Epoch: 48 [14336/45000 (32%)] Loss: 0.316316\n",
            "Train Epoch: 48 [14848/45000 (33%)] Loss: 0.550613\n",
            "Train Epoch: 48 [15360/45000 (34%)] Loss: 0.529516\n",
            "Train Epoch: 48 [15872/45000 (35%)] Loss: 0.448253\n",
            "Train Epoch: 48 [16384/45000 (36%)] Loss: 0.463259\n",
            "Train Epoch: 48 [16896/45000 (38%)] Loss: 0.507106\n",
            "Train Epoch: 48 [17408/45000 (39%)] Loss: 0.670050\n",
            "Train Epoch: 48 [17920/45000 (40%)] Loss: 0.517055\n",
            "Train Epoch: 48 [18432/45000 (41%)] Loss: 0.599318\n",
            "Train Epoch: 48 [18944/45000 (42%)] Loss: 0.669620\n",
            "Train Epoch: 48 [19456/45000 (43%)] Loss: 0.635803\n",
            "Train Epoch: 48 [19968/45000 (44%)] Loss: 0.659395\n",
            "Train Epoch: 48 [20480/45000 (46%)] Loss: 0.739339\n",
            "Train Epoch: 48 [20992/45000 (47%)] Loss: 0.444812\n",
            "Train Epoch: 48 [21504/45000 (48%)] Loss: 0.552431\n",
            "Train Epoch: 48 [22016/45000 (49%)] Loss: 0.518541\n",
            "Train Epoch: 48 [22528/45000 (50%)] Loss: 0.465537\n",
            "Train Epoch: 48 [23040/45000 (51%)] Loss: 0.532016\n",
            "Train Epoch: 48 [23552/45000 (52%)] Loss: 0.514653\n",
            "Train Epoch: 48 [24064/45000 (53%)] Loss: 0.709505\n",
            "Train Epoch: 48 [24576/45000 (55%)] Loss: 0.648602\n",
            "Train Epoch: 48 [25088/45000 (56%)] Loss: 0.395293\n",
            "Train Epoch: 48 [25600/45000 (57%)] Loss: 0.728357\n",
            "Train Epoch: 48 [26112/45000 (58%)] Loss: 0.354376\n",
            "Train Epoch: 48 [26624/45000 (59%)] Loss: 0.614804\n",
            "Train Epoch: 48 [27136/45000 (60%)] Loss: 0.446756\n",
            "Train Epoch: 48 [27648/45000 (61%)] Loss: 0.488938\n",
            "Train Epoch: 48 [28160/45000 (63%)] Loss: 0.378164\n",
            "Train Epoch: 48 [28672/45000 (64%)] Loss: 0.577745\n",
            "Train Epoch: 48 [29184/45000 (65%)] Loss: 0.393037\n",
            "Train Epoch: 48 [29696/45000 (66%)] Loss: 0.567924\n",
            "Train Epoch: 48 [30208/45000 (67%)] Loss: 0.546261\n",
            "Train Epoch: 48 [30720/45000 (68%)] Loss: 0.681297\n",
            "Train Epoch: 48 [31232/45000 (69%)] Loss: 0.634413\n",
            "Train Epoch: 48 [31744/45000 (71%)] Loss: 0.524199\n",
            "Train Epoch: 48 [32256/45000 (72%)] Loss: 0.572696\n",
            "Train Epoch: 48 [32768/45000 (73%)] Loss: 0.570311\n",
            "Train Epoch: 48 [33280/45000 (74%)] Loss: 0.552095\n",
            "Train Epoch: 48 [33792/45000 (75%)] Loss: 0.630295\n",
            "Train Epoch: 48 [34304/45000 (76%)] Loss: 0.482715\n",
            "Train Epoch: 48 [34816/45000 (77%)] Loss: 0.470281\n",
            "Train Epoch: 48 [35328/45000 (79%)] Loss: 0.552525\n",
            "Train Epoch: 48 [35840/45000 (80%)] Loss: 0.415409\n",
            "Train Epoch: 48 [36352/45000 (81%)] Loss: 0.909789\n",
            "Train Epoch: 48 [36864/45000 (82%)] Loss: 0.498202\n",
            "Train Epoch: 48 [37376/45000 (83%)] Loss: 0.374557\n",
            "Train Epoch: 48 [37888/45000 (84%)] Loss: 0.617686\n",
            "Train Epoch: 48 [38400/45000 (85%)] Loss: 0.598231\n",
            "Train Epoch: 48 [38912/45000 (86%)] Loss: 0.555519\n",
            "Train Epoch: 48 [39424/45000 (88%)] Loss: 0.721273\n",
            "Train Epoch: 48 [39936/45000 (89%)] Loss: 0.299799\n",
            "Train Epoch: 48 [40448/45000 (90%)] Loss: 0.790464\n",
            "Train Epoch: 48 [40960/45000 (91%)] Loss: 0.529477\n",
            "Train Epoch: 48 [41472/45000 (92%)] Loss: 0.583899\n",
            "Train Epoch: 48 [41984/45000 (93%)] Loss: 0.691342\n",
            "Train Epoch: 48 [42496/45000 (94%)] Loss: 0.496376\n",
            "Train Epoch: 48 [43008/45000 (96%)] Loss: 0.477479\n",
            "Train Epoch: 48 [43520/45000 (97%)] Loss: 0.387067\n",
            "Train Epoch: 48 [44032/45000 (98%)] Loss: 1.073332\n",
            "Train Epoch: 48 [44544/45000 (99%)] Loss: 0.582469\n",
            "    epoch          : 48\n",
            "    loss           : 0.5321835039437495\n",
            "    accuracy       : 81.884765625\n",
            "    val_loss       : 0.593999666503713\n",
            "    val_accuracy   : 79.86550632911393\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch48.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 49 [0/45000 (0%)] Loss: 0.496964\n",
            "Train Epoch: 49 [512/45000 (1%)] Loss: 0.602014\n",
            "Train Epoch: 49 [1024/45000 (2%)] Loss: 0.421658\n",
            "Train Epoch: 49 [1536/45000 (3%)] Loss: 0.536797\n",
            "Train Epoch: 49 [2048/45000 (5%)] Loss: 0.444953\n",
            "Train Epoch: 49 [2560/45000 (6%)] Loss: 0.560479\n",
            "Train Epoch: 49 [3072/45000 (7%)] Loss: 0.763832\n",
            "Train Epoch: 49 [3584/45000 (8%)] Loss: 0.548797\n",
            "Train Epoch: 49 [4096/45000 (9%)] Loss: 0.650037\n",
            "Train Epoch: 49 [4608/45000 (10%)] Loss: 0.430104\n",
            "Train Epoch: 49 [5120/45000 (11%)] Loss: 0.485687\n",
            "Train Epoch: 49 [5632/45000 (13%)] Loss: 0.410206\n",
            "Train Epoch: 49 [6144/45000 (14%)] Loss: 0.529860\n",
            "Train Epoch: 49 [6656/45000 (15%)] Loss: 0.585669\n",
            "Train Epoch: 49 [7168/45000 (16%)] Loss: 0.499914\n",
            "Train Epoch: 49 [7680/45000 (17%)] Loss: 0.614746\n",
            "Train Epoch: 49 [8192/45000 (18%)] Loss: 0.457953\n",
            "Train Epoch: 49 [8704/45000 (19%)] Loss: 0.359016\n",
            "Train Epoch: 49 [9216/45000 (20%)] Loss: 0.419660\n",
            "Train Epoch: 49 [9728/45000 (22%)] Loss: 0.633499\n",
            "Train Epoch: 49 [10240/45000 (23%)] Loss: 0.717123\n",
            "Train Epoch: 49 [10752/45000 (24%)] Loss: 0.277706\n",
            "Train Epoch: 49 [11264/45000 (25%)] Loss: 0.719306\n",
            "Train Epoch: 49 [11776/45000 (26%)] Loss: 0.425704\n",
            "Train Epoch: 49 [12288/45000 (27%)] Loss: 0.649791\n",
            "Train Epoch: 49 [12800/45000 (28%)] Loss: 0.434077\n",
            "Train Epoch: 49 [13312/45000 (30%)] Loss: 0.551081\n",
            "Train Epoch: 49 [13824/45000 (31%)] Loss: 0.441061\n",
            "Train Epoch: 49 [14336/45000 (32%)] Loss: 0.523357\n",
            "Train Epoch: 49 [14848/45000 (33%)] Loss: 0.329995\n",
            "Train Epoch: 49 [15360/45000 (34%)] Loss: 0.589787\n",
            "Train Epoch: 49 [15872/45000 (35%)] Loss: 0.474355\n",
            "Train Epoch: 49 [16384/45000 (36%)] Loss: 0.721479\n",
            "Train Epoch: 49 [16896/45000 (38%)] Loss: 0.512079\n",
            "Train Epoch: 49 [17408/45000 (39%)] Loss: 0.457344\n",
            "Train Epoch: 49 [17920/45000 (40%)] Loss: 0.505611\n",
            "Train Epoch: 49 [18432/45000 (41%)] Loss: 0.559487\n",
            "Train Epoch: 49 [18944/45000 (42%)] Loss: 0.405198\n",
            "Train Epoch: 49 [19456/45000 (43%)] Loss: 0.404877\n",
            "Train Epoch: 49 [19968/45000 (44%)] Loss: 0.452044\n",
            "Train Epoch: 49 [20480/45000 (46%)] Loss: 0.504882\n",
            "Train Epoch: 49 [20992/45000 (47%)] Loss: 0.438286\n",
            "Train Epoch: 49 [21504/45000 (48%)] Loss: 0.568537\n",
            "Train Epoch: 49 [22016/45000 (49%)] Loss: 0.548838\n",
            "Train Epoch: 49 [22528/45000 (50%)] Loss: 0.493336\n",
            "Train Epoch: 49 [23040/45000 (51%)] Loss: 0.824033\n",
            "Train Epoch: 49 [23552/45000 (52%)] Loss: 0.583921\n",
            "Train Epoch: 49 [24064/45000 (53%)] Loss: 0.365440\n",
            "Train Epoch: 49 [24576/45000 (55%)] Loss: 0.612189\n",
            "Train Epoch: 49 [25088/45000 (56%)] Loss: 0.466384\n",
            "Train Epoch: 49 [25600/45000 (57%)] Loss: 0.521002\n",
            "Train Epoch: 49 [26112/45000 (58%)] Loss: 0.669565\n",
            "Train Epoch: 49 [26624/45000 (59%)] Loss: 0.552023\n",
            "Train Epoch: 49 [27136/45000 (60%)] Loss: 0.527161\n",
            "Train Epoch: 49 [27648/45000 (61%)] Loss: 0.692202\n",
            "Train Epoch: 49 [28160/45000 (63%)] Loss: 0.613000\n",
            "Train Epoch: 49 [28672/45000 (64%)] Loss: 0.729766\n",
            "Train Epoch: 49 [29184/45000 (65%)] Loss: 0.441443\n",
            "Train Epoch: 49 [29696/45000 (66%)] Loss: 0.680550\n",
            "Train Epoch: 49 [30208/45000 (67%)] Loss: 0.453455\n",
            "Train Epoch: 49 [30720/45000 (68%)] Loss: 0.520618\n",
            "Train Epoch: 49 [31232/45000 (69%)] Loss: 0.421643\n",
            "Train Epoch: 49 [31744/45000 (71%)] Loss: 0.739500\n",
            "Train Epoch: 49 [32256/45000 (72%)] Loss: 0.494584\n",
            "Train Epoch: 49 [32768/45000 (73%)] Loss: 0.605836\n",
            "Train Epoch: 49 [33280/45000 (74%)] Loss: 0.573572\n",
            "Train Epoch: 49 [33792/45000 (75%)] Loss: 0.456026\n",
            "Train Epoch: 49 [34304/45000 (76%)] Loss: 0.455900\n",
            "Train Epoch: 49 [34816/45000 (77%)] Loss: 0.406213\n",
            "Train Epoch: 49 [35328/45000 (79%)] Loss: 0.571260\n",
            "Train Epoch: 49 [35840/45000 (80%)] Loss: 0.758151\n",
            "Train Epoch: 49 [36352/45000 (81%)] Loss: 0.280889\n",
            "Train Epoch: 49 [36864/45000 (82%)] Loss: 0.524754\n",
            "Train Epoch: 49 [37376/45000 (83%)] Loss: 0.427506\n",
            "Train Epoch: 49 [37888/45000 (84%)] Loss: 0.539521\n",
            "Train Epoch: 49 [38400/45000 (85%)] Loss: 0.372044\n",
            "Train Epoch: 49 [38912/45000 (86%)] Loss: 0.468108\n",
            "Train Epoch: 49 [39424/45000 (88%)] Loss: 0.363234\n",
            "Train Epoch: 49 [39936/45000 (89%)] Loss: 0.470033\n",
            "Train Epoch: 49 [40448/45000 (90%)] Loss: 0.477275\n",
            "Train Epoch: 49 [40960/45000 (91%)] Loss: 0.785239\n",
            "Train Epoch: 49 [41472/45000 (92%)] Loss: 0.580609\n",
            "Train Epoch: 49 [41984/45000 (93%)] Loss: 0.322783\n",
            "Train Epoch: 49 [42496/45000 (94%)] Loss: 0.450452\n",
            "Train Epoch: 49 [43008/45000 (96%)] Loss: 0.479303\n",
            "Train Epoch: 49 [43520/45000 (97%)] Loss: 0.358502\n",
            "Train Epoch: 49 [44032/45000 (98%)] Loss: 0.606702\n",
            "Train Epoch: 49 [44544/45000 (99%)] Loss: 0.535233\n",
            "    epoch          : 49\n",
            "    loss           : 0.5319288699803028\n",
            "    accuracy       : 81.91139914772727\n",
            "    val_loss       : 0.5887141960519778\n",
            "    val_accuracy   : 79.62816455696202\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch49.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "Train Epoch: 50 [0/45000 (0%)] Loss: 0.462366\n",
            "Train Epoch: 50 [512/45000 (1%)] Loss: 0.474010\n",
            "Train Epoch: 50 [1024/45000 (2%)] Loss: 0.459240\n",
            "Train Epoch: 50 [1536/45000 (3%)] Loss: 0.561220\n",
            "Train Epoch: 50 [2048/45000 (5%)] Loss: 0.416632\n",
            "Train Epoch: 50 [2560/45000 (6%)] Loss: 0.634388\n",
            "Train Epoch: 50 [3072/45000 (7%)] Loss: 0.510578\n",
            "Train Epoch: 50 [3584/45000 (8%)] Loss: 0.635185\n",
            "Train Epoch: 50 [4096/45000 (9%)] Loss: 0.588730\n",
            "Train Epoch: 50 [4608/45000 (10%)] Loss: 0.520510\n",
            "Train Epoch: 50 [5120/45000 (11%)] Loss: 0.422533\n",
            "Train Epoch: 50 [5632/45000 (13%)] Loss: 0.563415\n",
            "Train Epoch: 50 [6144/45000 (14%)] Loss: 0.630379\n",
            "Train Epoch: 50 [6656/45000 (15%)] Loss: 0.368853\n",
            "Train Epoch: 50 [7168/45000 (16%)] Loss: 0.592622\n",
            "Train Epoch: 50 [7680/45000 (17%)] Loss: 0.637816\n",
            "Train Epoch: 50 [8192/45000 (18%)] Loss: 0.757420\n",
            "Train Epoch: 50 [8704/45000 (19%)] Loss: 0.516484\n",
            "Train Epoch: 50 [9216/45000 (20%)] Loss: 0.416539\n",
            "Train Epoch: 50 [9728/45000 (22%)] Loss: 0.467610\n",
            "Train Epoch: 50 [10240/45000 (23%)] Loss: 0.550650\n",
            "Train Epoch: 50 [10752/45000 (24%)] Loss: 0.445068\n",
            "Train Epoch: 50 [11264/45000 (25%)] Loss: 0.407524\n",
            "Train Epoch: 50 [11776/45000 (26%)] Loss: 0.634209\n",
            "Train Epoch: 50 [12288/45000 (27%)] Loss: 0.563193\n",
            "Train Epoch: 50 [12800/45000 (28%)] Loss: 0.578837\n",
            "Train Epoch: 50 [13312/45000 (30%)] Loss: 0.523646\n",
            "Train Epoch: 50 [13824/45000 (31%)] Loss: 0.450258\n",
            "Train Epoch: 50 [14336/45000 (32%)] Loss: 0.543979\n",
            "Train Epoch: 50 [14848/45000 (33%)] Loss: 0.715779\n",
            "Train Epoch: 50 [15360/45000 (34%)] Loss: 0.603273\n",
            "Train Epoch: 50 [15872/45000 (35%)] Loss: 0.393140\n",
            "Train Epoch: 50 [16384/45000 (36%)] Loss: 0.687495\n",
            "Train Epoch: 50 [16896/45000 (38%)] Loss: 0.731751\n",
            "Train Epoch: 50 [17408/45000 (39%)] Loss: 0.532751\n",
            "Train Epoch: 50 [17920/45000 (40%)] Loss: 0.494736\n",
            "Train Epoch: 50 [18432/45000 (41%)] Loss: 0.371607\n",
            "Train Epoch: 50 [18944/45000 (42%)] Loss: 0.351342\n",
            "Train Epoch: 50 [19456/45000 (43%)] Loss: 0.428578\n",
            "Train Epoch: 50 [19968/45000 (44%)] Loss: 0.496001\n",
            "Train Epoch: 50 [20480/45000 (46%)] Loss: 0.488887\n",
            "Train Epoch: 50 [20992/45000 (47%)] Loss: 0.412495\n",
            "Train Epoch: 50 [21504/45000 (48%)] Loss: 0.536138\n",
            "Train Epoch: 50 [22016/45000 (49%)] Loss: 0.642961\n",
            "Train Epoch: 50 [22528/45000 (50%)] Loss: 0.651238\n",
            "Train Epoch: 50 [23040/45000 (51%)] Loss: 0.695119\n",
            "Train Epoch: 50 [23552/45000 (52%)] Loss: 0.511627\n",
            "Train Epoch: 50 [24064/45000 (53%)] Loss: 0.528123\n",
            "Train Epoch: 50 [24576/45000 (55%)] Loss: 0.553527\n",
            "Train Epoch: 50 [25088/45000 (56%)] Loss: 0.398741\n",
            "Train Epoch: 50 [25600/45000 (57%)] Loss: 0.473688\n",
            "Train Epoch: 50 [26112/45000 (58%)] Loss: 0.439044\n",
            "Train Epoch: 50 [26624/45000 (59%)] Loss: 0.557571\n",
            "Train Epoch: 50 [27136/45000 (60%)] Loss: 0.472180\n",
            "Train Epoch: 50 [27648/45000 (61%)] Loss: 0.607330\n",
            "Train Epoch: 50 [28160/45000 (63%)] Loss: 0.537067\n",
            "Train Epoch: 50 [28672/45000 (64%)] Loss: 0.492009\n",
            "Train Epoch: 50 [29184/45000 (65%)] Loss: 0.560284\n",
            "Train Epoch: 50 [29696/45000 (66%)] Loss: 0.417036\n",
            "Train Epoch: 50 [30208/45000 (67%)] Loss: 0.478661\n",
            "Train Epoch: 50 [30720/45000 (68%)] Loss: 0.549167\n",
            "Train Epoch: 50 [31232/45000 (69%)] Loss: 0.524019\n",
            "Train Epoch: 50 [31744/45000 (71%)] Loss: 0.493806\n",
            "Train Epoch: 50 [32256/45000 (72%)] Loss: 0.369691\n",
            "Train Epoch: 50 [32768/45000 (73%)] Loss: 0.399036\n",
            "Train Epoch: 50 [33280/45000 (74%)] Loss: 0.487950\n",
            "Train Epoch: 50 [33792/45000 (75%)] Loss: 0.470822\n",
            "Train Epoch: 50 [34304/45000 (76%)] Loss: 0.456624\n",
            "Train Epoch: 50 [34816/45000 (77%)] Loss: 0.558185\n",
            "Train Epoch: 50 [35328/45000 (79%)] Loss: 0.568903\n",
            "Train Epoch: 50 [35840/45000 (80%)] Loss: 0.467003\n",
            "Train Epoch: 50 [36352/45000 (81%)] Loss: 0.710555\n",
            "Train Epoch: 50 [36864/45000 (82%)] Loss: 0.478699\n",
            "Train Epoch: 50 [37376/45000 (83%)] Loss: 0.536699\n",
            "Train Epoch: 50 [37888/45000 (84%)] Loss: 0.682410\n",
            "Train Epoch: 50 [38400/45000 (85%)] Loss: 0.584657\n",
            "Train Epoch: 50 [38912/45000 (86%)] Loss: 0.505616\n",
            "Train Epoch: 50 [39424/45000 (88%)] Loss: 0.661595\n",
            "Train Epoch: 50 [39936/45000 (89%)] Loss: 0.535985\n",
            "Train Epoch: 50 [40448/45000 (90%)] Loss: 0.523392\n",
            "Train Epoch: 50 [40960/45000 (91%)] Loss: 0.567405\n",
            "Train Epoch: 50 [41472/45000 (92%)] Loss: 0.835758\n",
            "Train Epoch: 50 [41984/45000 (93%)] Loss: 0.484820\n",
            "Train Epoch: 50 [42496/45000 (94%)] Loss: 0.525975\n",
            "Train Epoch: 50 [43008/45000 (96%)] Loss: 0.553218\n",
            "Train Epoch: 50 [43520/45000 (97%)] Loss: 0.436063\n",
            "Train Epoch: 50 [44032/45000 (98%)] Loss: 0.631001\n",
            "Train Epoch: 50 [44544/45000 (99%)] Loss: 0.639020\n",
            "    epoch          : 50\n",
            "    loss           : 0.5261545021891255\n",
            "    accuracy       : 82.2265625\n",
            "    val_loss       : 0.6255234891100775\n",
            "    val_accuracy   : 78.34256329113924\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch50.pth ...\n",
            "Train Epoch: 51 [0/45000 (0%)] Loss: 0.435352\n",
            "Train Epoch: 51 [512/45000 (1%)] Loss: 0.604774\n",
            "Train Epoch: 51 [1024/45000 (2%)] Loss: 0.503051\n",
            "Train Epoch: 51 [1536/45000 (3%)] Loss: 0.540347\n",
            "Train Epoch: 51 [2048/45000 (5%)] Loss: 0.595554\n",
            "Train Epoch: 51 [2560/45000 (6%)] Loss: 0.742874\n",
            "Train Epoch: 51 [3072/45000 (7%)] Loss: 0.599790\n",
            "Train Epoch: 51 [3584/45000 (8%)] Loss: 0.531296\n",
            "Train Epoch: 51 [4096/45000 (9%)] Loss: 0.438820\n",
            "Train Epoch: 51 [4608/45000 (10%)] Loss: 0.723021\n",
            "Train Epoch: 51 [5120/45000 (11%)] Loss: 0.526033\n",
            "Train Epoch: 51 [5632/45000 (13%)] Loss: 0.408660\n",
            "Train Epoch: 51 [6144/45000 (14%)] Loss: 0.473988\n",
            "Train Epoch: 51 [6656/45000 (15%)] Loss: 0.570111\n",
            "Train Epoch: 51 [7168/45000 (16%)] Loss: 0.651673\n",
            "Train Epoch: 51 [7680/45000 (17%)] Loss: 0.503277\n",
            "Train Epoch: 51 [8192/45000 (18%)] Loss: 0.667684\n",
            "Train Epoch: 51 [8704/45000 (19%)] Loss: 0.576108\n",
            "Train Epoch: 51 [9216/45000 (20%)] Loss: 0.624543\n",
            "Train Epoch: 51 [9728/45000 (22%)] Loss: 0.569910\n",
            "Train Epoch: 51 [10240/45000 (23%)] Loss: 0.459967\n",
            "Train Epoch: 51 [10752/45000 (24%)] Loss: 0.487641\n",
            "Train Epoch: 51 [11264/45000 (25%)] Loss: 0.428832\n",
            "Train Epoch: 51 [11776/45000 (26%)] Loss: 0.600088\n",
            "Train Epoch: 51 [12288/45000 (27%)] Loss: 0.468073\n",
            "Train Epoch: 51 [12800/45000 (28%)] Loss: 0.628304\n",
            "Train Epoch: 51 [13312/45000 (30%)] Loss: 0.439123\n",
            "Train Epoch: 51 [13824/45000 (31%)] Loss: 0.470920\n",
            "Train Epoch: 51 [14336/45000 (32%)] Loss: 0.462310\n",
            "Train Epoch: 51 [14848/45000 (33%)] Loss: 0.550985\n",
            "Train Epoch: 51 [15360/45000 (34%)] Loss: 0.479697\n",
            "Train Epoch: 51 [15872/45000 (35%)] Loss: 0.813252\n",
            "Train Epoch: 51 [16384/45000 (36%)] Loss: 0.396873\n",
            "Train Epoch: 51 [16896/45000 (38%)] Loss: 0.703578\n",
            "Train Epoch: 51 [17408/45000 (39%)] Loss: 0.676429\n",
            "Train Epoch: 51 [17920/45000 (40%)] Loss: 0.641718\n",
            "Train Epoch: 51 [18432/45000 (41%)] Loss: 0.772044\n",
            "Train Epoch: 51 [18944/45000 (42%)] Loss: 0.582851\n",
            "Train Epoch: 51 [19456/45000 (43%)] Loss: 0.633889\n",
            "Train Epoch: 51 [19968/45000 (44%)] Loss: 0.640564\n",
            "Train Epoch: 51 [20480/45000 (46%)] Loss: 0.666885\n",
            "Train Epoch: 51 [20992/45000 (47%)] Loss: 0.401043\n",
            "Train Epoch: 51 [21504/45000 (48%)] Loss: 0.444737\n",
            "Train Epoch: 51 [22016/45000 (49%)] Loss: 0.419795\n",
            "Train Epoch: 51 [22528/45000 (50%)] Loss: 0.421691\n",
            "Train Epoch: 51 [23040/45000 (51%)] Loss: 0.647539\n",
            "Train Epoch: 51 [23552/45000 (52%)] Loss: 0.549885\n",
            "Train Epoch: 51 [24064/45000 (53%)] Loss: 0.572415\n",
            "Train Epoch: 51 [24576/45000 (55%)] Loss: 0.475764\n",
            "Train Epoch: 51 [25088/45000 (56%)] Loss: 0.443333\n",
            "Train Epoch: 51 [25600/45000 (57%)] Loss: 0.563247\n",
            "Train Epoch: 51 [26112/45000 (58%)] Loss: 0.468797\n",
            "Train Epoch: 51 [26624/45000 (59%)] Loss: 0.250019\n",
            "Train Epoch: 51 [27136/45000 (60%)] Loss: 0.514017\n",
            "Train Epoch: 51 [27648/45000 (61%)] Loss: 0.629151\n",
            "Train Epoch: 51 [28160/45000 (63%)] Loss: 0.348426\n",
            "Train Epoch: 51 [28672/45000 (64%)] Loss: 0.576650\n",
            "Train Epoch: 51 [29184/45000 (65%)] Loss: 0.559041\n",
            "Train Epoch: 51 [29696/45000 (66%)] Loss: 0.607825\n",
            "Train Epoch: 51 [30208/45000 (67%)] Loss: 0.618133\n",
            "Train Epoch: 51 [30720/45000 (68%)] Loss: 0.439403\n",
            "Train Epoch: 51 [31232/45000 (69%)] Loss: 0.636923\n",
            "Train Epoch: 51 [31744/45000 (71%)] Loss: 0.589666\n",
            "Train Epoch: 51 [32256/45000 (72%)] Loss: 0.453123\n",
            "Train Epoch: 51 [32768/45000 (73%)] Loss: 0.496924\n",
            "Train Epoch: 51 [33280/45000 (74%)] Loss: 0.373811\n",
            "Train Epoch: 51 [33792/45000 (75%)] Loss: 0.592194\n",
            "Train Epoch: 51 [34304/45000 (76%)] Loss: 0.487155\n",
            "Train Epoch: 51 [34816/45000 (77%)] Loss: 0.659429\n",
            "Train Epoch: 51 [35328/45000 (79%)] Loss: 0.364043\n",
            "Train Epoch: 51 [35840/45000 (80%)] Loss: 0.435892\n",
            "Train Epoch: 51 [36352/45000 (81%)] Loss: 0.468155\n",
            "Train Epoch: 51 [36864/45000 (82%)] Loss: 0.576974\n",
            "Train Epoch: 51 [37376/45000 (83%)] Loss: 0.339768\n",
            "Train Epoch: 51 [37888/45000 (84%)] Loss: 0.483401\n",
            "Train Epoch: 51 [38400/45000 (85%)] Loss: 0.301211\n",
            "Train Epoch: 51 [38912/45000 (86%)] Loss: 0.609832\n",
            "Train Epoch: 51 [39424/45000 (88%)] Loss: 0.446821\n",
            "Train Epoch: 51 [39936/45000 (89%)] Loss: 0.538884\n",
            "Train Epoch: 51 [40448/45000 (90%)] Loss: 0.426076\n",
            "Train Epoch: 51 [40960/45000 (91%)] Loss: 0.378410\n",
            "Train Epoch: 51 [41472/45000 (92%)] Loss: 0.570900\n",
            "Train Epoch: 51 [41984/45000 (93%)] Loss: 0.639552\n",
            "Train Epoch: 51 [42496/45000 (94%)] Loss: 0.652917\n",
            "Train Epoch: 51 [43008/45000 (96%)] Loss: 0.480365\n",
            "Train Epoch: 51 [43520/45000 (97%)] Loss: 0.774975\n",
            "Train Epoch: 51 [44032/45000 (98%)] Loss: 0.415599\n",
            "Train Epoch: 51 [44544/45000 (99%)] Loss: 0.633082\n",
            "    epoch          : 51\n",
            "    loss           : 0.5281149319119074\n",
            "    accuracy       : 82.04234730113636\n",
            "    val_loss       : 0.6058119124249567\n",
            "    val_accuracy   : 79.50949367088607\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch51.pth ...\n",
            "Train Epoch: 52 [0/45000 (0%)] Loss: 0.479253\n",
            "Train Epoch: 52 [512/45000 (1%)] Loss: 0.452915\n",
            "Train Epoch: 52 [1024/45000 (2%)] Loss: 0.608337\n",
            "Train Epoch: 52 [1536/45000 (3%)] Loss: 0.369657\n",
            "Train Epoch: 52 [2048/45000 (5%)] Loss: 0.438045\n",
            "Train Epoch: 52 [2560/45000 (6%)] Loss: 0.493039\n",
            "Train Epoch: 52 [3072/45000 (7%)] Loss: 0.565474\n",
            "Train Epoch: 52 [3584/45000 (8%)] Loss: 0.398836\n",
            "Train Epoch: 52 [4096/45000 (9%)] Loss: 0.433594\n",
            "Train Epoch: 52 [4608/45000 (10%)] Loss: 0.687878\n",
            "Train Epoch: 52 [5120/45000 (11%)] Loss: 0.387504\n",
            "Train Epoch: 52 [5632/45000 (13%)] Loss: 0.505519\n",
            "Train Epoch: 52 [6144/45000 (14%)] Loss: 0.713381\n",
            "Train Epoch: 52 [6656/45000 (15%)] Loss: 0.606426\n",
            "Train Epoch: 52 [7168/45000 (16%)] Loss: 0.617840\n",
            "Train Epoch: 52 [7680/45000 (17%)] Loss: 0.211655\n",
            "Train Epoch: 52 [8192/45000 (18%)] Loss: 0.497822\n",
            "Train Epoch: 52 [8704/45000 (19%)] Loss: 0.441602\n",
            "Train Epoch: 52 [9216/45000 (20%)] Loss: 0.469394\n",
            "Train Epoch: 52 [9728/45000 (22%)] Loss: 0.645692\n",
            "Train Epoch: 52 [10240/45000 (23%)] Loss: 0.465518\n",
            "Train Epoch: 52 [10752/45000 (24%)] Loss: 0.445518\n",
            "Train Epoch: 52 [11264/45000 (25%)] Loss: 0.592434\n",
            "Train Epoch: 52 [11776/45000 (26%)] Loss: 0.533186\n",
            "Train Epoch: 52 [12288/45000 (27%)] Loss: 0.714198\n",
            "Train Epoch: 52 [12800/45000 (28%)] Loss: 0.592007\n",
            "Train Epoch: 52 [13312/45000 (30%)] Loss: 0.445045\n",
            "Train Epoch: 52 [13824/45000 (31%)] Loss: 0.322563\n",
            "Train Epoch: 52 [14336/45000 (32%)] Loss: 0.525877\n",
            "Train Epoch: 52 [14848/45000 (33%)] Loss: 0.374806\n",
            "Train Epoch: 52 [15360/45000 (34%)] Loss: 0.620461\n",
            "Train Epoch: 52 [15872/45000 (35%)] Loss: 0.369133\n",
            "Train Epoch: 52 [16384/45000 (36%)] Loss: 0.706668\n",
            "Train Epoch: 52 [16896/45000 (38%)] Loss: 0.789308\n",
            "Train Epoch: 52 [17408/45000 (39%)] Loss: 0.593511\n",
            "Train Epoch: 52 [17920/45000 (40%)] Loss: 0.515480\n",
            "Train Epoch: 52 [18432/45000 (41%)] Loss: 0.531681\n",
            "Train Epoch: 52 [18944/45000 (42%)] Loss: 0.398151\n",
            "Train Epoch: 52 [19456/45000 (43%)] Loss: 0.454910\n",
            "Train Epoch: 52 [19968/45000 (44%)] Loss: 0.423760\n",
            "Train Epoch: 52 [20480/45000 (46%)] Loss: 0.710860\n",
            "Train Epoch: 52 [20992/45000 (47%)] Loss: 0.501203\n",
            "Train Epoch: 52 [21504/45000 (48%)] Loss: 0.685277\n",
            "Train Epoch: 52 [22016/45000 (49%)] Loss: 0.479195\n",
            "Train Epoch: 52 [22528/45000 (50%)] Loss: 0.597956\n",
            "Train Epoch: 52 [23040/45000 (51%)] Loss: 0.500967\n",
            "Train Epoch: 52 [23552/45000 (52%)] Loss: 0.467459\n",
            "Train Epoch: 52 [24064/45000 (53%)] Loss: 0.652829\n",
            "Train Epoch: 52 [24576/45000 (55%)] Loss: 0.494292\n",
            "Train Epoch: 52 [25088/45000 (56%)] Loss: 0.510624\n",
            "Train Epoch: 52 [25600/45000 (57%)] Loss: 0.539538\n",
            "Train Epoch: 52 [26112/45000 (58%)] Loss: 0.552940\n",
            "Train Epoch: 52 [26624/45000 (59%)] Loss: 0.374621\n",
            "Train Epoch: 52 [27136/45000 (60%)] Loss: 0.615143\n",
            "Train Epoch: 52 [27648/45000 (61%)] Loss: 0.461717\n",
            "Train Epoch: 52 [28160/45000 (63%)] Loss: 0.528794\n",
            "Train Epoch: 52 [28672/45000 (64%)] Loss: 0.574712\n",
            "Train Epoch: 52 [29184/45000 (65%)] Loss: 0.509321\n",
            "Train Epoch: 52 [29696/45000 (66%)] Loss: 0.579710\n",
            "Train Epoch: 52 [30208/45000 (67%)] Loss: 0.378902\n",
            "Train Epoch: 52 [30720/45000 (68%)] Loss: 0.323639\n",
            "Train Epoch: 52 [31232/45000 (69%)] Loss: 0.419860\n",
            "Train Epoch: 52 [31744/45000 (71%)] Loss: 0.360091\n",
            "Train Epoch: 52 [32256/45000 (72%)] Loss: 0.419660\n",
            "Train Epoch: 52 [32768/45000 (73%)] Loss: 0.529130\n",
            "Train Epoch: 52 [33280/45000 (74%)] Loss: 0.605610\n",
            "Train Epoch: 52 [33792/45000 (75%)] Loss: 0.516207\n",
            "Train Epoch: 52 [34304/45000 (76%)] Loss: 0.537384\n",
            "Train Epoch: 52 [34816/45000 (77%)] Loss: 0.692492\n",
            "Train Epoch: 52 [35328/45000 (79%)] Loss: 0.591323\n",
            "Train Epoch: 52 [35840/45000 (80%)] Loss: 0.707458\n",
            "Train Epoch: 52 [36352/45000 (81%)] Loss: 0.606870\n",
            "Train Epoch: 52 [36864/45000 (82%)] Loss: 0.713659\n",
            "Train Epoch: 52 [37376/45000 (83%)] Loss: 0.700961\n",
            "Train Epoch: 52 [37888/45000 (84%)] Loss: 0.705717\n",
            "Train Epoch: 52 [38400/45000 (85%)] Loss: 0.481675\n",
            "Train Epoch: 52 [38912/45000 (86%)] Loss: 0.474153\n",
            "Train Epoch: 52 [39424/45000 (88%)] Loss: 0.558489\n",
            "Train Epoch: 52 [39936/45000 (89%)] Loss: 0.409752\n",
            "Train Epoch: 52 [40448/45000 (90%)] Loss: 0.531068\n",
            "Train Epoch: 52 [40960/45000 (91%)] Loss: 0.433863\n",
            "Train Epoch: 52 [41472/45000 (92%)] Loss: 0.571366\n",
            "Train Epoch: 52 [41984/45000 (93%)] Loss: 0.494986\n",
            "Train Epoch: 52 [42496/45000 (94%)] Loss: 0.568728\n",
            "Train Epoch: 52 [43008/45000 (96%)] Loss: 0.395028\n",
            "Train Epoch: 52 [43520/45000 (97%)] Loss: 0.780416\n",
            "Train Epoch: 52 [44032/45000 (98%)] Loss: 0.522942\n",
            "Train Epoch: 52 [44544/45000 (99%)] Loss: 0.603220\n",
            "    epoch          : 52\n",
            "    loss           : 0.5304776319217953\n",
            "    accuracy       : 81.95134943181819\n",
            "    val_loss       : 0.6109986640984499\n",
            "    val_accuracy   : 79.01503164556962\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch52.pth ...\n",
            "Train Epoch: 53 [0/45000 (0%)] Loss: 0.494049\n",
            "Train Epoch: 53 [512/45000 (1%)] Loss: 0.522056\n",
            "Train Epoch: 53 [1024/45000 (2%)] Loss: 0.465334\n",
            "Train Epoch: 53 [1536/45000 (3%)] Loss: 0.524360\n",
            "Train Epoch: 53 [2048/45000 (5%)] Loss: 0.642361\n",
            "Train Epoch: 53 [2560/45000 (6%)] Loss: 0.694479\n",
            "Train Epoch: 53 [3072/45000 (7%)] Loss: 0.307852\n",
            "Train Epoch: 53 [3584/45000 (8%)] Loss: 0.486562\n",
            "Train Epoch: 53 [4096/45000 (9%)] Loss: 0.417919\n",
            "Train Epoch: 53 [4608/45000 (10%)] Loss: 0.468570\n",
            "Train Epoch: 53 [5120/45000 (11%)] Loss: 0.428360\n",
            "Train Epoch: 53 [5632/45000 (13%)] Loss: 0.516040\n",
            "Train Epoch: 53 [6144/45000 (14%)] Loss: 0.543442\n",
            "Train Epoch: 53 [6656/45000 (15%)] Loss: 0.503264\n",
            "Train Epoch: 53 [7168/45000 (16%)] Loss: 0.450470\n",
            "Train Epoch: 53 [7680/45000 (17%)] Loss: 0.713781\n",
            "Train Epoch: 53 [8192/45000 (18%)] Loss: 0.666871\n",
            "Train Epoch: 53 [8704/45000 (19%)] Loss: 0.662232\n",
            "Train Epoch: 53 [9216/45000 (20%)] Loss: 0.411628\n",
            "Train Epoch: 53 [9728/45000 (22%)] Loss: 0.612637\n",
            "Train Epoch: 53 [10240/45000 (23%)] Loss: 0.466412\n",
            "Train Epoch: 53 [10752/45000 (24%)] Loss: 0.523637\n",
            "Train Epoch: 53 [11264/45000 (25%)] Loss: 0.617006\n",
            "Train Epoch: 53 [11776/45000 (26%)] Loss: 0.550454\n",
            "Train Epoch: 53 [12288/45000 (27%)] Loss: 0.375628\n",
            "Train Epoch: 53 [12800/45000 (28%)] Loss: 0.583110\n",
            "Train Epoch: 53 [13312/45000 (30%)] Loss: 0.566272\n",
            "Train Epoch: 53 [13824/45000 (31%)] Loss: 0.290419\n",
            "Train Epoch: 53 [14336/45000 (32%)] Loss: 0.525837\n",
            "Train Epoch: 53 [14848/45000 (33%)] Loss: 0.506766\n",
            "Train Epoch: 53 [15360/45000 (34%)] Loss: 0.484150\n",
            "Train Epoch: 53 [15872/45000 (35%)] Loss: 0.412161\n",
            "Train Epoch: 53 [16384/45000 (36%)] Loss: 0.550816\n",
            "Train Epoch: 53 [16896/45000 (38%)] Loss: 0.528199\n",
            "Train Epoch: 53 [17408/45000 (39%)] Loss: 0.698251\n",
            "Train Epoch: 53 [17920/45000 (40%)] Loss: 0.622837\n",
            "Train Epoch: 53 [18432/45000 (41%)] Loss: 0.678990\n",
            "Train Epoch: 53 [18944/45000 (42%)] Loss: 0.487177\n",
            "Train Epoch: 53 [19456/45000 (43%)] Loss: 0.447078\n",
            "Train Epoch: 53 [19968/45000 (44%)] Loss: 0.630939\n",
            "Train Epoch: 53 [20480/45000 (46%)] Loss: 0.459990\n",
            "Train Epoch: 53 [20992/45000 (47%)] Loss: 0.405874\n",
            "Train Epoch: 53 [21504/45000 (48%)] Loss: 0.554504\n",
            "Train Epoch: 53 [22016/45000 (49%)] Loss: 0.514615\n",
            "Train Epoch: 53 [22528/45000 (50%)] Loss: 0.475019\n",
            "Train Epoch: 53 [23040/45000 (51%)] Loss: 0.437918\n",
            "Train Epoch: 53 [23552/45000 (52%)] Loss: 0.649496\n",
            "Train Epoch: 53 [24064/45000 (53%)] Loss: 0.624745\n",
            "Train Epoch: 53 [24576/45000 (55%)] Loss: 0.586314\n",
            "Train Epoch: 53 [25088/45000 (56%)] Loss: 0.535956\n",
            "Train Epoch: 53 [25600/45000 (57%)] Loss: 0.515917\n",
            "Train Epoch: 53 [26112/45000 (58%)] Loss: 0.463313\n",
            "Train Epoch: 53 [26624/45000 (59%)] Loss: 0.748515\n",
            "Train Epoch: 53 [27136/45000 (60%)] Loss: 0.649619\n",
            "Train Epoch: 53 [27648/45000 (61%)] Loss: 0.482529\n",
            "Train Epoch: 53 [28160/45000 (63%)] Loss: 0.503130\n",
            "Train Epoch: 53 [28672/45000 (64%)] Loss: 0.546339\n",
            "Train Epoch: 53 [29184/45000 (65%)] Loss: 0.376433\n",
            "Train Epoch: 53 [29696/45000 (66%)] Loss: 0.469403\n",
            "Train Epoch: 53 [30208/45000 (67%)] Loss: 0.503576\n",
            "Train Epoch: 53 [30720/45000 (68%)] Loss: 0.526440\n",
            "Train Epoch: 53 [31232/45000 (69%)] Loss: 0.423185\n",
            "Train Epoch: 53 [31744/45000 (71%)] Loss: 0.653186\n",
            "Train Epoch: 53 [32256/45000 (72%)] Loss: 0.476973\n",
            "Train Epoch: 53 [32768/45000 (73%)] Loss: 0.575107\n",
            "Train Epoch: 53 [33280/45000 (74%)] Loss: 0.600591\n",
            "Train Epoch: 53 [33792/45000 (75%)] Loss: 0.578892\n",
            "Train Epoch: 53 [34304/45000 (76%)] Loss: 0.325657\n",
            "Train Epoch: 53 [34816/45000 (77%)] Loss: 0.471584\n",
            "Train Epoch: 53 [35328/45000 (79%)] Loss: 0.625547\n",
            "Train Epoch: 53 [35840/45000 (80%)] Loss: 0.708353\n",
            "Train Epoch: 53 [36352/45000 (81%)] Loss: 0.573605\n",
            "Train Epoch: 53 [36864/45000 (82%)] Loss: 0.521633\n",
            "Train Epoch: 53 [37376/45000 (83%)] Loss: 0.761808\n",
            "Train Epoch: 53 [37888/45000 (84%)] Loss: 0.396635\n",
            "Train Epoch: 53 [38400/45000 (85%)] Loss: 0.516460\n",
            "Train Epoch: 53 [38912/45000 (86%)] Loss: 0.639430\n",
            "Train Epoch: 53 [39424/45000 (88%)] Loss: 0.612602\n",
            "Train Epoch: 53 [39936/45000 (89%)] Loss: 0.480146\n",
            "Train Epoch: 53 [40448/45000 (90%)] Loss: 0.504750\n",
            "Train Epoch: 53 [40960/45000 (91%)] Loss: 0.514934\n",
            "Train Epoch: 53 [41472/45000 (92%)] Loss: 0.476469\n",
            "Train Epoch: 53 [41984/45000 (93%)] Loss: 0.454932\n",
            "Train Epoch: 53 [42496/45000 (94%)] Loss: 0.349505\n",
            "Train Epoch: 53 [43008/45000 (96%)] Loss: 0.649052\n",
            "Train Epoch: 53 [43520/45000 (97%)] Loss: 0.512089\n",
            "Train Epoch: 53 [44032/45000 (98%)] Loss: 0.476813\n",
            "Train Epoch: 53 [44544/45000 (99%)] Loss: 0.745072\n",
            "    epoch          : 53\n",
            "    loss           : 0.5296813564121046\n",
            "    accuracy       : 81.98908025568181\n",
            "    val_loss       : 0.6057358350180373\n",
            "    val_accuracy   : 79.11392405063292\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch53.pth ...\n",
            "Train Epoch: 54 [0/45000 (0%)] Loss: 0.557924\n",
            "Train Epoch: 54 [512/45000 (1%)] Loss: 0.412528\n",
            "Train Epoch: 54 [1024/45000 (2%)] Loss: 0.457962\n",
            "Train Epoch: 54 [1536/45000 (3%)] Loss: 0.438183\n",
            "Train Epoch: 54 [2048/45000 (5%)] Loss: 0.388871\n",
            "Train Epoch: 54 [2560/45000 (6%)] Loss: 0.389105\n",
            "Train Epoch: 54 [3072/45000 (7%)] Loss: 0.526744\n",
            "Train Epoch: 54 [3584/45000 (8%)] Loss: 0.529248\n",
            "Train Epoch: 54 [4096/45000 (9%)] Loss: 0.528300\n",
            "Train Epoch: 54 [4608/45000 (10%)] Loss: 0.467379\n",
            "Train Epoch: 54 [5120/45000 (11%)] Loss: 0.493605\n",
            "Train Epoch: 54 [5632/45000 (13%)] Loss: 0.353609\n",
            "Train Epoch: 54 [6144/45000 (14%)] Loss: 0.397654\n",
            "Train Epoch: 54 [6656/45000 (15%)] Loss: 0.625731\n",
            "Train Epoch: 54 [7168/45000 (16%)] Loss: 0.464218\n",
            "Train Epoch: 54 [7680/45000 (17%)] Loss: 0.667762\n",
            "Train Epoch: 54 [8192/45000 (18%)] Loss: 0.558167\n",
            "Train Epoch: 54 [8704/45000 (19%)] Loss: 0.443598\n",
            "Train Epoch: 54 [9216/45000 (20%)] Loss: 0.505541\n",
            "Train Epoch: 54 [9728/45000 (22%)] Loss: 0.377475\n",
            "Train Epoch: 54 [10240/45000 (23%)] Loss: 0.592247\n",
            "Train Epoch: 54 [10752/45000 (24%)] Loss: 0.372152\n",
            "Train Epoch: 54 [11264/45000 (25%)] Loss: 0.372351\n",
            "Train Epoch: 54 [11776/45000 (26%)] Loss: 0.346589\n",
            "Train Epoch: 54 [12288/45000 (27%)] Loss: 0.566074\n",
            "Train Epoch: 54 [12800/45000 (28%)] Loss: 0.514923\n",
            "Train Epoch: 54 [13312/45000 (30%)] Loss: 0.445168\n",
            "Train Epoch: 54 [13824/45000 (31%)] Loss: 0.366180\n",
            "Train Epoch: 54 [14336/45000 (32%)] Loss: 0.484904\n",
            "Train Epoch: 54 [14848/45000 (33%)] Loss: 0.537106\n",
            "Train Epoch: 54 [15360/45000 (34%)] Loss: 0.676439\n",
            "Train Epoch: 54 [15872/45000 (35%)] Loss: 0.505879\n",
            "Train Epoch: 54 [16384/45000 (36%)] Loss: 0.462886\n",
            "Train Epoch: 54 [16896/45000 (38%)] Loss: 0.466237\n",
            "Train Epoch: 54 [17408/45000 (39%)] Loss: 0.581415\n",
            "Train Epoch: 54 [17920/45000 (40%)] Loss: 0.428856\n",
            "Train Epoch: 54 [18432/45000 (41%)] Loss: 0.644005\n",
            "Train Epoch: 54 [18944/45000 (42%)] Loss: 0.619894\n",
            "Train Epoch: 54 [19456/45000 (43%)] Loss: 0.569731\n",
            "Train Epoch: 54 [19968/45000 (44%)] Loss: 0.603893\n",
            "Train Epoch: 54 [20480/45000 (46%)] Loss: 0.527334\n",
            "Train Epoch: 54 [20992/45000 (47%)] Loss: 0.677308\n",
            "Train Epoch: 54 [21504/45000 (48%)] Loss: 0.389102\n",
            "Train Epoch: 54 [22016/45000 (49%)] Loss: 0.623128\n",
            "Train Epoch: 54 [22528/45000 (50%)] Loss: 0.517669\n",
            "Train Epoch: 54 [23040/45000 (51%)] Loss: 0.509595\n",
            "Train Epoch: 54 [23552/45000 (52%)] Loss: 0.497119\n",
            "Train Epoch: 54 [24064/45000 (53%)] Loss: 0.440989\n",
            "Train Epoch: 54 [24576/45000 (55%)] Loss: 0.533339\n",
            "Train Epoch: 54 [25088/45000 (56%)] Loss: 0.671944\n",
            "Train Epoch: 54 [25600/45000 (57%)] Loss: 0.424401\n",
            "Train Epoch: 54 [26112/45000 (58%)] Loss: 0.494751\n",
            "Train Epoch: 54 [26624/45000 (59%)] Loss: 0.416610\n",
            "Train Epoch: 54 [27136/45000 (60%)] Loss: 0.333848\n",
            "Train Epoch: 54 [27648/45000 (61%)] Loss: 0.490156\n",
            "Train Epoch: 54 [28160/45000 (63%)] Loss: 0.543242\n",
            "Train Epoch: 54 [28672/45000 (64%)] Loss: 0.572096\n",
            "Train Epoch: 54 [29184/45000 (65%)] Loss: 0.504777\n",
            "Train Epoch: 54 [29696/45000 (66%)] Loss: 0.508482\n",
            "Train Epoch: 54 [30208/45000 (67%)] Loss: 0.373001\n",
            "Train Epoch: 54 [30720/45000 (68%)] Loss: 1.033311\n",
            "Train Epoch: 54 [31232/45000 (69%)] Loss: 0.456797\n",
            "Train Epoch: 54 [31744/45000 (71%)] Loss: 0.718521\n",
            "Train Epoch: 54 [32256/45000 (72%)] Loss: 0.480510\n",
            "Train Epoch: 54 [32768/45000 (73%)] Loss: 0.440535\n",
            "Train Epoch: 54 [33280/45000 (74%)] Loss: 0.658830\n",
            "Train Epoch: 54 [33792/45000 (75%)] Loss: 0.770571\n",
            "Train Epoch: 54 [34304/45000 (76%)] Loss: 0.515317\n",
            "Train Epoch: 54 [34816/45000 (77%)] Loss: 0.404141\n",
            "Train Epoch: 54 [35328/45000 (79%)] Loss: 0.756557\n",
            "Train Epoch: 54 [35840/45000 (80%)] Loss: 0.350013\n",
            "Train Epoch: 54 [36352/45000 (81%)] Loss: 0.435784\n",
            "Train Epoch: 54 [36864/45000 (82%)] Loss: 0.726749\n",
            "Train Epoch: 54 [37376/45000 (83%)] Loss: 0.636093\n",
            "Train Epoch: 54 [37888/45000 (84%)] Loss: 0.721935\n",
            "Train Epoch: 54 [38400/45000 (85%)] Loss: 0.533145\n",
            "Train Epoch: 54 [38912/45000 (86%)] Loss: 0.539475\n",
            "Train Epoch: 54 [39424/45000 (88%)] Loss: 0.465154\n",
            "Train Epoch: 54 [39936/45000 (89%)] Loss: 0.436357\n",
            "Train Epoch: 54 [40448/45000 (90%)] Loss: 0.356517\n",
            "Train Epoch: 54 [40960/45000 (91%)] Loss: 0.531604\n",
            "Train Epoch: 54 [41472/45000 (92%)] Loss: 0.696433\n",
            "Train Epoch: 54 [41984/45000 (93%)] Loss: 0.492921\n",
            "Train Epoch: 54 [42496/45000 (94%)] Loss: 0.651794\n",
            "Train Epoch: 54 [43008/45000 (96%)] Loss: 0.653744\n",
            "Train Epoch: 54 [43520/45000 (97%)] Loss: 0.582022\n",
            "Train Epoch: 54 [44032/45000 (98%)] Loss: 0.490326\n",
            "Train Epoch: 54 [44544/45000 (99%)] Loss: 0.749646\n",
            "    epoch          : 54\n",
            "    loss           : 0.5315719917204909\n",
            "    accuracy       : 82.00461647727273\n",
            "    val_loss       : 0.6112426817417145\n",
            "    val_accuracy   : 78.85680379746836\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch54.pth ...\n",
            "Train Epoch: 55 [0/45000 (0%)] Loss: 0.675499\n",
            "Train Epoch: 55 [512/45000 (1%)] Loss: 0.431925\n",
            "Train Epoch: 55 [1024/45000 (2%)] Loss: 0.578411\n",
            "Train Epoch: 55 [1536/45000 (3%)] Loss: 0.383443\n",
            "Train Epoch: 55 [2048/45000 (5%)] Loss: 0.453267\n",
            "Train Epoch: 55 [2560/45000 (6%)] Loss: 0.480991\n",
            "Train Epoch: 55 [3072/45000 (7%)] Loss: 0.479287\n",
            "Train Epoch: 55 [3584/45000 (8%)] Loss: 0.500431\n",
            "Train Epoch: 55 [4096/45000 (9%)] Loss: 0.392267\n",
            "Train Epoch: 55 [4608/45000 (10%)] Loss: 0.460332\n",
            "Train Epoch: 55 [5120/45000 (11%)] Loss: 0.634111\n",
            "Train Epoch: 55 [5632/45000 (13%)] Loss: 0.421071\n",
            "Train Epoch: 55 [6144/45000 (14%)] Loss: 0.715629\n",
            "Train Epoch: 55 [6656/45000 (15%)] Loss: 0.494408\n",
            "Train Epoch: 55 [7168/45000 (16%)] Loss: 0.594836\n",
            "Train Epoch: 55 [7680/45000 (17%)] Loss: 0.419829\n",
            "Train Epoch: 55 [8192/45000 (18%)] Loss: 0.604596\n",
            "Train Epoch: 55 [8704/45000 (19%)] Loss: 0.741820\n",
            "Train Epoch: 55 [9216/45000 (20%)] Loss: 0.544352\n",
            "Train Epoch: 55 [9728/45000 (22%)] Loss: 0.510453\n",
            "Train Epoch: 55 [10240/45000 (23%)] Loss: 0.597980\n",
            "Train Epoch: 55 [10752/45000 (24%)] Loss: 0.780190\n",
            "Train Epoch: 55 [11264/45000 (25%)] Loss: 0.500939\n",
            "Train Epoch: 55 [11776/45000 (26%)] Loss: 0.803029\n",
            "Train Epoch: 55 [12288/45000 (27%)] Loss: 0.547707\n",
            "Train Epoch: 55 [12800/45000 (28%)] Loss: 0.400304\n",
            "Train Epoch: 55 [13312/45000 (30%)] Loss: 0.307852\n",
            "Train Epoch: 55 [13824/45000 (31%)] Loss: 0.486355\n",
            "Train Epoch: 55 [14336/45000 (32%)] Loss: 0.584238\n",
            "Train Epoch: 55 [14848/45000 (33%)] Loss: 0.427335\n",
            "Train Epoch: 55 [15360/45000 (34%)] Loss: 0.553353\n",
            "Train Epoch: 55 [15872/45000 (35%)] Loss: 0.354576\n",
            "Train Epoch: 55 [16384/45000 (36%)] Loss: 0.346583\n",
            "Train Epoch: 55 [16896/45000 (38%)] Loss: 0.348563\n",
            "Train Epoch: 55 [17408/45000 (39%)] Loss: 0.347220\n",
            "Train Epoch: 55 [17920/45000 (40%)] Loss: 0.489701\n",
            "Train Epoch: 55 [18432/45000 (41%)] Loss: 0.716191\n",
            "Train Epoch: 55 [18944/45000 (42%)] Loss: 0.574927\n",
            "Train Epoch: 55 [19456/45000 (43%)] Loss: 0.513817\n",
            "Train Epoch: 55 [19968/45000 (44%)] Loss: 0.510516\n",
            "Train Epoch: 55 [20480/45000 (46%)] Loss: 0.611889\n",
            "Train Epoch: 55 [20992/45000 (47%)] Loss: 0.353595\n",
            "Train Epoch: 55 [21504/45000 (48%)] Loss: 0.432414\n",
            "Train Epoch: 55 [22016/45000 (49%)] Loss: 0.737572\n",
            "Train Epoch: 55 [22528/45000 (50%)] Loss: 0.866100\n",
            "Train Epoch: 55 [23040/45000 (51%)] Loss: 0.426028\n",
            "Train Epoch: 55 [23552/45000 (52%)] Loss: 0.626129\n",
            "Train Epoch: 55 [24064/45000 (53%)] Loss: 0.546438\n",
            "Train Epoch: 55 [24576/45000 (55%)] Loss: 0.318977\n",
            "Train Epoch: 55 [25088/45000 (56%)] Loss: 0.516154\n",
            "Train Epoch: 55 [25600/45000 (57%)] Loss: 0.477641\n",
            "Train Epoch: 55 [26112/45000 (58%)] Loss: 0.606129\n",
            "Train Epoch: 55 [26624/45000 (59%)] Loss: 0.646500\n",
            "Train Epoch: 55 [27136/45000 (60%)] Loss: 0.557241\n",
            "Train Epoch: 55 [27648/45000 (61%)] Loss: 0.534701\n",
            "Train Epoch: 55 [28160/45000 (63%)] Loss: 0.715970\n",
            "Train Epoch: 55 [28672/45000 (64%)] Loss: 0.448089\n",
            "Train Epoch: 55 [29184/45000 (65%)] Loss: 0.654006\n",
            "Train Epoch: 55 [29696/45000 (66%)] Loss: 0.528796\n",
            "Train Epoch: 55 [30208/45000 (67%)] Loss: 0.473359\n",
            "Train Epoch: 55 [30720/45000 (68%)] Loss: 0.548683\n",
            "Train Epoch: 55 [31232/45000 (69%)] Loss: 0.645718\n",
            "Train Epoch: 55 [31744/45000 (71%)] Loss: 0.548552\n",
            "Train Epoch: 55 [32256/45000 (72%)] Loss: 0.391158\n",
            "Train Epoch: 55 [32768/45000 (73%)] Loss: 0.464632\n",
            "Train Epoch: 55 [33280/45000 (74%)] Loss: 0.494285\n",
            "Train Epoch: 55 [33792/45000 (75%)] Loss: 0.482770\n",
            "Train Epoch: 55 [34304/45000 (76%)] Loss: 0.821685\n",
            "Train Epoch: 55 [34816/45000 (77%)] Loss: 0.514510\n",
            "Train Epoch: 55 [35328/45000 (79%)] Loss: 0.351470\n",
            "Train Epoch: 55 [35840/45000 (80%)] Loss: 0.429478\n",
            "Train Epoch: 55 [36352/45000 (81%)] Loss: 0.517588\n",
            "Train Epoch: 55 [36864/45000 (82%)] Loss: 0.651761\n",
            "Train Epoch: 55 [37376/45000 (83%)] Loss: 0.377550\n",
            "Train Epoch: 55 [37888/45000 (84%)] Loss: 0.478713\n",
            "Train Epoch: 55 [38400/45000 (85%)] Loss: 0.594676\n",
            "Train Epoch: 55 [38912/45000 (86%)] Loss: 0.700400\n",
            "Train Epoch: 55 [39424/45000 (88%)] Loss: 0.352133\n",
            "Train Epoch: 55 [39936/45000 (89%)] Loss: 0.582590\n",
            "Train Epoch: 55 [40448/45000 (90%)] Loss: 0.505287\n",
            "Train Epoch: 55 [40960/45000 (91%)] Loss: 0.603641\n",
            "Train Epoch: 55 [41472/45000 (92%)] Loss: 0.542314\n",
            "Train Epoch: 55 [41984/45000 (93%)] Loss: 0.467542\n",
            "Train Epoch: 55 [42496/45000 (94%)] Loss: 0.463819\n",
            "Train Epoch: 55 [43008/45000 (96%)] Loss: 0.636914\n",
            "Train Epoch: 55 [43520/45000 (97%)] Loss: 0.773017\n",
            "Train Epoch: 55 [44032/45000 (98%)] Loss: 0.534469\n",
            "Train Epoch: 55 [44544/45000 (99%)] Loss: 0.464498\n",
            "    epoch          : 55\n",
            "    loss           : 0.530678944344717\n",
            "    accuracy       : 81.7959872159091\n",
            "    val_loss       : 0.6065454852731922\n",
            "    val_accuracy   : 79.39082278481013\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch55.pth ...\n",
            "Train Epoch: 56 [0/45000 (0%)] Loss: 0.484649\n",
            "Train Epoch: 56 [512/45000 (1%)] Loss: 0.732600\n",
            "Train Epoch: 56 [1024/45000 (2%)] Loss: 0.496506\n",
            "Train Epoch: 56 [1536/45000 (3%)] Loss: 0.620874\n",
            "Train Epoch: 56 [2048/45000 (5%)] Loss: 0.423414\n",
            "Train Epoch: 56 [2560/45000 (6%)] Loss: 0.534691\n",
            "Train Epoch: 56 [3072/45000 (7%)] Loss: 0.421865\n",
            "Train Epoch: 56 [3584/45000 (8%)] Loss: 0.483270\n",
            "Train Epoch: 56 [4096/45000 (9%)] Loss: 0.561748\n",
            "Train Epoch: 56 [4608/45000 (10%)] Loss: 0.473295\n",
            "Train Epoch: 56 [5120/45000 (11%)] Loss: 0.501519\n",
            "Train Epoch: 56 [5632/45000 (13%)] Loss: 0.397806\n",
            "Train Epoch: 56 [6144/45000 (14%)] Loss: 0.605417\n",
            "Train Epoch: 56 [6656/45000 (15%)] Loss: 0.510692\n",
            "Train Epoch: 56 [7168/45000 (16%)] Loss: 0.607746\n",
            "Train Epoch: 56 [7680/45000 (17%)] Loss: 0.507312\n",
            "Train Epoch: 56 [8192/45000 (18%)] Loss: 0.478085\n",
            "Train Epoch: 56 [8704/45000 (19%)] Loss: 0.604225\n",
            "Train Epoch: 56 [9216/45000 (20%)] Loss: 0.616778\n",
            "Train Epoch: 56 [9728/45000 (22%)] Loss: 0.449534\n",
            "Train Epoch: 56 [10240/45000 (23%)] Loss: 0.580502\n",
            "Train Epoch: 56 [10752/45000 (24%)] Loss: 0.437446\n",
            "Train Epoch: 56 [11264/45000 (25%)] Loss: 0.543278\n",
            "Train Epoch: 56 [11776/45000 (26%)] Loss: 0.326168\n",
            "Train Epoch: 56 [12288/45000 (27%)] Loss: 0.587111\n",
            "Train Epoch: 56 [12800/45000 (28%)] Loss: 0.700107\n",
            "Train Epoch: 56 [13312/45000 (30%)] Loss: 0.441411\n",
            "Train Epoch: 56 [13824/45000 (31%)] Loss: 0.492429\n",
            "Train Epoch: 56 [14336/45000 (32%)] Loss: 0.560010\n",
            "Train Epoch: 56 [14848/45000 (33%)] Loss: 0.643165\n",
            "Train Epoch: 56 [15360/45000 (34%)] Loss: 0.414133\n",
            "Train Epoch: 56 [15872/45000 (35%)] Loss: 0.503363\n",
            "Train Epoch: 56 [16384/45000 (36%)] Loss: 0.390713\n",
            "Train Epoch: 56 [16896/45000 (38%)] Loss: 0.367161\n",
            "Train Epoch: 56 [17408/45000 (39%)] Loss: 0.316850\n",
            "Train Epoch: 56 [17920/45000 (40%)] Loss: 0.550389\n",
            "Train Epoch: 56 [18432/45000 (41%)] Loss: 0.449780\n",
            "Train Epoch: 56 [18944/45000 (42%)] Loss: 0.519881\n",
            "Train Epoch: 56 [19456/45000 (43%)] Loss: 0.414848\n",
            "Train Epoch: 56 [19968/45000 (44%)] Loss: 0.475164\n",
            "Train Epoch: 56 [20480/45000 (46%)] Loss: 0.640182\n",
            "Train Epoch: 56 [20992/45000 (47%)] Loss: 0.470607\n",
            "Train Epoch: 56 [21504/45000 (48%)] Loss: 0.583965\n",
            "Train Epoch: 56 [22016/45000 (49%)] Loss: 0.383186\n",
            "Train Epoch: 56 [22528/45000 (50%)] Loss: 0.562365\n",
            "Train Epoch: 56 [23040/45000 (51%)] Loss: 0.361980\n",
            "Train Epoch: 56 [23552/45000 (52%)] Loss: 0.491656\n",
            "Train Epoch: 56 [24064/45000 (53%)] Loss: 0.497175\n",
            "Train Epoch: 56 [24576/45000 (55%)] Loss: 0.482388\n",
            "Train Epoch: 56 [25088/45000 (56%)] Loss: 0.757930\n",
            "Train Epoch: 56 [25600/45000 (57%)] Loss: 0.379822\n",
            "Train Epoch: 56 [26112/45000 (58%)] Loss: 0.632871\n",
            "Train Epoch: 56 [26624/45000 (59%)] Loss: 0.531640\n",
            "Train Epoch: 56 [27136/45000 (60%)] Loss: 0.468287\n",
            "Train Epoch: 56 [27648/45000 (61%)] Loss: 0.406258\n",
            "Train Epoch: 56 [28160/45000 (63%)] Loss: 0.594082\n",
            "Train Epoch: 56 [28672/45000 (64%)] Loss: 0.499948\n",
            "Train Epoch: 56 [29184/45000 (65%)] Loss: 0.528459\n",
            "Train Epoch: 56 [29696/45000 (66%)] Loss: 0.399271\n",
            "Train Epoch: 56 [30208/45000 (67%)] Loss: 0.557490\n",
            "Train Epoch: 56 [30720/45000 (68%)] Loss: 0.556646\n",
            "Train Epoch: 56 [31232/45000 (69%)] Loss: 0.674610\n",
            "Train Epoch: 56 [31744/45000 (71%)] Loss: 0.511790\n",
            "Train Epoch: 56 [32256/45000 (72%)] Loss: 0.312109\n",
            "Train Epoch: 56 [32768/45000 (73%)] Loss: 0.549162\n",
            "Train Epoch: 56 [33280/45000 (74%)] Loss: 0.536716\n",
            "Train Epoch: 56 [33792/45000 (75%)] Loss: 0.423247\n",
            "Train Epoch: 56 [34304/45000 (76%)] Loss: 0.494085\n",
            "Train Epoch: 56 [34816/45000 (77%)] Loss: 0.770525\n",
            "Train Epoch: 56 [35328/45000 (79%)] Loss: 0.534023\n",
            "Train Epoch: 56 [35840/45000 (80%)] Loss: 0.429337\n",
            "Train Epoch: 56 [36352/45000 (81%)] Loss: 0.538814\n",
            "Train Epoch: 56 [36864/45000 (82%)] Loss: 0.502896\n",
            "Train Epoch: 56 [37376/45000 (83%)] Loss: 0.495188\n",
            "Train Epoch: 56 [37888/45000 (84%)] Loss: 0.524158\n",
            "Train Epoch: 56 [38400/45000 (85%)] Loss: 0.432582\n",
            "Train Epoch: 56 [38912/45000 (86%)] Loss: 0.553458\n",
            "Train Epoch: 56 [39424/45000 (88%)] Loss: 0.586245\n",
            "Train Epoch: 56 [39936/45000 (89%)] Loss: 0.502496\n",
            "Train Epoch: 56 [40448/45000 (90%)] Loss: 0.597901\n",
            "Train Epoch: 56 [40960/45000 (91%)] Loss: 0.687654\n",
            "Train Epoch: 56 [41472/45000 (92%)] Loss: 0.604858\n",
            "Train Epoch: 56 [41984/45000 (93%)] Loss: 0.504582\n",
            "Train Epoch: 56 [42496/45000 (94%)] Loss: 0.397270\n",
            "Train Epoch: 56 [43008/45000 (96%)] Loss: 0.521272\n",
            "Train Epoch: 56 [43520/45000 (97%)] Loss: 0.348644\n",
            "Train Epoch: 56 [44032/45000 (98%)] Loss: 0.673846\n",
            "Train Epoch: 56 [44544/45000 (99%)] Loss: 0.542461\n",
            "    epoch          : 56\n",
            "    loss           : 0.5259568078274076\n",
            "    accuracy       : 81.92027698863636\n",
            "    val_loss       : 0.6063716815242285\n",
            "    val_accuracy   : 79.05458860759494\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch56.pth ...\n",
            "Train Epoch: 57 [0/45000 (0%)] Loss: 0.712086\n",
            "Train Epoch: 57 [512/45000 (1%)] Loss: 0.474317\n",
            "Train Epoch: 57 [1024/45000 (2%)] Loss: 0.793605\n",
            "Train Epoch: 57 [1536/45000 (3%)] Loss: 0.581177\n",
            "Train Epoch: 57 [2048/45000 (5%)] Loss: 0.543739\n",
            "Train Epoch: 57 [2560/45000 (6%)] Loss: 0.724405\n",
            "Train Epoch: 57 [3072/45000 (7%)] Loss: 0.765807\n",
            "Train Epoch: 57 [3584/45000 (8%)] Loss: 0.394272\n",
            "Train Epoch: 57 [4096/45000 (9%)] Loss: 0.533704\n",
            "Train Epoch: 57 [4608/45000 (10%)] Loss: 0.614183\n",
            "Train Epoch: 57 [5120/45000 (11%)] Loss: 0.467217\n",
            "Train Epoch: 57 [5632/45000 (13%)] Loss: 0.516879\n",
            "Train Epoch: 57 [6144/45000 (14%)] Loss: 0.553900\n",
            "Train Epoch: 57 [6656/45000 (15%)] Loss: 0.567971\n",
            "Train Epoch: 57 [7168/45000 (16%)] Loss: 0.516959\n",
            "Train Epoch: 57 [7680/45000 (17%)] Loss: 0.631655\n",
            "Train Epoch: 57 [8192/45000 (18%)] Loss: 0.470635\n",
            "Train Epoch: 57 [8704/45000 (19%)] Loss: 0.611380\n",
            "Train Epoch: 57 [9216/45000 (20%)] Loss: 0.698313\n",
            "Train Epoch: 57 [9728/45000 (22%)] Loss: 0.563579\n",
            "Train Epoch: 57 [10240/45000 (23%)] Loss: 0.516882\n",
            "Train Epoch: 57 [10752/45000 (24%)] Loss: 0.528987\n",
            "Train Epoch: 57 [11264/45000 (25%)] Loss: 0.644874\n",
            "Train Epoch: 57 [11776/45000 (26%)] Loss: 0.474676\n",
            "Train Epoch: 57 [12288/45000 (27%)] Loss: 0.500981\n",
            "Train Epoch: 57 [12800/45000 (28%)] Loss: 0.570010\n",
            "Train Epoch: 57 [13312/45000 (30%)] Loss: 0.623706\n",
            "Train Epoch: 57 [13824/45000 (31%)] Loss: 0.627341\n",
            "Train Epoch: 57 [14336/45000 (32%)] Loss: 0.495309\n",
            "Train Epoch: 57 [14848/45000 (33%)] Loss: 0.363458\n",
            "Train Epoch: 57 [15360/45000 (34%)] Loss: 0.417484\n",
            "Train Epoch: 57 [15872/45000 (35%)] Loss: 0.566471\n",
            "Train Epoch: 57 [16384/45000 (36%)] Loss: 0.639762\n",
            "Train Epoch: 57 [16896/45000 (38%)] Loss: 0.442428\n",
            "Train Epoch: 57 [17408/45000 (39%)] Loss: 0.442051\n",
            "Train Epoch: 57 [17920/45000 (40%)] Loss: 0.477910\n",
            "Train Epoch: 57 [18432/45000 (41%)] Loss: 0.348963\n",
            "Train Epoch: 57 [18944/45000 (42%)] Loss: 0.343478\n",
            "Train Epoch: 57 [19456/45000 (43%)] Loss: 0.414239\n",
            "Train Epoch: 57 [19968/45000 (44%)] Loss: 0.627377\n",
            "Train Epoch: 57 [20480/45000 (46%)] Loss: 0.553928\n",
            "Train Epoch: 57 [20992/45000 (47%)] Loss: 0.439098\n",
            "Train Epoch: 57 [21504/45000 (48%)] Loss: 0.730994\n",
            "Train Epoch: 57 [22016/45000 (49%)] Loss: 0.361859\n",
            "Train Epoch: 57 [22528/45000 (50%)] Loss: 0.428052\n",
            "Train Epoch: 57 [23040/45000 (51%)] Loss: 0.568825\n",
            "Train Epoch: 57 [23552/45000 (52%)] Loss: 0.397825\n",
            "Train Epoch: 57 [24064/45000 (53%)] Loss: 0.446893\n",
            "Train Epoch: 57 [24576/45000 (55%)] Loss: 0.555277\n",
            "Train Epoch: 57 [25088/45000 (56%)] Loss: 0.439503\n",
            "Train Epoch: 57 [25600/45000 (57%)] Loss: 0.616285\n",
            "Train Epoch: 57 [26112/45000 (58%)] Loss: 0.439472\n",
            "Train Epoch: 57 [26624/45000 (59%)] Loss: 0.461450\n",
            "Train Epoch: 57 [27136/45000 (60%)] Loss: 0.690403\n",
            "Train Epoch: 57 [27648/45000 (61%)] Loss: 0.504589\n",
            "Train Epoch: 57 [28160/45000 (63%)] Loss: 0.554077\n",
            "Train Epoch: 57 [28672/45000 (64%)] Loss: 0.535268\n",
            "Train Epoch: 57 [29184/45000 (65%)] Loss: 0.309002\n",
            "Train Epoch: 57 [29696/45000 (66%)] Loss: 0.635895\n",
            "Train Epoch: 57 [30208/45000 (67%)] Loss: 0.537790\n",
            "Train Epoch: 57 [30720/45000 (68%)] Loss: 0.474314\n",
            "Train Epoch: 57 [31232/45000 (69%)] Loss: 0.389215\n",
            "Train Epoch: 57 [31744/45000 (71%)] Loss: 0.519043\n",
            "Train Epoch: 57 [32256/45000 (72%)] Loss: 0.548401\n",
            "Train Epoch: 57 [32768/45000 (73%)] Loss: 0.400580\n",
            "Train Epoch: 57 [33280/45000 (74%)] Loss: 0.620177\n",
            "Train Epoch: 57 [33792/45000 (75%)] Loss: 0.468889\n",
            "Train Epoch: 57 [34304/45000 (76%)] Loss: 0.545407\n",
            "Train Epoch: 57 [34816/45000 (77%)] Loss: 0.426365\n",
            "Train Epoch: 57 [35328/45000 (79%)] Loss: 0.567543\n",
            "Train Epoch: 57 [35840/45000 (80%)] Loss: 0.751866\n",
            "Train Epoch: 57 [36352/45000 (81%)] Loss: 0.438770\n",
            "Train Epoch: 57 [36864/45000 (82%)] Loss: 0.593888\n",
            "Train Epoch: 57 [37376/45000 (83%)] Loss: 0.542248\n",
            "Train Epoch: 57 [37888/45000 (84%)] Loss: 0.416768\n",
            "Train Epoch: 57 [38400/45000 (85%)] Loss: 0.523395\n",
            "Train Epoch: 57 [38912/45000 (86%)] Loss: 0.457047\n",
            "Train Epoch: 57 [39424/45000 (88%)] Loss: 0.465714\n",
            "Train Epoch: 57 [39936/45000 (89%)] Loss: 0.647292\n",
            "Train Epoch: 57 [40448/45000 (90%)] Loss: 0.462833\n",
            "Train Epoch: 57 [40960/45000 (91%)] Loss: 0.569855\n",
            "Train Epoch: 57 [41472/45000 (92%)] Loss: 0.433077\n",
            "Train Epoch: 57 [41984/45000 (93%)] Loss: 0.444434\n",
            "Train Epoch: 57 [42496/45000 (94%)] Loss: 0.440071\n",
            "Train Epoch: 57 [43008/45000 (96%)] Loss: 0.521789\n",
            "Train Epoch: 57 [43520/45000 (97%)] Loss: 0.440163\n",
            "Train Epoch: 57 [44032/45000 (98%)] Loss: 0.477649\n",
            "Train Epoch: 57 [44544/45000 (99%)] Loss: 0.569229\n",
            "    epoch          : 57\n",
            "    loss           : 0.5274174127897079\n",
            "    accuracy       : 81.88698508522727\n",
            "    val_loss       : 0.6214188009123259\n",
            "    val_accuracy   : 79.27215189873418\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch57.pth ...\n",
            "Train Epoch: 58 [0/45000 (0%)] Loss: 0.495336\n",
            "Train Epoch: 58 [512/45000 (1%)] Loss: 0.516305\n",
            "Train Epoch: 58 [1024/45000 (2%)] Loss: 0.656367\n",
            "Train Epoch: 58 [1536/45000 (3%)] Loss: 0.436730\n",
            "Train Epoch: 58 [2048/45000 (5%)] Loss: 0.414516\n",
            "Train Epoch: 58 [2560/45000 (6%)] Loss: 0.404931\n",
            "Train Epoch: 58 [3072/45000 (7%)] Loss: 0.702581\n",
            "Train Epoch: 58 [3584/45000 (8%)] Loss: 0.689924\n",
            "Train Epoch: 58 [4096/45000 (9%)] Loss: 0.415745\n",
            "Train Epoch: 58 [4608/45000 (10%)] Loss: 0.696256\n",
            "Train Epoch: 58 [5120/45000 (11%)] Loss: 0.392256\n",
            "Train Epoch: 58 [5632/45000 (13%)] Loss: 0.658073\n",
            "Train Epoch: 58 [6144/45000 (14%)] Loss: 0.747539\n",
            "Train Epoch: 58 [6656/45000 (15%)] Loss: 0.428529\n",
            "Train Epoch: 58 [7168/45000 (16%)] Loss: 0.649222\n",
            "Train Epoch: 58 [7680/45000 (17%)] Loss: 0.479335\n",
            "Train Epoch: 58 [8192/45000 (18%)] Loss: 0.321978\n",
            "Train Epoch: 58 [8704/45000 (19%)] Loss: 0.452825\n",
            "Train Epoch: 58 [9216/45000 (20%)] Loss: 0.543433\n",
            "Train Epoch: 58 [9728/45000 (22%)] Loss: 0.464608\n",
            "Train Epoch: 58 [10240/45000 (23%)] Loss: 0.550452\n",
            "Train Epoch: 58 [10752/45000 (24%)] Loss: 0.544802\n",
            "Train Epoch: 58 [11264/45000 (25%)] Loss: 0.466196\n",
            "Train Epoch: 58 [11776/45000 (26%)] Loss: 0.435036\n",
            "Train Epoch: 58 [12288/45000 (27%)] Loss: 0.419329\n",
            "Train Epoch: 58 [12800/45000 (28%)] Loss: 0.428268\n",
            "Train Epoch: 58 [13312/45000 (30%)] Loss: 0.503033\n",
            "Train Epoch: 58 [13824/45000 (31%)] Loss: 0.605275\n",
            "Train Epoch: 58 [14336/45000 (32%)] Loss: 0.440702\n",
            "Train Epoch: 58 [14848/45000 (33%)] Loss: 0.445439\n",
            "Train Epoch: 58 [15360/45000 (34%)] Loss: 0.458550\n",
            "Train Epoch: 58 [15872/45000 (35%)] Loss: 0.606081\n",
            "Train Epoch: 58 [16384/45000 (36%)] Loss: 0.440433\n",
            "Train Epoch: 58 [16896/45000 (38%)] Loss: 0.589116\n",
            "Train Epoch: 58 [17408/45000 (39%)] Loss: 0.444748\n",
            "Train Epoch: 58 [17920/45000 (40%)] Loss: 0.580661\n",
            "Train Epoch: 58 [18432/45000 (41%)] Loss: 0.342235\n",
            "Train Epoch: 58 [18944/45000 (42%)] Loss: 0.516053\n",
            "Train Epoch: 58 [19456/45000 (43%)] Loss: 0.375456\n",
            "Train Epoch: 58 [19968/45000 (44%)] Loss: 0.440830\n",
            "Train Epoch: 58 [20480/45000 (46%)] Loss: 0.580674\n",
            "Train Epoch: 58 [20992/45000 (47%)] Loss: 0.693837\n",
            "Train Epoch: 58 [21504/45000 (48%)] Loss: 0.749694\n",
            "Train Epoch: 58 [22016/45000 (49%)] Loss: 0.535372\n",
            "Train Epoch: 58 [22528/45000 (50%)] Loss: 0.538846\n",
            "Train Epoch: 58 [23040/45000 (51%)] Loss: 0.577072\n",
            "Train Epoch: 58 [23552/45000 (52%)] Loss: 0.454200\n",
            "Train Epoch: 58 [24064/45000 (53%)] Loss: 0.472262\n",
            "Train Epoch: 58 [24576/45000 (55%)] Loss: 0.367411\n",
            "Train Epoch: 58 [25088/45000 (56%)] Loss: 0.524325\n",
            "Train Epoch: 58 [25600/45000 (57%)] Loss: 0.348705\n",
            "Train Epoch: 58 [26112/45000 (58%)] Loss: 0.610407\n",
            "Train Epoch: 58 [26624/45000 (59%)] Loss: 0.495033\n",
            "Train Epoch: 58 [27136/45000 (60%)] Loss: 0.427949\n",
            "Train Epoch: 58 [27648/45000 (61%)] Loss: 0.656887\n",
            "Train Epoch: 58 [28160/45000 (63%)] Loss: 0.561906\n",
            "Train Epoch: 58 [28672/45000 (64%)] Loss: 0.350580\n",
            "Train Epoch: 58 [29184/45000 (65%)] Loss: 0.625784\n",
            "Train Epoch: 58 [29696/45000 (66%)] Loss: 0.599119\n",
            "Train Epoch: 58 [30208/45000 (67%)] Loss: 0.497671\n",
            "Train Epoch: 58 [30720/45000 (68%)] Loss: 0.481472\n",
            "Train Epoch: 58 [31232/45000 (69%)] Loss: 0.596262\n",
            "Train Epoch: 58 [31744/45000 (71%)] Loss: 0.448319\n",
            "Train Epoch: 58 [32256/45000 (72%)] Loss: 0.801451\n",
            "Train Epoch: 58 [32768/45000 (73%)] Loss: 0.517515\n",
            "Train Epoch: 58 [33280/45000 (74%)] Loss: 0.494931\n",
            "Train Epoch: 58 [33792/45000 (75%)] Loss: 0.406081\n",
            "Train Epoch: 58 [34304/45000 (76%)] Loss: 0.300875\n",
            "Train Epoch: 58 [34816/45000 (77%)] Loss: 0.473348\n",
            "Train Epoch: 58 [35328/45000 (79%)] Loss: 0.424241\n",
            "Train Epoch: 58 [35840/45000 (80%)] Loss: 0.346260\n",
            "Train Epoch: 58 [36352/45000 (81%)] Loss: 0.342341\n",
            "Train Epoch: 58 [36864/45000 (82%)] Loss: 0.481090\n",
            "Train Epoch: 58 [37376/45000 (83%)] Loss: 0.471003\n",
            "Train Epoch: 58 [37888/45000 (84%)] Loss: 0.649804\n",
            "Train Epoch: 58 [38400/45000 (85%)] Loss: 0.422209\n",
            "Train Epoch: 58 [38912/45000 (86%)] Loss: 0.541524\n",
            "Train Epoch: 58 [39424/45000 (88%)] Loss: 0.581452\n",
            "Train Epoch: 58 [39936/45000 (89%)] Loss: 0.441828\n",
            "Train Epoch: 58 [40448/45000 (90%)] Loss: 0.581002\n",
            "Train Epoch: 58 [40960/45000 (91%)] Loss: 0.279270\n",
            "Train Epoch: 58 [41472/45000 (92%)] Loss: 0.572957\n",
            "Train Epoch: 58 [41984/45000 (93%)] Loss: 0.405681\n",
            "Train Epoch: 58 [42496/45000 (94%)] Loss: 0.607001\n",
            "Train Epoch: 58 [43008/45000 (96%)] Loss: 0.456765\n",
            "Train Epoch: 58 [43520/45000 (97%)] Loss: 0.513385\n",
            "Train Epoch: 58 [44032/45000 (98%)] Loss: 0.680716\n",
            "Train Epoch: 58 [44544/45000 (99%)] Loss: 0.540037\n",
            "    epoch          : 58\n",
            "    loss           : 0.5313019631430507\n",
            "    accuracy       : 81.93359375\n",
            "    val_loss       : 0.5935726780680162\n",
            "    val_accuracy   : 79.60838607594937\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch58.pth ...\n",
            "Train Epoch: 59 [0/45000 (0%)] Loss: 0.420338\n",
            "Train Epoch: 59 [512/45000 (1%)] Loss: 0.318173\n",
            "Train Epoch: 59 [1024/45000 (2%)] Loss: 0.252461\n",
            "Train Epoch: 59 [1536/45000 (3%)] Loss: 0.349432\n",
            "Train Epoch: 59 [2048/45000 (5%)] Loss: 0.469624\n",
            "Train Epoch: 59 [2560/45000 (6%)] Loss: 0.568781\n",
            "Train Epoch: 59 [3072/45000 (7%)] Loss: 0.400572\n",
            "Train Epoch: 59 [3584/45000 (8%)] Loss: 0.558604\n",
            "Train Epoch: 59 [4096/45000 (9%)] Loss: 0.530185\n",
            "Train Epoch: 59 [4608/45000 (10%)] Loss: 0.462698\n",
            "Train Epoch: 59 [5120/45000 (11%)] Loss: 0.452502\n",
            "Train Epoch: 59 [5632/45000 (13%)] Loss: 0.638115\n",
            "Train Epoch: 59 [6144/45000 (14%)] Loss: 0.654099\n",
            "Train Epoch: 59 [6656/45000 (15%)] Loss: 0.521662\n",
            "Train Epoch: 59 [7168/45000 (16%)] Loss: 0.604743\n",
            "Train Epoch: 59 [7680/45000 (17%)] Loss: 0.451262\n",
            "Train Epoch: 59 [8192/45000 (18%)] Loss: 0.520683\n",
            "Train Epoch: 59 [8704/45000 (19%)] Loss: 0.604566\n",
            "Train Epoch: 59 [9216/45000 (20%)] Loss: 0.566193\n",
            "Train Epoch: 59 [9728/45000 (22%)] Loss: 0.524651\n",
            "Train Epoch: 59 [10240/45000 (23%)] Loss: 0.630894\n",
            "Train Epoch: 59 [10752/45000 (24%)] Loss: 0.525413\n",
            "Train Epoch: 59 [11264/45000 (25%)] Loss: 0.389180\n",
            "Train Epoch: 59 [11776/45000 (26%)] Loss: 0.577325\n",
            "Train Epoch: 59 [12288/45000 (27%)] Loss: 0.500055\n",
            "Train Epoch: 59 [12800/45000 (28%)] Loss: 0.604830\n",
            "Train Epoch: 59 [13312/45000 (30%)] Loss: 0.401192\n",
            "Train Epoch: 59 [13824/45000 (31%)] Loss: 0.574422\n",
            "Train Epoch: 59 [14336/45000 (32%)] Loss: 0.530842\n",
            "Train Epoch: 59 [14848/45000 (33%)] Loss: 0.581906\n",
            "Train Epoch: 59 [15360/45000 (34%)] Loss: 0.463598\n",
            "Train Epoch: 59 [15872/45000 (35%)] Loss: 0.402742\n",
            "Train Epoch: 59 [16384/45000 (36%)] Loss: 0.482026\n",
            "Train Epoch: 59 [16896/45000 (38%)] Loss: 0.455829\n",
            "Train Epoch: 59 [17408/45000 (39%)] Loss: 0.751683\n",
            "Train Epoch: 59 [17920/45000 (40%)] Loss: 0.495456\n",
            "Train Epoch: 59 [18432/45000 (41%)] Loss: 0.478131\n",
            "Train Epoch: 59 [18944/45000 (42%)] Loss: 0.506498\n",
            "Train Epoch: 59 [19456/45000 (43%)] Loss: 0.798720\n",
            "Train Epoch: 59 [19968/45000 (44%)] Loss: 0.580885\n",
            "Train Epoch: 59 [20480/45000 (46%)] Loss: 0.697666\n",
            "Train Epoch: 59 [20992/45000 (47%)] Loss: 0.682472\n",
            "Train Epoch: 59 [21504/45000 (48%)] Loss: 0.603306\n",
            "Train Epoch: 59 [22016/45000 (49%)] Loss: 0.667324\n",
            "Train Epoch: 59 [22528/45000 (50%)] Loss: 0.436031\n",
            "Train Epoch: 59 [23040/45000 (51%)] Loss: 0.647646\n",
            "Train Epoch: 59 [23552/45000 (52%)] Loss: 0.794024\n",
            "Train Epoch: 59 [24064/45000 (53%)] Loss: 0.644963\n",
            "Train Epoch: 59 [24576/45000 (55%)] Loss: 0.564258\n",
            "Train Epoch: 59 [25088/45000 (56%)] Loss: 0.607378\n",
            "Train Epoch: 59 [25600/45000 (57%)] Loss: 0.522008\n",
            "Train Epoch: 59 [26112/45000 (58%)] Loss: 0.488916\n",
            "Train Epoch: 59 [26624/45000 (59%)] Loss: 0.560652\n",
            "Train Epoch: 59 [27136/45000 (60%)] Loss: 0.444818\n",
            "Train Epoch: 59 [27648/45000 (61%)] Loss: 0.513874\n",
            "Train Epoch: 59 [28160/45000 (63%)] Loss: 0.593025\n",
            "Train Epoch: 59 [28672/45000 (64%)] Loss: 0.467156\n",
            "Train Epoch: 59 [29184/45000 (65%)] Loss: 0.577995\n",
            "Train Epoch: 59 [29696/45000 (66%)] Loss: 0.264271\n",
            "Train Epoch: 59 [30208/45000 (67%)] Loss: 0.571844\n",
            "Train Epoch: 59 [30720/45000 (68%)] Loss: 0.556018\n",
            "Train Epoch: 59 [31232/45000 (69%)] Loss: 0.454528\n",
            "Train Epoch: 59 [31744/45000 (71%)] Loss: 0.456486\n",
            "Train Epoch: 59 [32256/45000 (72%)] Loss: 0.585155\n",
            "Train Epoch: 59 [32768/45000 (73%)] Loss: 0.578224\n",
            "Train Epoch: 59 [33280/45000 (74%)] Loss: 0.407523\n",
            "Train Epoch: 59 [33792/45000 (75%)] Loss: 0.508317\n",
            "Train Epoch: 59 [34304/45000 (76%)] Loss: 0.643267\n",
            "Train Epoch: 59 [34816/45000 (77%)] Loss: 0.532687\n",
            "Train Epoch: 59 [35328/45000 (79%)] Loss: 0.655202\n",
            "Train Epoch: 59 [35840/45000 (80%)] Loss: 0.332137\n",
            "Train Epoch: 59 [36352/45000 (81%)] Loss: 0.379190\n",
            "Train Epoch: 59 [36864/45000 (82%)] Loss: 0.594820\n",
            "Train Epoch: 59 [37376/45000 (83%)] Loss: 0.432356\n",
            "Train Epoch: 59 [37888/45000 (84%)] Loss: 0.514862\n",
            "Train Epoch: 59 [38400/45000 (85%)] Loss: 0.473297\n",
            "Train Epoch: 59 [38912/45000 (86%)] Loss: 0.575267\n",
            "Train Epoch: 59 [39424/45000 (88%)] Loss: 0.484121\n",
            "Train Epoch: 59 [39936/45000 (89%)] Loss: 0.710727\n",
            "Train Epoch: 59 [40448/45000 (90%)] Loss: 0.495922\n",
            "Train Epoch: 59 [40960/45000 (91%)] Loss: 0.411965\n",
            "Train Epoch: 59 [41472/45000 (92%)] Loss: 0.469634\n",
            "Train Epoch: 59 [41984/45000 (93%)] Loss: 0.682852\n",
            "Train Epoch: 59 [42496/45000 (94%)] Loss: 0.783516\n",
            "Train Epoch: 59 [43008/45000 (96%)] Loss: 0.556428\n",
            "Train Epoch: 59 [43520/45000 (97%)] Loss: 0.555932\n",
            "Train Epoch: 59 [44032/45000 (98%)] Loss: 0.514080\n",
            "Train Epoch: 59 [44544/45000 (99%)] Loss: 0.526017\n",
            "    epoch          : 59\n",
            "    loss           : 0.5314909408757971\n",
            "    accuracy       : 81.9735440340909\n",
            "    val_loss       : 0.6103927440281156\n",
            "    val_accuracy   : 79.39082278481013\n",
            "Saving checkpoint: saved/models/CIFR10/1114_135317/checkpoint-epoch59.pth ...\n",
            "Train Epoch: 60 [0/45000 (0%)] Loss: 0.285020\n",
            "Train Epoch: 60 [512/45000 (1%)] Loss: 0.545306\n",
            "Train Epoch: 60 [1024/45000 (2%)] Loss: 0.548394\n",
            "Train Epoch: 60 [1536/45000 (3%)] Loss: 0.461947\n",
            "Train Epoch: 60 [2048/45000 (5%)] Loss: 0.482045\n",
            "Train Epoch: 60 [2560/45000 (6%)] Loss: 0.383416\n",
            "Train Epoch: 60 [3072/45000 (7%)] Loss: 0.530977\n",
            "Train Epoch: 60 [3584/45000 (8%)] Loss: 0.376896\n",
            "Train Epoch: 60 [4096/45000 (9%)] Loss: 0.483599\n",
            "Train Epoch: 60 [4608/45000 (10%)] Loss: 0.515080\n",
            "Train Epoch: 60 [5120/45000 (11%)] Loss: 0.705764\n",
            "Train Epoch: 60 [5632/45000 (13%)] Loss: 0.564642\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Computer-Vision-Project/S7/base/base_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mnot_improved_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# save logged informations into log dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Computer-Vision-Project/S7/trainer/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_ftns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06RFCY0iU4bE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8512578-ae30-4a66-9366-ce4f4aa53220"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epoch          : 1\n",
            "    loss           : 1.474361673166806\n",
            "    accuracy       : 47.96697443181818\n",
            "    val_loss       : 1.4066828911817526\n",
            "    val_accuracy   : 52.986550632911396\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch1.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 2\n",
            "    loss           : 1.1271957524798133\n",
            "    accuracy       : 60.6201171875\n",
            "    val_loss       : 1.212920380544059\n",
            "    val_accuracy   : 57.04113924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch2.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 3\n",
            "    loss           : 1.0126117636364969\n",
            "    accuracy       : 64.67729048295455\n",
            "    val_loss       : 1.0137274604809434\n",
            "    val_accuracy   : 64.51740506329114\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch3.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 4\n",
            "    loss           : 0.9453697516159578\n",
            "    accuracy       : 67.16974431818181\n",
            "    val_loss       : 0.9758882794199111\n",
            "    val_accuracy   : 65.84256329113924\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch4.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 5\n",
            "    loss           : 0.9012195615267212\n",
            "    accuracy       : 68.72780539772727\n",
            "    val_loss       : 0.9451241312147696\n",
            "    val_accuracy   : 66.85126582278481\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch5.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 6\n",
            "    loss           : 0.8632059424099597\n",
            "    accuracy       : 70.20374644886364\n",
            "    val_loss       : 1.007167169564887\n",
            "    val_accuracy   : 64.08227848101266\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch6.pth ...\n",
            "    epoch          : 7\n",
            "    loss           : 0.8369434025053951\n",
            "    accuracy       : 71.05823863636364\n",
            "    val_loss       : 0.8434120891969416\n",
            "    val_accuracy   : 70.11471518987342\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch7.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 8\n",
            "    loss           : 0.808358948212117\n",
            "    accuracy       : 71.98375355113636\n",
            "    val_loss       : 0.9219249264348911\n",
            "    val_accuracy   : 68.1368670886076\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch8.pth ...\n",
            "    epoch          : 9\n",
            "    loss           : 0.7850078829902817\n",
            "    accuracy       : 72.8848544034091\n",
            "    val_loss       : 0.8653239487092707\n",
            "    val_accuracy   : 69.44224683544304\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch9.pth ...\n",
            "    epoch          : 10\n",
            "    loss           : 0.7674688140184365\n",
            "    accuracy       : 73.4774502840909\n",
            "    val_loss       : 0.8003014533580104\n",
            "    val_accuracy   : 72.07278481012658\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch10.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 11\n",
            "    loss           : 0.7439635455693033\n",
            "    accuracy       : 73.94797585227273\n",
            "    val_loss       : 0.9486841333063343\n",
            "    val_accuracy   : 68.0379746835443\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch11.pth ...\n",
            "    epoch          : 12\n",
            "    loss           : 0.7283924891274761\n",
            "    accuracy       : 74.67151988636364\n",
            "    val_loss       : 0.9182253366784204\n",
            "    val_accuracy   : 68.90822784810126\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch12.pth ...\n",
            "    epoch          : 13\n",
            "    loss           : 0.7208365041085265\n",
            "    accuracy       : 75.21306818181819\n",
            "    val_loss       : 0.7590373343304743\n",
            "    val_accuracy   : 73.55617088607595\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch13.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 14\n",
            "    loss           : 0.7039712998084724\n",
            "    accuracy       : 75.78125\n",
            "    val_loss       : 0.7952421432054495\n",
            "    val_accuracy   : 72.66613924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch14.pth ...\n",
            "    epoch          : 15\n",
            "    loss           : 0.6970234879885208\n",
            "    accuracy       : 75.99875710227273\n",
            "    val_loss       : 0.8620773078520086\n",
            "    val_accuracy   : 70.76740506329114\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch15.pth ...\n",
            "    epoch          : 16\n",
            "    loss           : 0.6885607651519504\n",
            "    accuracy       : 76.27618963068181\n",
            "    val_loss       : 0.7143555913544908\n",
            "    val_accuracy   : 75.53401898734177\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch16.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 17\n",
            "    loss           : 0.6770434391007505\n",
            "    accuracy       : 76.42711292613636\n",
            "    val_loss       : 0.7175923167150232\n",
            "    val_accuracy   : 75.01977848101266\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch17.pth ...\n",
            "    epoch          : 18\n",
            "    loss           : 0.6659063105471432\n",
            "    accuracy       : 76.92205255681819\n",
            "    val_loss       : 0.7554233066643341\n",
            "    val_accuracy   : 73.5363924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch18.pth ...\n",
            "    epoch          : 19\n",
            "    loss           : 0.6568868948485364\n",
            "    accuracy       : 77.23499644886364\n",
            "    val_loss       : 0.7690437896342217\n",
            "    val_accuracy   : 73.4375\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch19.pth ...\n",
            "    epoch          : 20\n",
            "    loss           : 0.6545876286585223\n",
            "    accuracy       : 77.49689275568181\n",
            "    val_loss       : 0.70706805926335\n",
            "    val_accuracy   : 75.8504746835443\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch20.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 21\n",
            "    loss           : 0.64106321842833\n",
            "    accuracy       : 77.734375\n",
            "    val_loss       : 0.7189535491074188\n",
            "    val_accuracy   : 76.00870253164557\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch21.pth ...\n",
            "    epoch          : 22\n",
            "    loss           : 0.6287440567023375\n",
            "    accuracy       : 78.35138494318181\n",
            "    val_loss       : 0.6959058978135073\n",
            "    val_accuracy   : 75.51424050632912\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch22.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 23\n",
            "    loss           : 0.6276814636181701\n",
            "    accuracy       : 78.38023792613636\n",
            "    val_loss       : 0.7021969013576266\n",
            "    val_accuracy   : 75.67246835443038\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch23.pth ...\n",
            "    epoch          : 24\n",
            "    loss           : 0.6201868917454373\n",
            "    accuracy       : 78.5400390625\n",
            "    val_loss       : 0.7929401650458952\n",
            "    val_accuracy   : 72.66613924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch24.pth ...\n",
            "    epoch          : 25\n",
            "    loss           : 0.6116464619355445\n",
            "    accuracy       : 78.6288174715909\n",
            "    val_loss       : 0.7057701028600524\n",
            "    val_accuracy   : 76.06803797468355\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch25.pth ...\n",
            "    epoch          : 26\n",
            "    loss           : 0.608239623633298\n",
            "    accuracy       : 78.9395419034091\n",
            "    val_loss       : 0.7353638455837588\n",
            "    val_accuracy   : 74.9011075949367\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch26.pth ...\n",
            "    epoch          : 27\n",
            "    loss           : 0.608153673142872\n",
            "    accuracy       : 78.92622514204545\n",
            "    val_loss       : 0.7539002880265441\n",
            "    val_accuracy   : 73.83306962025317\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch27.pth ...\n",
            "    epoch          : 28\n",
            "    loss           : 0.5975884026001123\n",
            "    accuracy       : 79.33904474431819\n",
            "    val_loss       : 0.7008467369441744\n",
            "    val_accuracy   : 75.98892405063292\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch28.pth ...\n",
            "    epoch          : 29\n",
            "    loss           : 0.5956534855491058\n",
            "    accuracy       : 79.22585227272727\n",
            "    val_loss       : 0.6924694327613975\n",
            "    val_accuracy   : 76.16693037974683\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch29.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 30\n",
            "    loss           : 0.5877788587557998\n",
            "    accuracy       : 79.89390980113636\n",
            "    val_loss       : 0.6704653991928583\n",
            "    val_accuracy   : 77.63053797468355\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch30.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 31\n",
            "    loss           : 0.5747819548599761\n",
            "    accuracy       : 80.17134232954545\n",
            "    val_loss       : 0.6730793657936628\n",
            "    val_accuracy   : 76.1867088607595\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch31.pth ...\n",
            "    epoch          : 32\n",
            "    loss           : 0.5798150957138701\n",
            "    accuracy       : 79.7940340909091\n",
            "    val_loss       : 0.703283688690089\n",
            "    val_accuracy   : 75.41534810126582\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch32.pth ...\n",
            "    epoch          : 33\n",
            "    loss           : 0.5688422062984583\n",
            "    accuracy       : 80.21351207386364\n",
            "    val_loss       : 0.6820391080802\n",
            "    val_accuracy   : 76.34493670886076\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch33.pth ...\n",
            "    epoch          : 34\n",
            "    loss           : 0.5678963786075738\n",
            "    accuracy       : 80.38219105113636\n",
            "    val_loss       : 0.6900231162958508\n",
            "    val_accuracy   : 77.23496835443038\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch34.pth ...\n",
            "    epoch          : 35\n",
            "    loss           : 0.5661544621583413\n",
            "    accuracy       : 80.42436079545455\n",
            "    val_loss       : 0.6724845787769631\n",
            "    val_accuracy   : 77.53164556962025\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch35.pth ...\n",
            "    epoch          : 36\n",
            "    loss           : 0.5599110803397541\n",
            "    accuracy       : 80.4532137784091\n",
            "    val_loss       : 0.6684028291249577\n",
            "    val_accuracy   : 76.76028481012658\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch36.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 37\n",
            "    loss           : 0.5608839890919626\n",
            "    accuracy       : 80.63520951704545\n",
            "    val_loss       : 0.6749347120146209\n",
            "    val_accuracy   : 76.64161392405063\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch37.pth ...\n",
            "    epoch          : 38\n",
            "    loss           : 0.5547627776607194\n",
            "    accuracy       : 80.7861328125\n",
            "    val_loss       : 0.6914744105520128\n",
            "    val_accuracy   : 76.72072784810126\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch38.pth ...\n",
            "    epoch          : 39\n",
            "    loss           : 0.5474172005091201\n",
            "    accuracy       : 81.19007457386364\n",
            "    val_loss       : 0.7147912220864356\n",
            "    val_accuracy   : 75.7120253164557\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch39.pth ...\n",
            "    epoch          : 40\n",
            "    loss           : 0.5478683392601934\n",
            "    accuracy       : 81.0879794034091\n",
            "    val_loss       : 0.6595647074753725\n",
            "    val_accuracy   : 77.35363924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch40.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 41\n",
            "    loss           : 0.489269107834182\n",
            "    accuracy       : 83.2430752840909\n",
            "    val_loss       : 0.5812115325957914\n",
            "    val_accuracy   : 80.18196202531645\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch41.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 42\n",
            "    loss           : 0.47407954054969276\n",
            "    accuracy       : 83.62926136363636\n",
            "    val_loss       : 0.5990689694881439\n",
            "    val_accuracy   : 79.80617088607595\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch42.pth ...\n",
            "    epoch          : 43\n",
            "    loss           : 0.4726127004250884\n",
            "    accuracy       : 83.80015980113636\n",
            "    val_loss       : 0.5923023744474484\n",
            "    val_accuracy   : 79.4501582278481\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch43.pth ...\n",
            "    epoch          : 44\n",
            "    loss           : 0.47056418790651316\n",
            "    accuracy       : 83.935546875\n",
            "    val_loss       : 0.5956610663782193\n",
            "    val_accuracy   : 79.72705696202532\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch44.pth ...\n",
            "    epoch          : 45\n",
            "    loss           : 0.4598098902920769\n",
            "    accuracy       : 84.27068536931819\n",
            "    val_loss       : 0.5865156782578819\n",
            "    val_accuracy   : 79.7863924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch45.pth ...\n",
            "    epoch          : 46\n",
            "    loss           : 0.4584942648864605\n",
            "    accuracy       : 84.01322798295455\n",
            "    val_loss       : 0.5958516235592999\n",
            "    val_accuracy   : 79.90506329113924\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch46.pth ...\n",
            "    epoch          : 47\n",
            "    loss           : 0.45872445876540785\n",
            "    accuracy       : 84.33283025568181\n",
            "    val_loss       : 0.5837227177770832\n",
            "    val_accuracy   : 79.76661392405063\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch47.pth ...\n",
            "    epoch          : 48\n",
            "    loss           : 0.4552797407377511\n",
            "    accuracy       : 84.47487571022727\n",
            "    val_loss       : 0.5877332691150375\n",
            "    val_accuracy   : 80.0632911392405\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch48.pth ...\n",
            "    epoch          : 49\n",
            "    loss           : 0.4546547311527485\n",
            "    accuracy       : 84.32173295454545\n",
            "    val_loss       : 0.5751364944101889\n",
            "    val_accuracy   : 80.0632911392405\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch49.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 50\n",
            "    loss           : 0.4488386040426452\n",
            "    accuracy       : 84.69016335227273\n",
            "    val_loss       : 0.5934379623283313\n",
            "    val_accuracy   : 79.48971518987342\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch50.pth ...\n",
            "    epoch          : 51\n",
            "    loss           : 0.4554779367648404\n",
            "    accuracy       : 84.41716974431819\n",
            "    val_loss       : 0.5915184992400906\n",
            "    val_accuracy   : 79.35126582278481\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch51.pth ...\n",
            "    epoch          : 52\n",
            "    loss           : 0.4499854427042671\n",
            "    accuracy       : 84.52370383522727\n",
            "    val_loss       : 0.5728480878132808\n",
            "    val_accuracy   : 80.89398734177215\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch52.pth ...\n",
            "Saving current best: model_best.pth ...\n",
            "    epoch          : 53\n",
            "    loss           : 0.4454803502356464\n",
            "    accuracy       : 84.85662286931819\n",
            "    val_loss       : 0.5919286378576786\n",
            "    val_accuracy   : 80.7753164556962\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch53.pth ...\n",
            "    epoch          : 54\n",
            "    loss           : 0.45059699268842285\n",
            "    accuracy       : 84.47709517045455\n",
            "    val_loss       : 0.6064446583578859\n",
            "    val_accuracy   : 79.13370253164557\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch54.pth ...\n",
            "    epoch          : 55\n",
            "    loss           : 0.4442332973915406\n",
            "    accuracy       : 84.69682173295455\n",
            "    val_loss       : 0.6134692819058141\n",
            "    val_accuracy   : 79.52927215189874\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch55.pth ...\n",
            "    epoch          : 56\n",
            "    loss           : 0.44677996243858203\n",
            "    accuracy       : 84.74343039772727\n",
            "    val_loss       : 0.5770900336247456\n",
            "    val_accuracy   : 80.45886075949367\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch56.pth ...\n",
            "    epoch          : 57\n",
            "    loss           : 0.4475381205874411\n",
            "    accuracy       : 84.64577414772727\n",
            "    val_loss       : 0.5898586624785315\n",
            "    val_accuracy   : 79.7863924050633\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch57.pth ...\n",
            "    epoch          : 58\n",
            "    loss           : 0.44230333235199476\n",
            "    accuracy       : 84.64799360795455\n",
            "    val_loss       : 0.5859317362685746\n",
            "    val_accuracy   : 79.60838607594937\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch58.pth ...\n",
            "    epoch          : 59\n",
            "    loss           : 0.43934909819455986\n",
            "    accuracy       : 84.89879261363636\n",
            "    val_loss       : 0.5918186012702652\n",
            "    val_accuracy   : 80.34018987341773\n",
            "Saving checkpoint: saved/models/CIFR10/1115_002957/checkpoint-epoch59.pth ...\n"
          ]
        }
      ]
    }
  ]
}